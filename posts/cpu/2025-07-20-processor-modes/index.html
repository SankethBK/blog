<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Processor Modes in x86 | Sanketh's Blog</title><meta name=keywords content="cpu,x86"><meta name=description content="The 8086 Processor
A Brief History
The Intel 8086, released in 1978, marked a pivotal moment in computing history as Intel&rsquo;s first 16-bit microprocessor. Designed by a team led by Stephen Morse, the 8086 was Intel&rsquo;s answer to the growing demand for more powerful processors that could handle larger programs and address more memory than the existing 8-bit chips of the era.
The processor introduced the x86 architecture that would become the foundation for decades of computing evolution. With its 16-bit registers and 20-bit address bus 1, the 8086 could access up to 1 megabyte of memory—a massive improvement over the 64KB limitation of 8-bit processors. However, it retained backward compatibility concepts that would prove both beneficial and constraining for future generations."><meta name=author content="Sanketh"><link rel=canonical href=https://sankethbk.github.io/blog/posts/cpu/2025-07-20-processor-modes/><link crossorigin=anonymous href=/blog/assets/css/stylesheet.e2ed8047f83ad264119a8881d8496bb9bd824712cec7cb80665766cf714041fe.css integrity="sha256-4u2AR/g60mQRmoiB2Elrub2CRxLOx8uAZldmz3FAQf4=" rel="preload stylesheet" as=style><link rel=icon href=https://sankethbk.github.io/blog/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://sankethbk.github.io/blog/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://sankethbk.github.io/blog/favicon-32x32.png><link rel=apple-touch-icon href=https://sankethbk.github.io/blog/apple-touch-icon.png><link rel=mask-icon href=https://sankethbk.github.io/blog/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://sankethbk.github.io/blog/posts/cpu/2025-07-20-processor-modes/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://sankethbk.github.io/blog/posts/cpu/2025-07-20-processor-modes/"><meta property="og:site_name" content="Sanketh's Blog"><meta property="og:title" content="Processor Modes in x86"><meta property="og:description" content="The 8086 Processor A Brief History The Intel 8086, released in 1978, marked a pivotal moment in computing history as Intel’s first 16-bit microprocessor. Designed by a team led by Stephen Morse, the 8086 was Intel’s answer to the growing demand for more powerful processors that could handle larger programs and address more memory than the existing 8-bit chips of the era.
The processor introduced the x86 architecture that would become the foundation for decades of computing evolution. With its 16-bit registers and 20-bit address bus 1, the 8086 could access up to 1 megabyte of memory—a massive improvement over the 64KB limitation of 8-bit processors. However, it retained backward compatibility concepts that would prove both beneficial and constraining for future generations."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-07-18T00:00:00+00:00"><meta property="article:modified_time" content="2025-07-18T00:00:00+00:00"><meta property="article:tag" content="Cpu"><meta property="article:tag" content="X86"><meta name=twitter:card content="summary"><meta name=twitter:title content="Processor Modes in x86"><meta name=twitter:description content="The 8086 Processor
A Brief History
The Intel 8086, released in 1978, marked a pivotal moment in computing history as Intel&rsquo;s first 16-bit microprocessor. Designed by a team led by Stephen Morse, the 8086 was Intel&rsquo;s answer to the growing demand for more powerful processors that could handle larger programs and address more memory than the existing 8-bit chips of the era.
The processor introduced the x86 architecture that would become the foundation for decades of computing evolution. With its 16-bit registers and 20-bit address bus 1, the 8086 could access up to 1 megabyte of memory—a massive improvement over the 64KB limitation of 8-bit processors. However, it retained backward compatibility concepts that would prove both beneficial and constraining for future generations."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://sankethbk.github.io/blog/posts/"},{"@type":"ListItem","position":2,"name":"Processor Modes in x86","item":"https://sankethbk.github.io/blog/posts/cpu/2025-07-20-processor-modes/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Processor Modes in x86","name":"Processor Modes in x86","description":"The 8086 Processor A Brief History The Intel 8086, released in 1978, marked a pivotal moment in computing history as Intel\u0026rsquo;s first 16-bit microprocessor. Designed by a team led by Stephen Morse, the 8086 was Intel\u0026rsquo;s answer to the growing demand for more powerful processors that could handle larger programs and address more memory than the existing 8-bit chips of the era.\nThe processor introduced the x86 architecture that would become the foundation for decades of computing evolution. With its 16-bit registers and 20-bit address bus 1, the 8086 could access up to 1 megabyte of memory—a massive improvement over the 64KB limitation of 8-bit processors. However, it retained backward compatibility concepts that would prove both beneficial and constraining for future generations.\n","keywords":["cpu","x86"],"articleBody":"The 8086 Processor A Brief History The Intel 8086, released in 1978, marked a pivotal moment in computing history as Intel’s first 16-bit microprocessor. Designed by a team led by Stephen Morse, the 8086 was Intel’s answer to the growing demand for more powerful processors that could handle larger programs and address more memory than the existing 8-bit chips of the era.\nThe processor introduced the x86 architecture that would become the foundation for decades of computing evolution. With its 16-bit registers and 20-bit address bus 1, the 8086 could access up to 1 megabyte of memory—a massive improvement over the 64KB limitation of 8-bit processors. However, it retained backward compatibility concepts that would prove both beneficial and constraining for future generations.\nWhy 20-bit Address Bus in the 8086? The 8086 used a 20-bit address bus, which was a deliberate design decision based on several factors:\nMemory Capacity: With 20 address lines, the processor could address 2^20 = 1,048,576 locations, or exactly 1 megabyte of memory. In 1978, this was considered enormous - most computers had only 4KB to 64KB of memory.\nEconomic Considerations: Adding more address lines would have increased the chip’s pin count, making it more expensive to manufacture and requiring more expensive motherboards. Intel balanced capability with cost-effectiveness.\nThe Segmented Memory Model Intel’s previous 8-bit processors contained 8-bit wide registers and 16-bit wide address bus, which can enable addressing of 2^16 = 64KB of memory. So thoeretically a program could use 64KB of memory.\nIntel’s main goal was to maintain programming familiarity while expanding addressable memory. They wanted programmers to continue thinking in terms of 16-bit addresses (which they were already comfortable with from 8-bit processors) while secretly accessing a larger memory space. The segmentation model essentially says: “You can still write programs using 16-bit addresses, but we’ll automatically map these into different 64KB ‘segments’ of the larger 1MB space.”\nThe physical address was divided into 2 parts: selector/segment and offset.\nSelector (Segment): 16-bit value stored in one of CS, DS, ES, SS, etc. Offset: 16-bit value (e.g., in SI, DI, BP, SP, or an immediate/displacement). Physical Address Calculation: physical_address = (selector × 16) + offset The idea is to express a 20-bit address using 2 16-bit registers. A selector register (CS, DS, ES, SS) indicates the starting address of the segment and the offset register (SI, DI, BP, SP) indicates the boundary of the segment. Since the offset is 16-bits, the boundary can be at a maximum of 64KB thus maintaining backward compatibility.\nWhat the diagram shows\nA segment is not a fixed block—it’s a sliding 64 KB window that can start on any 16-byte paragraph.\nSegment value = paragraph number; multiplying by 16 shifts the window left or right in 16-byte steps.\nSegment N and Segment N+1 start only 16 bytes apart, so their two 64 KB windows overlap almost completely.\nAny physical byte inside that overlap can be reached with two (or many more) different segment:offset pairs.\nBecause the window can slide to 65,536 different paragraph positions (0000h–FFFFh), the segment register must be 16 bits wide—not just 4 bits.\nThe offset (0–65535) always selects the byte inside the current 64 KB window.\nTogether, segment and offset build the 20-bit physical address:\nDisadvantages of the Segmentation Model 64 KB Segment Limit:\nEach selector covers only 64 KB (the 16-bit offset range). Although it was theoretically possible to support a higher offset which means larger segment memory for a program. Large programs or data structures must be split across multiple segments. Switching segments (e.g., changing CS or DS) adds overhead and complexity. Alias Addresses:\nThe same physical byte can be addressed by many segment:offset pairs. Example: physical 04808₁₆ = 047C:0048 = 047D:0038 = 047E:0028 = 047B:0058 Makes comparing or normalizing pointers tricky. Wrap Around after 20 bits:\nAll segments after 0xF000 reference memory positions above the 1 MB address space that don’t exist, which the 8086 chose to wrap around by ignoring the 21st bit of an address. After all, there is no 21st line in the address bus. The Real Mode Real mode is the operating mode that all x86 processors boot into, providing direct hardware access and backward compatibility with the original 8086 processor. Named “real” because it provides direct, unsupervised access to real physical memory addresses without any protection mechanisms or virtual memory translation.\nWhen an x86 processor powers on, it starts in real mode regardless of whether it’s a modern 64-bit CPU or the original 8086. This ensures that decades-old software can still run and that the boot process remains consistent across the entire x86 family.\nContents of 1MB memory layout in 8086 real mode FFFFFh ┌─────────────────────────────────────────────────────────┐ │ System ROM BIOS (64KB) │ │ • Boot code and POST routines │ │ • Hardware initialization │ │ • Interrupt handlers (INT 10h, 13h, 16h, etc.) │ │ • System services and utilities │ F0000h ├─────────────────────────────────────────────────────────┤ │ Expansion ROM Area (192KB) │ │ • Network card ROM │ │ • SCSI controller ROM │ │ • Other adapter ROM │ │ • Often partially unused │ C0000h ├─────────────────────────────────────────────────────────┤ │ Video BIOS ROM (128KB) │ │ • VGA/EGA BIOS routines │ │ • Graphics mode setup │ │ • Character font data │ │ • Display adapter firmware │ A0000h ├─────────────────────────────────────────────────────────┤ │ Video RAM (128KB) │ │ A0000h-AFFFFh: EGA/VGA graphics memory (64KB) │ │ B0000h-B7FFFh: Monochrome text memory (32KB) │ │ B8000h-BFFFFh: Color text memory (32KB) │ 90000h ├─────────────────────────────────────────────────────────┤ │ Extended Conventional Memory (576KB) │ │ • Available for programs if installed │ │ • Many early systems had less RAM │ │ • Could be used for disk buffers, RAM disks │ │ • Upper portion often used by DOS itself │ A0000h ├─────────────────────────────────────────────────────────┤ ← 640KB barrier │ │ │ Conventional Memory (640KB) │ │ Main user program area │ │ │ │ ┌─────────────────────────────────────────────────────┐ │ │ │ User Program Area │ │ │ │ • Application programs │ │ │ │ • Program data and variables │ │ │ │ • Dynamic memory allocation │ │ │ │ • TSR (Terminate and Stay Resident) programs │ │ │ └─────────────────────────────────────────────────────┘ │ │ ┌─────────────────────────────────────────────────────┐ │ │ │ DOS Kernel and System Files │ │ │ │ • COMMAND.COM │ │ │ │ • Device drivers │ │ │ │ • File allocation tables │ │ │ │ • Directory buffers │ │ │ └─────────────────────────────────────────────────────┘ │ 00500h ├─────────────────────────────────────────────────────────┤ │ BIOS Data Area (256 bytes) │ │ • Hardware configuration data │ │ • Equipment list │ │ • Keyboard buffer │ │ • Video mode information │ │ • Serial/parallel port addresses │ │ • Timer tick count │ │ • Memory size information │ 003FFh ├─────────────────────────────────────────────────────────┤ │ Interrupt Vector Table (1024 bytes) │ │ • 256 interrupt vectors × 4 bytes each │ │ • Each vector: segment:offset (2 bytes:2 bytes) │ │ • INT 00h-FFh handler addresses │ │ • Hardware and software interrupts │ │ • Critical for system operation │ 00000h └─────────────────────────────────────────────────────────┘ Key Memory Regions Interrupt Vector Table (00000h-003FFh) Size: 1024 bytes (256 vectors × 4 bytes each) Structure: Each entry contains segment:offset pointer (YYYY:XXXX format) Purpose: The system’s “phone book” for interrupt handlers Function: When hardware or software triggers an interrupt (like pressing a key), the CPU looks up the handler address here Critical vectors: INT 08h: System timer (18.2 times per second) INT 09h: Keyboard interrupt INT 10h: Video services INT 13h: Disk services INT 16h: Keyboard services INT 21h: DOS system calls Why it’s at address 0: The CPU automatically multiplies the interrupt number by 4 to find the handler address, so INT 09h handler is at 0×4×9 = 36 (0024h). BIOS Data Area (00400h-004FFh) - 256 bytes Purpose: System configuration and status information Hardware ports: COM1-4 2 and LPT1-3 3 base addresses Video info: Current video mode, screen dimensions, cursor position Keyboard: Shift/Ctrl/Alt key states 4, keyboard buffer 5 System info: Installed memory size, equipment flags Timers: System tick count since boot Conventional Memory (00500h-9FFFFh) - ~640KB Purpose: Main workspace for operating system and applications DOS Kernel Area (lower portion) COMMAND.COM: The DOS command interpreter DOS kernel: File system, memory management, process control Device drivers: Disk drivers, printer drivers, etc. System buffers: File allocation table cache, directory buffers User Program Area (upper portion) Application programs: Your actual software Program data: Variables, arrays, user data Dynamic allocation: Heap memory for runtime allocation TSR programs: Background utilities (like antivirus, print spoolers) Why 640KB limit: IBM reserved the upper 384KB for hardware, creating the famous “640KB ought to be enough” barrier. Video RAM (A0000h-BFFFFh) - 128KB\nPurpose: Direct access to display memory A0000h-AFFFFh: Graphics Memory (64KB) EGA/VGA framebuffer: Each byte represents pixel data Direct pixel control: Writing here immediately changes screen pixels Mode-dependent: Layout changes based on resolution and color depth B0000h-B7FFFh: Monochrome Text (32KB)\nCharacter display: For monochrome monitors Text mode: 80×25 characters, 2 bytes per character (char + attribute) B8000h-BFFFFh: Color Text (32KB)\nColor character display: Standard color text mode Format: Byte pairs (character, attribute) Example: Writing ‘A’ (65) + 0x07 (white on black) to B8000h displays ‘A’ at top-left Video BIOS ROM (C0000h-C7FFFh) - 32KB\nPurpose: Graphics card firmware and services Font data: Character sets for text modes Hardware control: Register programming for graphics chips BIOS extensions: Additional video services beyond basic BIOS Memory-mapped: This is ROM on the graphics card, not system RAM. Expansion ROM Area (C8000h-EFFFFh) - 160KB\nPurpose: Additional adapter card firmware Network cards: Boot ROM for network booting SCSI controllers: Disk controller firmware Sound cards: Audio processing firmware Other adapters: Any card that needs ROM space Often unused: Many systems had empty areas here. System ROM BIOS (F0000h-FFFFFh) - 64KB\nPurpose: Core system firmware Power-On Self Test (POST): Hardware diagnostics at boot Bootstrap loader: Loads operating system from disk Hardware drivers: Low-level hardware access routines System services: INT 10h (video), INT 13h (disk), INT 16h (keyboard) Reset vector: CPU starts execution at FFFF:0000 on power-up Why This Layout? Hardware Requirements: Different devices need different address ranges ROM needs upper memory: BIOS must be at top (reset vector at FFFFFh) Video needs fast access: Memory-mapped for performance Programs need contiguous space: Large conventional memory block The 80286 and protected mode Introduction to the 80286 The Intel 80286, released in 1982, represented a revolutionary leap in x86 architecture. While maintaining backward compatibility with the 8086, it introduced protected mode - a sophisticated operating environment that broke free from real mode’s limitations and laid the foundation for modern computing.\nThe 80286 was Intel’s answer to the growing demands for multitasking operating systems, memory protection, and the ability to address more than 1MB of memory. It powered the IBM PC/AT and became the processor that truly enabled the transition from simple DOS machines to powerful workstations.\nKey Innovations of the 80286 16MB Address Space 24-bit address bus (compared to 8086’s 20-bit) 16MB maximum memory (2^24 = 16,777,216 bytes) Maintained real mode compatibility for existing Hardware Memory Protection Privilege levels preventing user programs from corrupting system memory Segment-level protection with access rights and bounds checking Hardware-enforced security that software cannot bypass Virtual Memory Foundation Segment descriptors containing detailed memory management information Global and Local Descriptor Tables for memory organization Task switching support enabling true multitasking Addressing 24-Bit Memory The 80286 processor had 24 address bus compared to 20-Bit address bus of 8086. It had to implement the addressing in such a way that its backward compatible with 8086 processor’s addressing. Instead of extending the logic used in 8086’s real mode addressing, 80286 took an entirely different approach. The memory was still addressed with selector (16-Bit): offset (16-Bit) pairs. In real mode, a selector value was a paragraph number of physical memory. In protected mode, a selector value is an index into a descriptor table. In both modes, programs are divided into segments. In real mode, these segments are at fixed positions in physical memory and the selector value denotes the paragraph number of the beginning of the segment.\nWhile we are storing the actual physical address of the segment in descriptor table, the descriptor table entry can store other information related to the segment as well. For eg: length of the segment which can be used to check if the memory accessed by the program is within the segment, read/write flags which can be used to enforce protection, etc.\nThe Virtual Memory The idea of virtual memory is provide an illusion to a program that it is the only program running and it has access to all the memory. The 80286 introduced the foundational concepts of virtual memory to the x86 architecture, though it implemented a more limited form compared to modern processors. Understanding the 80286’s approach helps clarify why virtual memory became essential and how it evolved.\nVirtual memory creates an abstraction layer between what programs think they’re accessing (virtual addresses) and what actually exists in physical memory. The 80286 achieved this through segmentation-based virtual memory.\nSimplified Programming Model with Virtual Memory Before virtual memory, programmer had to directly manage physical addresses which is error prone and there’s a possibility of overwriting other program’s data. This also means the programmer has to know where the segments will be loaded in memory beforehand. Virtual Memory solves this issue as each segment will be under the illusion that it starts at memory address 0 and can access upto 64KB of memory.\nGlobal and Local Descriptor Tables (GDT and LDT) What Are Descriptor Tables? Think of descriptor tables as address books for the computer’s memory system. Just like you use a phone book to look up someone’s address when you only know their name, the 80286 processor uses descriptor tables to look up memory information when it only knows a selector (a kind of memory “name”).\nThe Basic Problem They Solve In real mode, programs had to deal with physical memory addresses directly:\nReal Mode Problem: Program says: \"I want to access memory at 0x12345\" CPU responds: \"OK, accessing physical memory at 0x12345\" Issues: - Programs must know exact physical addresses - No protection between programs - Programs can corrupt each other's memory - Hard to relocate programs in memory Protected mode solves this with an indirection layer:\nProtected Mode Solution: Program says: \"I want to access selector 0x0008, offset 0x1234\" CPU responds: \"Let me look up selector 0x0008 in the descriptor table...\" CPU finds: \"Selector 0x0008 points to base address 0x100000\" CPU calculates: \"Physical address = 0x100000 + 0x1234 = 0x101234\" CPU verifies: \"Access allowed? Yes. Accessing physical memory at 0x101234\" Understanding Selectors A selector is a 16-bit value that acts like a “memory ID card.” Instead of using physical addresses, programs use selectors to identify memory segments.\nIndex (bits 15-3): Which entry in the descriptor table (0-8191) TI (bit 2): Table Indicator - 0 = GDT, 1 = LDT RPL (bits 1-0): Requested Privilege Level (0-3) What Is a Descriptor? A descriptor is an 8-byte data structure that contains all the information the CPU needs to access a memory segment safely.\nBase Address (24 bits total in 80286): (Base[23..16] + Base[15..0])\nBits 15..0 from the lower section Bits 23..16 from the upper section Limit (20 bits total, but 80286 only uses 16 bits):\nLimit 15..0 (16 bits) - from Lower 32 bits Limit 19..16 (4 bits) - from Upper 32 bits (but not used in 80286) The descriptor format was designed to be forward-compatible. The 80386 later extended it to use:\nFull 32-bit base address (adding Base 31..24) Full 20-bit limit (adding Limit 19..16 with granularity bit) Final physical address calculation:\nPhysical Address = 24-bit Base (from descriptor) + 16-bit Offset (from instruction) Access Byte Format\nP (Present) - Bit 7: Indicates whether the segment is currently loaded in memory. When P=1, the segment is valid and can be accessed. When P=0, any attempt to access this segment generates a segment-not-present exception, allowing the OS to load the segment from disk (virtual memory support). DPL (Descriptor Privilege Level) - Bits 6-5: Defines the privilege level required to access this segment (0-3, where 0 is most privileged). Code running at privilege level 3 (user mode) cannot access segments with DPL=0 (kernel mode). This enforces memory protection between kernel and user space. S (System) - Bit 4: Distinguishes between application segments and system segments. When S=1, this is an application segment (code/data used by programs). When S=0, this is a system segment (like Task State Segment or LDT descriptor) used by the processor for special operations. E (Executable) - Bit 3: Determines if this segment contains executable code or data. When E=1, this is a code segment that can be executed (instructions fetched from here). When E=0, this is a data segment used for storing variables and cannot be executed. D (Direction/Conforming) - Bit 2: For data segments: D=0 means segment grows upward (normal), D=1 means grows downward (stack). For code segments: D=0 means non-conforming (strict privilege checking), D=1 means conforming (can be called from lower privilege levels without changing CPL). R (Read/Write) - Bit 1: For data segments: R=1 allows write access, R=0 makes it read-only. For code segments: R=1 allows reading the code (useful for debuggers), R=0 makes it execute-only. Code segments are never writable regardless of this bit. A (Accessed) - Bit 0: Automatically set by the CPU whenever the segment is accessed (loaded into a segment register or used). Never cleared by hardware - only software can clear it. Used by operating systems to implement virtual memory algorithms by tracking which segments are actively being used. Flags Field (4 bits) Bit 3: G (Granularity)\nG = 0: Limit is in bytes (fine granularity)\nSegment can be 1 byte to 1 MB in size Limit value is used directly G = 1: Limit is in 4KB pages (page granularity)\nSegment can be 4KB to 4GB in size CPU automatically shifts limit left by 12 bits (multiplies by 4096) Bit 2: D/B (Default/Big)\nFor Code Segments: Controls default operand/address size\nD = 0: 16-bit mode (8086/80286 compatible) D = 1: 32-bit mode (80386+ native) For Data Segments: Controls stack pointer size\nB = 0: Stack uses SP (16-bit stack pointer) B = 1: Stack uses ESP (32-bit stack pointer) Bit 1: L (Long Mode)\nFor 64-bit mode only (not relevant for 80286) L = 0: Not a 64-bit code segment L = 1: 64-bit code segment (x86-64 mode) Rule: If L = 1, then D must = 0 Bit 0: AVL (Available)\nAvailable for system software use Not used by CPU hardware OS can use for its own purposes Examples: Process tracking, debugging flags, memory management hints Global Descriptor Table (GDT) The Global Descriptor Table is a system-wide table containing descriptors that all tasks can potentially access. Think of it as the “public directory” of memory segments.\nGDT Structure and Location Physical Memory Layout: ┌─────────────────────────────────────────────────────────────┐ │ System RAM │ │ │ │ ┌─────────────────────────────────────────────────────┐ │ │ │ GDT │ │ │ ├─────────────────────────────────────────────────────┤ │ │ │ Entry 0: NULL Descriptor (required) │ │ │ ├─────────────────────────────────────────────────────┤ │ │ │ Entry 1: Kernel Code Segment │ │ │ ├─────────────────────────────────────────────────────┤ │ │ │ Entry 2: Kernel Data Segment │ │ │ ├─────────────────────────────────────────────────────┤ │ │ │ Entry 3: User Code Segment │ │ │ ├─────────────────────────────────────────────────────┤ │ │ │ Entry 4: User Data Segment │ │ │ ├─────────────────────────────────────────────────────┤ │ │ │ Entry 5: Task A's LDT Descriptor │ │ │ ├─────────────────────────────────────────────────────┤ │ │ │ Entry 6: Task A's TSS Descriptor │ │ │ ├─────────────────────────────────────────────────────┤ │ │ │ Entry 7: Task B's LDT Descriptor │ │ │ ├─────────────────────────────────────────────────────┤ │ │ │ Entry 8: Task B's TSS Descriptor │ │ │ └─────────────────────────────────────────────────────┘ │ │ │ └─────────────────────────────────────────────────────────────┘ GDTR Register (inside CPU): ┌─────────────────────────────────────────────────────────────┐ │ Base Address: Points to start of GDT in memory │ │ Limit: Size of GDT - 1 │ └─────────────────────────────────────────────────────────────┘ What Goes in the GDT? System-wide resources that multiple tasks might need:\n1. Operating System Segments\nKernel code segment (Ring 0) Kernel data segment (Ring 0) System service segments 2. Common User Segments\nStandard user code segment (Ring 3) Standard user data segment (Ring 3) 3. Task Management Descriptors\nTask State Segments (TSS) for each task Local Descriptor Table (LDT) descriptors for each task 4. Device Driver Segments\nDriver code segments Shared system libraries Example GDT Layout ┌─────┬───────────────────┬──────────┬─────────┬─────────────────┐ │Index│ Description │ Base │ Limit │ Access Rights │ ├─────┼───────────────────┼──────────┼─────────┼─────────────────┤ │ 0 │ NULL (required) │ 00000000 │ 00000 │ 00000000 │ ├─────┼───────────────────┼──────────┼─────────┼─────────────────┤ │ 1 │ Kernel Code │ 00000000 │ FFFFF │ 9A (Ring 0, X/R)│ ├─────┼───────────────────┼──────────┼─────────┼─────────────────┤ │ 2 │ Kernel Data │ 00000000 │ FFFFF │ 92 (Ring 0, R/W)│ ├─────┼───────────────────┼──────────┼─────────┼─────────────────┤ │ 3 │ User Code │ 00000000 │ FFFFF │ FA (Ring 3, X/R)│ ├─────┼───────────────────┼──────────┼─────────┼─────────────────┤ │ 4 │ User Data │ 00000000 │ FFFFF │ F2 (Ring 3, R/W)│ ├─────┼───────────────────┼──────────┼─────────┼─────────────────┤ │ 5 │ Text Editor LDT │ 00200000 │ 01000 │ 82 (LDT, Ring 0)│ ├─────┼───────────────────┼──────────┼─────────┼─────────────────┤ │ 6 │ Text Editor TSS │ 00201000 │ 00068 │ 89 (TSS, Ring 0)│ ├─────┼───────────────────┼──────────┼─────────┼─────────────────┤ │ 7 │ Web Browser LDT │ 00300000 │ 01000 │ 82 (LDT, Ring 0)│ ├─────┼───────────────────┼──────────┼─────────┼─────────────────┤ │ 8 │ Web Browser TSS │ 00301000 │ 00068 │ 89 (TSS, Ring 0)│ └─────┴───────────────────┴──────────┴─────────┴─────────────────┘ Local Descriptor Table (LDT) A Local Descriptor Table is a task-specific table containing descriptors that are private to one particular task. Think of it as each task’s “private address book.”\nKey Differences: GDT vs LDT GDT (Global - Shared): LDT (Local - Private): ┌─────────────────────┐ ┌─────────────────────┐ │ • One per system │ │ • One per task │ │ • Shared by all │ │ • Private to task │ │ • System resources │ │ • Task resources │ │ • Always available │ │ • Only when task │ │ │ │ is running │ └─────────────────────┘ └─────────────────────┘ How LDTs Work Step 1: LDT Descriptor in GDT The GDT contains a descriptor that points to each task’s LDT:\nGDT Entry 5 (Text Editor's LDT): ┌─────────────────────────────────────────────────────────────┐ │ Base: 0x200000 ← Physical address where LDT is stored │ │ Limit: 0x1000 ← LDT can hold up to 512 descriptors │ │ Type: LDT ← This is an LDT descriptor │ │ DPL: 0 ← Ring 0 (system manages LDTs) │ └─────────────────────────────────────────────────────────────┘ Step 2: LDT Contains Task’s Private Descriptors\nAt physical address 0x200000 (Text Editor's LDT): ┌─────────────────────────────────────────────────────────────┐ │ Entry 0: NULL │ │ Entry 1: Text Editor Code Segment │ │ Entry 2: Text Editor Data Segment │ │ Entry 3: Text Editor Stack Segment │ │ Entry 4: Document Buffer Segment │ │ Entry 5: Font Library Segment │ └─────────────────────────────────────────────────────────────┘ LDT Entries LDT entries follow the exact same 8-byte descriptor format as GDT entries. An LDT is a block of (linear) memory up to 64K in size, just like the GDT. The difference from the GDT is in the Descriptors that it can store, and the method used to access it.\nBoth use the same:\n64-bit (8-byte) descriptor structure Same Base/Limit/Access byte/Flags layout Same bit positions for all fields However, there are content restrictions for LDT:\nLDT cannot hold system segments (Task State Segments and Local Descriptor Tables) LDT can only contain application segments (code/data) and some gates GDT can contain everything (application segments, system segments, LDT descriptors, TSS descriptors) What Are Gates? Gates are special descriptors that act as “doorways” for controlled transfers of execution. Unlike regular segment descriptors that point to memory regions, gates contain entry points (addresses) where execution should transfer to.\nTypes of Gates in x86: 1. Call Gates\nPurpose: Allow controlled calls from lower privilege code to higher privilege code Function: Like a “secure function pointer” - lets user code (Ring 3) safely call kernel functions (Ring 0) Contains: Target code segment selector + offset where to jump Security: CPU automatically checks privilege levels and switches stacks if needed 2. Task Gates\nPurpose: Trigger hardware task switches Function: Points to a TSS descriptor to switch to a different task Contains: TSS selector that identifies which task to switch to Usage: Can be placed in IDT for task-switching interrupts 3. Interrupt Gates\nPurpose: Handle interrupts and exceptions Function: Similar to call gates but for interrupt handling Contains: Target code segment + interrupt handler address Behavior: Automatically disables interrupts when called 4. Trap Gates\nPurpose: Handle exceptions and software interrupts Function: Like interrupt gates but doesn’t disable interrupts Contains: Target code segment + exception handler address Usage: For system calls and debugging exceptions Why Gates Can Be in LDT:\nWhile LDT cannot contain system segments (TSS, LDT descriptors), it can contain gates because:\nCall gates: Allow process-specific entry points to system services Task gates: Could theoretically allow process-specific task switching (though rarely used) Example Use Case:\nProcess A's LDT might contain: ├── Code Segment (Ring 3) ├── Data Segment (Ring 3) ├── Call Gate → Kernel function for file I/O └── Call Gate → Kernel function for memory allocation This way, each process can have its own set of “approved” kernel entry points through call gates in their private LDT, while the kernel maintains control over exactly which functions can be called and how.\nIn practice: Modern operating systems rarely use LDTs or gates, preferring software-based system call mechanisms and paging-based memory protection. But the hardware still supports these features for compatibility and specialized use cases.\nGDTR and LDTR The processor locates the GDT and the current LDT in memory by means of the GDTR and LDTR registers. These registers store the base addresses of the tables in the linear address space and store the segment limits.\nGDTR (Global Descriptor Table Register): ┌─────────────────────────────────────────────────────────────┐ │ GDTR - Simple pointer structure │ ├─────────────────────────────────┬───────────────────────────┤ │ Base Address (32-bit) │ Limit (16-bit) │ │ Linear address of GDT in memory │ Size of GDT - 1 │ └─────────────────────────────────┴───────────────────────────┘ Direct pointer to GDT location in memory Loaded with LGDT instruction Contains actual memory address and size LDTR (Local Descriptor Table Register): ┌─────────────────────────────────────────────────────────────┐ │ LDTR - Segment register with selector + cached descriptor │ ├─────────────────────────────────────────────────────────────┤ │ Visible: LDT Selector (16-bit) │ ├─────────────────────────────────────────────────────────────┤ │ Hidden: Cached LDT Descriptor (64-bit) │ │ Base + Limit + Access Rights from GDT entry │ └─────────────────────────────────────────────────────────────┘ Indirect reference through GDT selector The LDT is defined as a ’normal’ memory Segment inside the GDT - simply with a Base memory address and Limit Loaded with LLDT instruction using a selector CPU automatically fetches LDT descriptor from GDT and caches it The Relationship:\nGDTR points directly to GDT in memory LDTR contains a selector that points to an entry within the GDT That GDT entry describes where the LDT is located CPU caches that LDT descriptor information from GDT in LDTR’s hidden part WHo can Read/Write into GDTR and LDTR registers? GDTR (Global Descriptor Table Register):\nSet by: Operating system kernel (Ring 0 code only) Instructions: LGDT (Load GDT) and SGDT (Store GDT) Privilege: These instructions can only be executed in Ring 0 (kernel mode) When: During OS boot/initialization LDTR (Local Descriptor Table Register):\nSet by: Operating system kernel (Ring 0 code only) Instructions: LLDT (Load LDT) and SLDT (Store LDT) Privilege: Ring 0 only When: During task/process creation or context switches Initial Setup Process: 1. System Boot Sequence:\n1. CPU starts in Real Mode (no GDTR/LDTR) 2. Bootloader loads OS kernel 3. Kernel creates initial GDT in memory 4. Kernel executes LGDT to set GDTR 5. Kernel switches to Protected Mode 6. Kernel can now create LDTs and set LDTR as needed 2. GDT Creation (by OS Kernel):\n// Kernel code (Ring 0) during boot struct gdt_entry gdt[8]; // Array in kernel memory // Set up null descriptor (entry 0) gdt[0] = {0}; // Set up kernel code segment (entry 1) gdt[1] = {base: 0, limit: 0xFFFFF, access: 0x9A, flags: 0xC}; // Set up kernel data segment (entry 2) gdt[2] = {base: 0, limit: 0xFFFFF, access: 0x92, flags: 0xC}; // Set up user code segment (entry 3) gdt[3] = {base: 0, limit: 0xFFFFF, access: 0xFA, flags: 0xC}; // More entries... // Load the GDT struct gdt_ptr { uint16_t limit; uint32_t base; } gdt_descriptor = {sizeof(gdt)-1, (uint32_t)gdt}; asm(\"lgdt %0\" : : \"m\"(gdt_descriptor)); Who Can Read/Write GDT and LDT? Reading:\nGDT/LDT contents: Any code can read (they’re just memory) GDTR/LDTR values: SGDT/SLDT instructions (Ring 0 only)\nWriting:\nGDT/LDT contents: Only Ring 0 code should modify (by convention) GDTR/LDTR registers: Only Ring 0 via LGDT/LLDT\nMemory Protection:\nGDT location: Kernel typically places GDT in kernel-only memory pages LDT location: Can be in user-accessible memory (but user can’t change LDTR)\nPost 80386 Era SGDT/SLDT: Ring 3 accessible (any privilege level) LGDT/LLDT: Still Ring 0 only Why Intel Made This Change:\nPractical Reasons:\nDebugging tools: Debuggers and system utilities needed to examine system state Virtual machines: VM software needed to read GDT/IDT information System monitoring: Performance tools and diagnostics required access Compatibility: Some software had legitimate needs to read (not write) this info Security Analysis:\nReading GDTR/IDTR: Reveals memory layout but doesn’t grant control Still protected: Only reading allowed - writing still requires Ring 0 Limited exposure: Knowing GDT location doesn’t directly compromise security Modern Usage:\nThis change enabled:\nHypervisors: VMware, VirtualBox can inspect guest OS descriptor tables Security tools: Rootkit detectors can examine system structures Debuggers: WinDbg, GDB can show detailed system state OS utilities: System information tools can display memory management details Task State Segment (TSS) The Task State Segment (TSS) is a special data structure that contains the complete execution state of a task (program). Think of it as a “snapshot” that captures everything the CPU needs to know about a task - all its registers, memory settings, and execution context.\nBefore the 80286, task switching was a manual, error-prone process:\nManual Task Switching (8086 era): ┌─────────────────────────────────────────────────────────────┐ │ 1. Programmer saves all registers manually │ │ MOV [task_a_ax], AX │ │ MOV [task_a_bx], BX │ │ MOV [task_a_cx], CX │ │ ... (save 20+ registers and flags) │ │ │ │ 2. Programmer loads new task's registers manually │ │ MOV AX, [task_b_ax] │ │ MOV BX, [task_b_bx] │ │ ... (load 20+ registers and flags) │ │ │ │ 3. Programmer manages memory segments manually │ │ MOV DS, [task_b_ds] │ │ MOV ES, [task_b_es] │ │ │ │ Problems: │ │ ❌ 50+ instructions per task switch │ │ ❌ Easy to forget registers │ │ ❌ No atomic operation │ │ ❌ No protection │ │ ❌ Very slow │ └─────────────────────────────────────────────────────────────┘ TSS Solution: Hardware Task Switching (80286): ┌─────────────────────────────────────────────────────────────┐ │ Single instruction: JMP task_selector │ │ │ │ Hardware automatically: │ │ ✅ Saves ALL current state to current TSS │ │ ✅ Loads ALL new state from target TSS │ │ ✅ Updates memory management (LDT switch) │ │ ✅ Atomic operation (cannot be interrupted) │ │ ✅ Hardware protection checks │ │ ✅ Extremely fast (few clock cycles) │ └─────────────────────────────────────────────────────────────┘ TSS Structure and Layout The 80286 TSS is a 44-byte (104 bytes with I/O bitmap 6) data structure containing every piece of information needed to resume a task:\nTSS Layout (80286): ┌─────────────────────────────────────────────────────────────┐ │ Offset │ Size │ Field Name │ Description │ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 00h │ 2 │ Previous TSS Link │ Selector of previous │ │ │ │ │ task (for nested calls) │ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 02h │ 2 │ SP0 (Stack Ring 0)│ Stack pointer for Ring 0│ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 04h │ 2 │ SS0 (Stack Ring 0)│ Stack segment for Ring 0│ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 06h │ 2 │ SP1 (Stack Ring 1)│ Stack pointer for Ring 1│ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 08h │ 2 │ SS1 (Stack Ring 1)│ Stack segment for Ring 1│ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 0Ah │ 2 │ SP2 (Stack Ring 2)│ Stack pointer for Ring 2│ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 0Ch │ 2 │ SS2 (Stack Ring 2)│ Stack segment for Ring 2│ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 0Eh │ 2 │ IP │ Instruction Pointer │ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 10h │ 2 │ FLAGS │ Processor flags │ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 12h │ 2 │ AX │ General register AX │ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 14h │ 2 │ CX │ General register CX │ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 16h │ 2 │ DX │ General register DX │ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 18h │ 2 │ BX │ General register BX │ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 1Ah │ 2 │ SP │ Stack Pointer │ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 1Ch │ 2 │ BP │ Base Pointer │ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 1Eh │ 2 │ SI │ Source Index │ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 20h │ 2 │ DI │ Destination Index │ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 22h │ 2 │ ES │ Extra Segment │ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 24h │ 2 │ CS │ Code Segment │ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 26h │ 2 │ SS │ Stack Segment │ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 28h │ 2 │ DS │ Data Segment │ ├────────┼──────┼───────────────────┼─────────────────────────┤ │ 2Ah │ 2 │ LDT Selector │ Local Descriptor Table │ └─────────────────────────────────────────────────────────────┘ Memory Layout Visualization TSS in Physical Memory: ┌─────────────────────────────────────────────────────────────┐ │ Task A's TSS │ │ (44 bytes minimum) │ ├─────────────────────────────────────────────────────────────┤ │ Offset 00h: Previous Task = 0x0000 │ │ Offset 02h: Ring 0 SP = 0x7C00 │ │ Offset 04h: Ring 0 SS = 0x0008 │ │ Offset 06h: Ring 1 SP = 0x0000 │ │ Offset 08h: Ring 1 SS = 0x0000 │ │ Offset 0Ah: Ring 2 SP = 0x0000 │ │ Offset 0Ch: Ring 2 SS = 0x0000 │ │ Offset 0Eh: IP = 0x1234 ← Where task will resume │ │ Offset 10h: FLAGS = 0x0202 │ │ Offset 12h: AX = 0x1234 │ │ Offset 14h: CX = 0x5678 │ │ Offset 16h: DX = 0x9ABC │ │ Offset 18h: BX = 0xDEF0 │ │ Offset 1Ah: SP = 0x7FF0 │ │ Offset 1Ch: BP = 0x7FE0 │ │ Offset 1Eh: SI = 0x1000 │ │ Offset 20h: DI = 0x2000 │ │ Offset 22h: ES = 0x0010 │ │ Offset 24h: CS = 0x0008 │ │ Offset 26h: SS = 0x0010 │ │ Offset 28h: DS = 0x0010 │ │ Offset 2Ah: LDT = 0x0028 ← Task's private memory │ └─────────────────────────────────────────────────────────────┘ TSS Descriptor in the GDT The TSS itself is just a data structure in memory. To use it, there must be a TSS descriptor in the GDT that points to it: (SInce TSS Descriptor is just another entry in GDT, it follows the same pattern as GDT entries)\nGDT Entry for TSS: ┌─────────────────────────────────────────────────────────────┐ │ TSS Descriptor (8 bytes) │ ├─────────────────────────────────────────────────────────────┤ │ Base Address: 0x00010000 ← Physical address of TSS │ │ Limit: 0x0067 ← TSS size (103 bytes) │ │ Access Byte: 0x89 ← TSS type, Ring 0 │ │ Flags: 0x00 ← Standard flags │ └─────────────────────────────────────────────────────────────┘ Access Byte Breakdown (0x89): ┌─┬─────┬─┬─┬─────┬─┬─┬─┐ │1│ 00 │0│1│ 001 │0│0│1│ └─┴─────┴─┴─┴─────┴─┴─┴─┘ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ └─ Accessed bit │ │ │ │ │ │ └─── Reserved │ │ │ │ │ └───── Busy bit (0=available, 1=busy) │ │ │ │ └────────── TSS type (1001 = available TSS) │ │ │ └─────────────── System descriptor (0) │ │ └───────────────── Reserved │ └────────────────────── Privilege level (00 = Ring 0) └───────────────────────── Present (1 = valid) Key Differences by Descriptor Type\nBits 3-0 Interpretation\nApplication Descriptors (S=1):\nBit 3: Executable (1=code, 0=data) Bit 2: Direction/Conforming Bit 1: Read/Write permission Bit 0: Accessed by CPU System Descriptors (S=0):\nBits 3-0: System type (TSS, LDT, gates, etc.) System Types: 0001 = Available 286 TSS 0010 = LDT 0011 = Busy 286 TSS 0100 = 286 Call Gate 0101 = Task Gate 0110 = 286 Interrupt Gate 0111 = 286 Trap Gate 1001 = Available 386 TSS 1011 = Busy 386 TSS (others reserved) Task Switching Process When the CPU executes a task switch instruction, here’s exactly what happens:\nTask Switch: JMP 0x0030 ; Jump to task with TSS at GDT entry 6 Hardware Sequence: ┌─────────────────────────────────────────────────────────────┐ │ Step 1: Identify Target Task │ │ • Extract index from selector 0x0030 → Index 6 │ │ • Look up GDT entry 6 → TSS descriptor │ │ • Get TSS base address and verify it's a valid TSS │ ├─────────────────────────────────────────────────────────────┤ │ Step 2: Save Current Task State │ │ • Get current TSS address (from TR register) │ │ • Save all CPU registers to current TSS: │ │ - Store AX at TSS+0x12h │ │ - Store CX at TSS+0x14h │ │ - Store DX at TSS+0x16h │ │ - ... (save all registers and flags) │ │ - Store IP at TSS+0x0Eh │ │ - Store segment registers │ ├─────────────────────────────────────────────────────────────┤ │ Step 3: Mark Tasks │ │ • Set current TSS descriptor busy bit = 0 (available) │ │ • Set target TSS descriptor busy bit = 1 (busy) │ ├─────────────────────────────────────────────────────────────┤ │ Step 4: Load New Task State │ │ • Load all registers from target TSS: │ │ - Load AX from TSS+0x12h │ │ - Load CX from TSS+0x14h │ │ - ... (load all registers and flags) │ │ - Load IP from TSS+0x0Eh │ │ - Load segment registers │ ├─────────────────────────────────────────────────────────────┤ │ Step 5: Update Memory Management │ │ • Load LDT selector from TSS+0x2Ah │ │ • Update LDTR register → new task's private memory view │ │ • Flush segment register caches │ ├─────────────────────────────────────────────────────────────┤ │ Step 6: Update Task Register │ │ • Store new TSS selector in TR register │ │ • Cache new TSS descriptor in hidden portion │ ├─────────────────────────────────────────────────────────────┤ │ Step 7: Continue Execution │ │ • Begin executing at CS:IP from new TSS │ │ • Task switch complete! │ └─────────────────────────────────────────────────────────────┘ Total time: ~17-34 clock cycles (extremely fast!)\nPrivilege Level Stack Management Each privilege level (Ring 0-3) needs its own separate stack for each program for security and proper operation:\nWhy Multiple Stacks are Needed? Security Problem Without Separate Stacks: ┌─────────────────────────────────────────────────────────────┐ │ User Program (Ring 3) stack contains: │ │ ┌─────────────────────────────────────────────────────────┐ │ │ │ User data, local variables, function calls │ │ │ │ Potentially malicious or corrupted data │ │ │ └─────────────────────────────────────────────────────────┘ │ │ │ │ System Call (Ring 3 → Ring 0): │ │ If kernel uses same stack: │ │ ❌ Kernel data mixed with user data │ │ ❌ User could corrupt kernel stack │ │ ❌ Security vulnerability │ │ ❌ Kernel crash could corrupt user stack │ └─────────────────────────────────────────────────────────────┘ Solution - Separate Stacks: ┌─────────────────────────────────────────────────────────────┐ │ Ring 0 Stack (Kernel): │ │ ┌─────────────────────────────────────────────────────────┐ │ │ │ Kernel local variables, system call parameters │ │ │ │ Protected from user access │ │ │ └─────────────────────────────────────────────────────────┘ │ │ │ │ Ring 3 Stack (User): │ │ ┌─────────────────────────────────────────────────────────┐ │ │ │ User program data, function calls │ │ │ │ Cannot affect kernel operations │ │ │ └─────────────────────────────────────────────────────────┘ │ └─────────────────────────────────────────────────────────────┘ Stack Pointer (SP) and Stack Segment (SS) Explained Stack Pointer (SP): The offset within the stack segment where the stack currently “points” Stack Segment (SS): The selector that identifies which memory segment contains the stack How Stack Switching Works? Privilege Level Change Example: User Program (Ring 3) makes system call: ┌─────────────────────────────────────────────────────────────┐ │ Current State: │ │ SS = 0x0010 (user data segment) │ │ SP = 0x7FF0 (user stack pointer) │ │ CPL = 3 (Ring 3) │ └─────────────────────────────────────────────────────────────┘ │ ▼ INT 21h (system call) ┌─────────────────────────────────────────────────────────────┐ │ Hardware automatically: │ │ 1. Detects privilege change: Ring 3 → Ring 0 │ │ 2. Gets Ring 0 stack from current TSS: │ │ SS0 = 0x0008, SP0 = 0x7C00 │ │ 3. Switches to Ring 0 stack: │ │ SS = 0x0008, SP = 0x7C00 │ │ 4. Pushes Ring 3 context onto Ring 0 stack: │ │ - Push old SS (0x0010) │ │ - Push old SP (0x7FF0) │ │ - Push FLAGS │ │ - Push CS │ │ - Push IP │ │ 5. Loads interrupt handler address │ └─────────────────────────────────────────────────────────────┘ │ ▼ ┌────────────────────────────────────────────────────────────┐ │ Now Running in Ring 0: │ │ SS = 0x0008 (kernel data segment) │ │ SP = 0x7BF6 (adjusted after pushes) │ │ CPL = 0 (Ring 0) │ │ │ │ Ring 0 stack now contains: │ │ [SP+12]: Old SS (0x0010) │ │ [SP+10]: Old SP (0x7FF0) │ │ [SP+8]: Old FLAGS │ │ [SP+6]: Old CS │ │ [SP+4]: Old IP │ │ [SP+2]: (space for kernel use) │ │ [SP+0]: (current stack top) │ └────────────────────────────────────────────────────────────┘ Ring 1 and Ring 2 Stacks Ring Usage in Practice: ┌─────────────────────────────────────────────────────────────┐ │ Ring 0: Operating System Kernel │ │ • SS0/SP0: Most critical system operations │ │ • Memory management, process switching │ │ • Hardware interrupt handlers │ ├─────────────────────────────────────────────────────────────┤ │ Ring 1: Device Drivers (Rarely Used) │ │ • SS1/SP1: Device driver code │ │ • Some operating systems use this for drivers │ │ • Most modern systems use Ring 0 for drivers │ ├─────────────────────────────────────────────────────────────┤ │ Ring 2: System Services (Rarely Used) │ │ • SS2/SP2: System service layer │ │ • Most systems jump directly from Ring 3 to Ring 0 │ │ • Some experimental OS designs used this │ ├─────────────────────────────────────────────────────────────┤ │ Ring 3: User Applications │ │ • SS/SP: Normal application stack │ │ • Regular program execution │ │ • Cannot directly access lower rings │ └─────────────────────────────────────────────────────────────┘ Typical Stack Usage: Most 80286 systems only used Ring 0 and Ring 3: - SS0/SP0: Kernel stack - SS1/SP1: Usually 0 (unused) - SS2/SP2: Usually 0 (unused) - SS/SP: User application stack When user program makes system call:\nHardware saves user context on kernel stack (SS0:SP0) Kernel operations use kernel stack space When returning, hardware restores user context User program continues with user stack (SS:SP) Why Each Program Gets its own Kernel Stack Even though Kernel Code is Common for all? If there was only one kernel stack for the entire OS, here’s what would happen:\nSingle Global Kernel Stack Problem: ┌─────────────────────────────────────────────────────────────┐ │ Task A makes system call: │ │ ┌─────────────────────────────────────────────────────────┐ │ │ │ Global Kernel Stack: │ │ │ │ [Task A's saved context] │ │ │ │ [Kernel local variables for Task A] │ │ │ │ [System call parameters] │ │ │ └─────────────────────────────────────────────────────────┘ │ │ │ │ Timer interrupt occurs → Task Switch to Task B: │ │ ❌ Task A's kernel context still on global stack! │ │ │ │ Task B makes system call: │ │ ┌─────────────────────────────────────────────────────────┐ │ │ │ Global Kernel Stack (CORRUPTED): │ │ │ │ [Task A's saved context] ← Still there! │ | │ │ [Task A's kernel variables] ← Still there! │ | │ │ [Task B's saved context] ← New data overwrites! │ │ │ │ [Task B's kernel variables] │ │ │ └─────────────────────────────────────────────────────────┘ │ │ │ │ When Task A resumes: │ │ ❌ Its kernel context is corrupted │ │ ❌ System crash or data corruption │ └─────────────────────────────────────────────────────────────┘ Why Each Task Needs Its Own Kernel Stack Each task gets its own kernel stack because:\nTask can be preempted while in kernel mode Kernel context must be preserved per task Multiple tasks can have pending system calls Recursion and nested operations Shared Kernel Segment, Separate Stack Areas The kernel memory segment is shared, but each task gets its own stack area within that segment:\nKernel Memory Layout: ┌────────────────────────────────────────────────────────────┐ │ Kernel Data Segment (Selector 0x0008) │ │ Base Address: 0x100000 │ ├────────────────────────────────────────────────────────────┤ │ 0x100000: Kernel Code │ │ 0x110000: Kernel Global Data │ │ 0x120000: Kernel Heap │ │ 0x130000: ┌─────────────────────────────────────────────┐ │ │ │ Task A Kernel Stack │ │ │ 0x131000: │ ← Task A's SS0:SP0 = 0x0008:0x31000 │ │ │ └─────────────────────────────────────────────┘ │ │ 0x131000: ┌─────────────────────────────────────────────┐ │ │ │ Task B Kernel Stack │ │ │ 0x132000: │ ← Task B's SS0:SP0 = 0x0008:0x32000 │ │ │ └────────────────────────────────────────-────┘ │ │ 0x132000: ┌─────────────────────────────────────────────┐ │ │ │ Task C Kernel Stack │ │ │ 0x133000: │ ← Task C's SS0:SP0 = 0x0008:0x33000 │ │ │ └-────────────────────────────────────────────┘ │ │ 0x140000: Other Kernel Data │ └────────────────────────────────────────────────────────────┘ Key Point: Same SS0 (0x0008), Different SP0 values TSS Stack Pointer Management Task Creation Process: ┌─────────────────────────────────────────────────────────────┐ │ When OS creates new task: │ │ │ │ 1. Allocate kernel stack space: │ │ kernel_stack_base = allocate_kernel_stack() │ │ // Returns something like 0x31000 │ │ │ │ 2. Set up TSS: │ │ task_tss.SS0 = KERNEL_DATA_SELECTOR // 0x0008 │ │ task_tss.SP0 = kernel_stack_base // 0x31000 │ │ │ │ 3. When task makes system call: │ │ Hardware automatically switches to SS0:SP0 │ │ Now using this task's private kernel stack area │ │ │ │ 4. When task switch occurs: │ │ Each task's kernel stack remains intact │ │ Next task uses its own SS0:SP0 values │ └─────────────────────────────────────────────────────────────┘ Real-World Example: System Call with Task Switch Scenario: Task A calls file read, gets blocked, Task B runs Step 1: Task A makes system call ┌─────────────────────────────────────────────────────────────┐ │ Task A (Ring 3): INT 21h ; Read file │ │ │ │ Hardware switches to Task A's kernel stack: │ │ SS = 0x0008, SP = 0x31000 (Task A's kernel stack) │ │ │ │ Task A's Kernel Stack (0x31000): │ │ [Task A's user SS:SP] │ │ [Task A's user FLAGS] │ │ [Task A's user CS:IP] │ │ [Kernel local variables for file operation] │ │ [File system state] │ └─────────────────────────────────────────────────────────────┘ Step 2: File not ready, Task A blocks ┌─────────────────────────────────────────────────────────────┐ │ Kernel: File not available, block Task A │ │ │ │ Kernel performs task switch to Task B: │ │ JMP task_b_selector │ │ │ │ Hardware saves current state to Task A's TSS: │ │ - Current SS (0x0008) → Task A TSS │ │ - Current SP (0x30F80) → Task A TSS ← Note: changed! │ │ - All registers → Task A TSS │ │ │ │ Hardware loads Task B's state: │ │ - SS = Task B's user SS │ │ - SP = Task B's user SP │ │ - SS0 = 0x0008, SP0 = 0x32000 ← Task B's kernel stack │ └─────────────────────────────────────────────────────────────┘ Step 3: Task B runs and makes system call ┌─────────────────────────────────────────────────────────────┐ │ Task B (Ring 3): INT 10h ; Video operation │ │ │ │ Hardware switches to Task B's kernel stack: │ │ SS = 0x0008, SP = 0x32000 (Task B's kernel stack) │ │ │ │ Memory State: │ │ Task A's Kernel Stack (0x31000): [Preserved file operation] │ │ Task B's Kernel Stack (0x32000): [New video operation] │ │ │ │ Both stacks coexist safely! │ └─────────────────────────────────────────────────────────────┘ Step 4: Task A resumes later ┌─────────────────────────────────────────────────────────────┐ │ File becomes available, switch back to Task A: │ │ JMP task_a_selector │ │ │ │ Hardware loads Task A's state from TSS: │ │ - SS = 0x0008, SP = 0x30F80 ← Back to Task A kernel stack │ │ │ │ Task A's kernel stack is exactly as it was left: │ │ [Task A's user context] │ │ [File operation state] ← Still there! │ │ [Kernel variables] ← All preserved! │ │ │ │ Kernel completes file operation and returns to user │ └─────────────────────────────────────────────────────────────┘ Why This Design Is Necessary Fundamental Requirements\nReentrancy: Multiple tasks can be “inside” the kernel simultaneously Preemption: Tasks can be switched even while in kernel mode State Preservation: Each task’s kernel context must survive task switches Isolation: One task’s kernel operations can’t interfere with another’s Alternative Approaches (Used in Some Systems) Alternative 1: Non-preemptive Kernel ┌─────────────────────────────────────────────────────────────┐ │ • Only one task in kernel at a time │ │ • Disable task switching during system calls │ │ • Simpler: can use single kernel stack │ │ • Problem: Poor responsiveness, no true multitasking │ └─────────────────────────────────────────────────────────────┘ Alternative 2: Kernel Threads (Modern Approach) ┌─────────────────────────────────────────────────────────────┐ │ • Separate kernel thread handles each system call │ │ • User task blocks, kernel thread continues │ │ • More complex but better scalability │ │ • Used in modern operating systems │ └─────────────────────────────────────────────────────────────┘ The Stack Collision Problem How Stack Collision Occurs\nStack Growth Problem: ┌─────────────────────────────────────────────────────────────┐ │ Normal State: │ │ 0x130000: ┌────────────────────────────────────────── ───┐ │ │ │ Task A Kernel Stack │ │ │ │ [Some data] │ │ │ │ [Some data] │ │ │ 0x130800: │ ← Current SP0 (stack grows down) │ │ │ │ [Free space] │ │ │ 0x131000: └─────────────────────────────────────────────┘ │ │ 0x131000: ┌──────────────────────────────────────────── ─┐ │ │ │ Task B Kernel Stack │ │ │ 0x131800: │ ← Current SP0 │ │ │ │ [Free space] │ │ │ 0x132000: └─────────────────────────────────────────────┘ │ └─────────────────────────────────────────────────────────────┘ Stack Overflow Scenario: ┌─────────────────────────────────────────────────────────────┐ │ Task A makes deep system call with many nested functions: │ │ 0x130000: ┌───────────────────────────────────────────── ┐ │ │ │ Task A Kernel Stack │ │ │ │ [Deep call stack] │ │ │ │ [Local variables] │ │ │ │ [More function calls] │ │ │ │ [Even more data] │ │ │ 0x130F00: │ ← SP0 approaching limit │ │ │ │ [Critical: Almost full!] │ │ │ 0x131000: └─────────────────────────────────────────────┘ │ │ 0x131000: ┌─────────────────────────────────────────── ──┐ │ │ │ Task B Kernel Stack ← CORRUPTED! │ │ │ │ [Task A overflow data] ← Wrong task data! │ │ │ 0x131800: │ ← Task B's SP0 │ │ │ 0x132000: └─────────────────────────────────────────────┘ │ │ │ │ Result: Task A corrupts Task B's kernel stack │ │ System crash, data corruption, security breach │ └─────────────────────────────────────────────────────────────┘ Real-World Solutions 1. Stack Size Planning and Limits\nConservative Stack Allocation: ┌─────────────────────────────────────────────────────────────┐ │ Better Layout with Larger Gaps: │ ├─────────────────────────────────────────────────────────────┤ │ 0x130000: ┌─────────────────────────────────────────────┐ │ │ │ Task A Kernel Stack (8KB) │ │ │ 0x132000: └─────────────────────────────────────────────┘ │ │ 0x132000: ┌─────────────────────────────────────────────┐ │ │ │ Task B Kernel Stack (8KB) │ │ │ 0x134000: └─────────────────────────────────────────────┘ │ │ 0x134000: ┌──────────────────────────────────────────-──┐ │ │ │ Task C Kernel Stack (8KB) │ │ │ 0x136000: └─────────────────────────────────────────────┘ │ │ │ │ Advantages: │ │ ✅ Larger stacks reduce overflow risk │ │ ✅ Clear boundaries │ │ ❌ Wastes memory if stacks are small │ └─────────────────────────────────────────────────────────────┘ 2. Guard Pages (Modern Approach)\nStack with Guard Pages: ┌─────────────────────────────────────────────────────────────┐ │ 0x130000: ┌───────────────────────────────────────--────┐ │ │ │ Task A Kernel Stack (4KB) │ │ │ 0x131000: └─────────────────────────────────────────────┘ │ │ 0x131000: ┌────────────────────────────────────────--───┐ │ │ │ GUARD PAGE (unmapped/protected) │ │ │ 0x132000: └─────────────────────────────────────────────┘ │ │ 0x132000: ┌───────────────────────────────────────-─────┐ │ │ │ Task B Kernel Stack (4KB) │ │ │ 0x133000: └─────────────────────────────────────────────┘ │ │ │ │ How it works: │ │ • Guard page has no memory mapped │ │ • Stack overflow triggers page fault │ │ • Kernel can detect and handle gracefully │ │ • Kill offending task instead of corrupting memory │ └─────────────────────────────────────────────────────────────┘ 3. Stack Bounds Checking\n; Kernel stack overflow detection check_stack_overflow: mov ax, sp ; Get current stack pointer cmp ax, stack_limit ; Compare with minimum allowed jb stack_overflow_handler ; Jump if below limit ret stack_overflow_handler: ; Emergency handling: ; 1. Log the error ; 2. Kill the current task ; 3. Switch to a safe task ; 4. Prevent system crash 4. Dynamic Stack Expansion (Advanced)\nExpandable Stacks: ┌─────────────────────────────────────────────────────────────┐ │ Initial Allocation (Small): │ │ 0x130000: ┌─────────────────────────────────────────────┐ │ │ │ Task A Initial Stack (1KB) │ │ │ 0x130400: └─────────────────────────────────────────────┘ │ │ │ Expansion Area (monitored) │ │ │ 0x131000: ┌─────────────────────────────────────────────┐ │ │ │ Task B Initial Stack (1KB) │ │ │ 0x131400: └─────────────────────────────────────────────┘ │ │ │ │ On Near-Overflow: │ │ • Kernel detects stack approaching limit │ │ • Allocates more space if available │ │ • Updates stack boundaries │ │ • Continues operation │ └─────────────────────────────────────────────────────────────┘ What 80286 Systems Actually Did Typical 80286 Approach: ┌────────────────────────────────────────────────────────────┐ │ Conservative Fixed Allocation: │ │ │ │ 1. Large Fixed Stack Sizes: │ │ • Each task: 4KB-8KB kernel stack │ │ • Over-provision to avoid overflow │ │ • Waste memory but ensure safety │ │ │ │ 2. Task Limits: │ │ • Limit number of concurrent tasks │ │ • Reduce memory pressure │ │ • Simpler management │ │ │ │ 3. Programming Discipline: │ │ • Avoid deep recursion in kernel │ │ • Minimize local variables │ │ • Use heap for large data structures │ │ │ │ 4. System Monitoring: │ │ • Debug builds check stack usage │ │ • Runtime stack depth monitoring │ │ • Early warning systems │ └────────────────────────────────────────────────────────────┘ Example: OS/2 Approach OS/2 Stack Management: ┌─────────────────────────────────────────────────────────────┐ │ Thread Creation: │ │ • Default kernel stack: 8KB per thread │ │ • Configurable stack sizes │ │ • Stack committed on demand │ │ │ │ Stack Layout: │ │ ┌─────────────────────────────────────────────────────────┐ │ │ │ Thread 1: 8KB kernel stack │ │ │ │ Thread 2: 8KB kernel stack │ │ │ │ Thread 3: 8KB kernel stack │ │ │ │ (Large gaps to prevent collision) │ │ │ └─────────────────────────────────────────────────────────┘ │ │ │ │ Protection: │ │ • Memory manager tracks allocations │ │ • Stack overflow detected by memory manager │ │ • Graceful task termination instead of corruption │ └─────────────────────────────────────────────────────────────┘ How Modern Systems Handle This Modern Approach (Linux/Windows): ┌─────────────────────────────────────────────────────────────┐ │ Virtual Memory + Guard Pages: │ │ │ │ Each process/thread gets: │ │ • Virtual address space │ │ • Guard pages at stack boundaries │ │ • Page fault handling for overflow │ │ • Dynamic expansion up to limits │ │ │ │ Benefits: │ │ ✅ No memory waste │ │ ✅ Automatic protection │ │ ✅ Scales to thousands of threads │ │ ✅ Hardware-assisted detection │ │ │ │ 80286 Limitations: │ │ ❌ No virtual memory/paging │ │ ❌ Limited memory management │ │ ❌ Must use simpler approaches │ └─────────────────────────────────────────────────────────────┘ Previous TSS Link The Previous TSS Link supports task calling chains - when one task calls another task (not just jumps to it).\nTask Calling vs Task Jumping: Task Jump (JMP): Task A ──JMP──→ Task B │ └─ Task A stops, Task B runs No way to return to Task A Task Call (CALL): Task A ──CALL──→ Task B ──IRET──→ Task A │ │ └─ Task A suspended ──────┘ Task B can return to Task A How Previous Task Link Works Example Task Calling Chain: Step 1: Main Program calls Print Service ┌─────────────────────────────────────────────────────────────┐ │ Main Program TSS (Selector 0x0030) │ │ Previous Link: 0x0000 (no caller) │ │ CALL 0x0038 ; Call Print Service Task │ └─────────────────────────────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────┐ │ Print Service TSS (Selector 0x0038) │ │ Previous Link: 0x0030 ← Points back to Main Program │ │ CALL 0x0040 ; Call File I/O Task │ └─────────────────────────────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────┐ │ File I/O TSS (Selector 0x0040) │ │ Previous Link: 0x0038 ← Points back to Print Service │ │ IRET ; Return to previous task │ └─────────────────────────────────────────────────────────────┘ When File I/O executes IRET: 1. CPU reads Previous Link (0x0038) 2. Switches back to Print Service TSS 3. Print Service continues where it left off When Print Service executes IRET: 1. CPU reads Previous Link (0x0030) 2. Switches back to Main Program TSS 3. Main Program continues after the CALL Hardware Behavior CALL task_selector behavior: 1. Save current state to current TSS 2. Set target TSS Previous Link = current TSS selector 3. Switch to target task 4. Target task can later use IRET to return JMP task_selector behavior: 1. Save current state to current TSS 2. Target TSS Previous Link unchanged (usually 0) 3. Switch to target task 4. No automatic return mechanism TSS Benefits and Limitations Advantages of Hardware Task Switching 1. Atomic Operation\nComplete task switch in single instruction Cannot be interrupted midway Guaranteed consistent state 2. Performance\nExtremely fast: ~17-34 clock cycles No manual register save/restore needed Hardware optimized 3. Reliability\nCannot forget to save registers Hardware enforced privilege management Automatic stack switching 4. Security\nMemory isolation through LDT switching Privilege level enforcement Protected task linkage Limitations and Problems 1. Memory Overhead\nEach task requires: - 44+ bytes for TSS - 8 bytes for TSS descriptor in GDT - Separate stacks for each privilege level - Private LDT (optional but recommended) For 100 tasks: ~5KB just for task management\n2. GDT Size Limitations\nGDT maximum size: 65536 bytes Each TSS descriptor: 8 bytes Maximum tasks: ~8000 (practical limit much lower) 3. Inflexibility\n- Fixed TSS structure - Cannot customize task switch behavior - All-or-nothing: must save ALL registers - Cannot optimize for specific use cases 4. Scalability Issues\nModern systems with thousands of threads: - Would need thousands of TSS structures - GDT would become enormous - Memory fragmentation problems Evolution Beyond 80286 Why Modern Systems Don’t Use Hardware Task Switching\nModern Software Task Switching: ┌─────────────────────────────────────────────────────────────┐ │ Advantages: │ │ ✅ Flexible task structure │ │ ✅ Can save only necessary registers │ │ ✅ Custom scheduling algorithms │ │ ✅ Supports unlimited tasks │ │ ✅ More efficient memory usage │ │ ✅ Better cache performance │ │ │ │ Trade-offs: │ │ ❌ More complex kernel code │ │ ❌ Slightly slower (but caches help) │ │ ❌ Must be carefully implemented │ └─────────────────────────────────────────────────────────────┘ Legacy of TSS Even though modern x86 systems don’t use hardware task switching for multitasking, the TSS remains important:\nOne TSS per CPU for privilege level stack management System call stack switching still uses TSS stack pointers Interrupt handling relies on TS The Memory Management Unit (MMU) The 80286 was the first x86 processor to introduce an MMU (Memory Management Unit), but it was a simpler form than what we consider a “full” MMU today. The MMU in the 80286 is a hardware component integrated into the CPU chip itself. THe main purpose of MMU is to translate virtual addresses into physical addresses, along with checking bounds, enforcing privileges, etc.\nKey MMU Functions Introduced by 80286 1. Hardware Address Translation ; 8086 - Software calculation: ; Physical = (DS × 16) + SI ; 80286 - Hardware MMU translation: MOV DS, 0x0008 ; Load selector (points to descriptor) MOV AL, [SI] ; MMU automatically: ; 1. Looks up descriptor for selector 0x0008 ; 2. Checks permissions and bounds ; 3. Translates to physical address 2. Memory Protection Descriptor Access Rights (enforced by MMU): ┌─┬─-─┬─┬─┬-─┬─-┬─┐ │P│DPL│S│E│DC│RW│A│ ← MMU checks these bits └─┴─-─┴─┴─┴─-┴-─┴─┘ │ │ │ │ │ │ │ │ │ │ │ │ │ └─ Accessed (set by MMU) │ │ │ │ │ └──── Read/Write permission │ │ │ │ └─────── Direction/Conforming │ │ │ └───────── Executable bit │ │ └─────────── Descriptor type │ └────────────── Privilege level (0-3) └──────────────── Present bit MMU generates protection fault if access violates these rules 3. Bounds Checking Every memory access checked by MMU: ┌─────────────────────────────────────────┐ │ Descriptor Limit = 0x7FFF (32KB) │ │ Offset = 0x1234 │ │ MMU Check: 0x1234 ≤ 0x7FFF? ✓ Allow │ │ │ │ Offset = 0x9000 │ │ MMU Check: 0x9000 ≤ 0x7FFF? ✗ Fault │ └─────────────────────────────────────────┘ 80286 MMU Components 1. Segment Register Cache (Hidden Descriptor Cache) What Would Happen Without Segment Register Cache Every Memory Access Without Cache: ┌─────────────────────────────────────────────────────────────┐ │ Program executes: MOV AL, [DS:0x1234] │ │ │ │ Without caching, MMU would need to: │ │ 1. Read DS selector: 0x0010 │ │ 2. Extract index: 2 (from bits 15-3) │ │ 3. Calculate GDT address: GDT_base + (2 × 8) │ │ 4. Read 8 bytes from memory (descriptor) │ ← Memory access #1 │ 5. Extract base address from descriptor │ │ 6. Add offset: base + 0x1234 │ │ 7. Finally access target memory │ ← Memory access #2 │ │ │ Result: Every memory access requires TWO memory reads! │ │ Performance: 50% of memory bandwidth wasted on translation │ └─────────────────────────────────────────────────────────────┘ How Each Segment Register Actually Works Complete Segment Register Structure: ┌─────────────────────────────────────────────────────────────┐ │ DS Register │ ├─────────────────────────────────────────────────────────────┤ │ Visible Part (16 bits) - What programmer sees: │ │ ┌─────────────────────────────────────────────────────────┐ │ │ │ Selector: 0x0010 │ │ │ └─────────────────────────────────────────────────────────┘ │ ├─────────────────────────────────────────────────────────────┤ │ Hidden Cache (64 bits) - Hardware only: │ │ ┌─────────────────┬─────────────┬─────────────────────────┐ │ │ │ Base Address │ Limit │ Access Rights │ │ │ │ 0x00200000 │ 0xFFFF │ Ring 3, Read/Write │ │ │ │ (Physical addr) │ (Segment sz)│ (Permissions) │ │ │ └─────────────────┴─────────────┴─────────────────────────┘ │ ├─────────────────────────────────────────────────────────────┤ │ Valid Bit: 1 (cache contains valid data) │ └─────────────────────────────────────────────────────────────┘ Instead of caching all GDT/LDT entries at MMU level, each segment register caches only one GDT/LDT entry - the one it currently points to:\nIndividual Segment Register Caches: ┌─────────────────────────────────────────────────────────────┐ │ CS Register: │ │ ┌─────────────────────────────────────────────────────────┐ │ │ │ Visible: 0x0008 (selector) │ │ │ │ Hidden: [Base: 0x100000, Limit: 0xFFFF, Access: R/X] │ │ │ └─────────────────────────────────────────────────────────┘ │ ├─────────────────────────────────────────────────────────────┤ │ DS Register: │ │ ┌─────────────────────────────────────────────────────────┐ │ │ │ Visible: 0x0010 (selector) │ │ │ │ Hidden: [Base: 0x200000, Limit: 0xFFFF, Access: R/W] │ │ │ └─────────────────────────────────────────────────────────┘ │ ├─────────────────────────────────────────────────────────────┤ │ ES Register: │ │ ┌─────────────────────────────────────────────────────────┐ │ │ │ Visible: 0x0018 (selector) │ │ │ │ Hidden: [Base: 0x300000, Limit: 0x7FFF, Access: R/W] │ │ │ └─────────────────────────────────────────────────────────┘ │ ├─────────────────────────────────────────────────────────────┤ │ SS Register: │ │ ┌─────────────────────────────────────────────────────────┐ │ │ │ Visible: 0x0020 (selector) │ │ │ │ Hidden: [Base: 0x400000, Limit: 0x1FFF, Access: R/W] │ │ │ └─────────────────────────────────────────────────────────┘ │ └─────────────────────────────────────────────────────────────┘ Each register caches ONE descriptor from GDT/LDT Cache Loading Process When Segment Register Is Loaded: ┌─────────────────────────────────────────────────────────────┐ │ Program executes: MOV DS, AX (AX = 0x0010) │ │ │ │ Hardware automatically: │ │ 1. Store 0x0010 in DS visible part │ │ 2. Extract index: 2 │ │ 3. Calculate descriptor address: GDT_base + 16 │ │ 4. Read descriptor from memory (8 bytes) │ │ 5. Parse descriptor into components: │ │ - Base = 0x00200000 │ │ - Limit = 0xFFFF │ │ - Access = Ring 3, Read/Write │ │ 6. Store in DS hidden cache │ │ 7. Set valid bit = 1 │ │ │ │ This happens ONCE when segment register is loaded │ └─────────────────────────────────────────────────────────────┘ Fast Address Translation with Cache Fast Memory Access Using Cache: ┌─────────────────────────────────────────────────────────────┐ │ Program executes: MOV AL, [DS:0x1234] │ │ │ │ MMU hardware: │ │ 1. Check DS cache valid bit: 1 ✓ │ │ 2. Get base from DS cache: 0x00200000 │ │ 3. Get limit from DS cache: 0xFFFF │ │ 4. Check bounds: 0x1234 ≤ 0xFFFF ✓ │ │ 5. Calculate address: 0x00200000 + 0x1234 = 0x00201234 │ │ 6. Access memory at 0x00201234 │ │ │ │ Total: ONE memory access (the actual data) │ │ No GDT lookup needed! │ └─────────────────────────────────────────────────────────────┘ Cache Invalidation and Management Cache Invalidation Scenarios: ┌─────────────────────────────────────────────────────────────┐ │ 1. Segment Register Reload: │ │ MOV DS, AX ; New selector → invalidate DS cache │ │ │ │ 2. Task Switch: │ │ JMP task_selector ; All caches invalidated │ │ │ │ 3. GDT/LDT Reload: │ │ LGDT [gdt_desc] ; All caches invalidated │ │ LLDT selector ; All LDT-based caches invalidated │ │ │ │ 4. Descriptor Modification: │ │ If OS modifies GDT/LDT in memory │ │ Must manually invalidate affected caches │ └─────────────────────────────────────────────────────────────┘ What the 80286 MMU Provided Segmentation-Based Memory Management The 80286’s MMU implemented:\nAddress translation via descriptor tables (GDT/LDT) Memory protection with privilege levels (rings 0-3) Bounds checking to prevent segment overruns Access control (read/write/execute permissions) What 80286 MMU Lacked No Virtual Memory All segments had to exist in physical memory No demand paging or swapping to disk No virtual address spaces larger than physical memory No Page-Level Protection Segment-level only - coarse-grained protection Cannot protect individual pages within segments Limited memory layout flexibility No Address Space Isolation Shared physical address space among all tasks Tasks could potentially access each other’s memory if descriptors allowed it No true virtual memory isolation Historical Significance The 80286 MMU was revolutionary for its time because it:\nIntroduced Hardware Memory Protection: First x86 processor with privilege levels Hardware-enforced protection (couldn’t be bypassed by software) Foundation for modern operating systems Enabled Multitasking: Task isolation through separate descriptor tables Controlled access to system resources Protection from application crashes Set Architecture Foundation: Descriptor table concept carried forward to 80386 Privilege level system still used today Segmentation principles (though largely superseded by paging) While the 80286’s MMU was simpler than modern MMUs, it represented the crucial first step from the 8086’s “wild west” of direct memory access to the protected, managed memory systems we use today. The 80386 would later add paging to create the “full” MMU architecture that became the standard for modern computing.\nRing Level Privileges in 80286 One of the most revolutionary features introduced by the Intel 80286 was its ring-based privilege system - a hardware-enforced security mechanism that fundamentally changed how computer systems protect themselves from malicious or buggy software. Before the 80286, programs had unrestricted access to all system resources, meaning a single misbehaving application could crash the entire computer or corrupt critical system data.\nThe 80286’s ring system solved this by creating four distinct privilege levels (Rings 0-3), arranged in a hierarchical structure where each ring has specific permissions and access rights. Think of it like security clearance levels in a government building - higher clearance (lower ring numbers) grants access to more sensitive areas, while lower clearance (higher ring numbers) restricts what you can access.\nThe 80286’s ring system introduced hardware-enforced separation between different types of code, ensuring that:\nUser applications (Ring 3) could only access their own resources Operating system code (Ring 0) maintained exclusive control over critical hardware Device drivers (Ring 1) had controlled access to specific hardware components System services (Ring 2) provided a middle layer for specialized operations Modern CPU’s removed ring 1 and ring 2 as they are not used by any applications because of complex privilege transitions.\nRing 0: The Kernel Domain Ring 0 represents the most trusted code in the system - the operating system kernel itself. Capabilities:\nDirect hardware access: Can manipulate any I/O port, memory location, or CPU register Memory management: Controls virtual memory, page tables, and segment descriptors Interrupt handling: Manages hardware interrupts and system exceptions Task switching: Can switch between different processes and threads Protection control: Can modify GDT, LDT, and other protection structures What runs in Ring 0:\nTypical Ring 0 Components: ┌─────────────────────────────────────────────────────────────┐ │ • Kernel core (scheduler, memory manager) │ │ • Device drivers (disk, network, graphics) │ │ • Interrupt service routines │ │ • System call handlers │ │ • Hardware abstraction layer │ └─────────────────────────────────────────────────────────────┘ Example Ring 0 Operations:\n; Ring 0 can directly manipulate hardware OUT 0x3F8, AL ; Write to serial port CLI ; Disable interrupts STI ; Enable interrupts LGDT [gdt_desc] ; Load new GDT Ring 1: Device Driver Territory Ring 1 was designed for device drivers and hardware abstraction layers that need some hardware access but shouldn’t have full kernel privileges.\nIntended capabilities:\nLimited hardware access: Can access specific I/O ports assigned to devices Kernel service calls: Can call Ring 0 services for memory allocation Device management: Direct control over assigned hardware devices Protected from user code: User programs cannot directly call Ring 1 code Why it’s rarely used:\nProblems with Ring 1: ┌─────────────────────────────────────────────────────────────┐ │ • Complex permission management │ │ • Performance overhead of privilege transitions │ │ • Difficult debugging across privilege boundaries │ │ • Limited benefits over Ring 0 drivers │ │ • Most hardware needs either full access or none │ └─────────────────────────────────────────────────────────────┘ Historical usage:\nEarly OS/2: Attempted to use Ring 1 for some device drivers Research systems: Academic projects exploring multi-level protection Embedded systems: Some real-time systems with strict separation requirements Ring 2: System Services Layer Ring 2 was envisioned as a middle layer for system services that needed more privilege than user applications but less than the kernel.\nIntended purposes:\nFile system services: Higher-level file operations Network protocol stacks: TCP/IP implementation Graphics subsystems: Advanced display management Database engines: System-level data management Why it failed in practice:\nRing 2 Challenges: ┌─────────────────────────────────────────────────────────────┐ │ • Unclear boundaries between Ring 1 and Ring 2 │ │ • Most services either needed full kernel access or none │ │ • Complex inter-ring communication protocols │ │ • Performance penalties for frequent ring transitions │ │ • Debugging and troubleshooting complexity │ └─────────────────────────────────────────────────────────────┘ Ring 3: User Application Space Ring 3 is where all user applications run - from simple utilities to complex programs like word processors and games.\nRestrictions:\nNo direct hardware access: Cannot use IN/OUT instructions No privileged instructions: Cannot modify system registers Limited memory access: Can only access memory explicitly allocated to the process No interrupt control: Cannot disable interrupts or modify interrupt vectors No system structure modification: Cannot change GDT, LDT, or page tables What Ring 3 can do:\nRing 3 Capabilities: ┌─────────────────────────────────────────────────────────────┐ │ • Access own allocated memory │ │ • Perform computational operations │ │ • Call system services via controlled interfaces │ │ • Communicate with other Ring 3 processes (if permitted) │ │ • Use standard library functions │ └─────────────────────────────────────────────────────────────┘ Privilege Enforcement Mechanisms Current Privilege Level (CPL) The Current Privilege Level determines what the processor can do at any given moment. It’s stored in the lowest 2 bits of the CS (Code Segment) register.\nCS Register Structure: ┌─────────────────────────────────────────────────────────---────┐ │ 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0 │ ├─────────────────────────────────────────────────────┬───┬───-──┤ │ Segment Index │TI │ CPL │ └─────────────────────────────────────────────────────┴───┴──-───┘ │ └─ Current Privilege Level (0-3) Level (0-3) CPL Examples:\nCPL = 0: Currently executing Ring 0 (kernel) code CPL = 3: Currently executing Ring 3 (user) code Descriptor Privilege Level (DPL) Every segment descriptor (GDT entries) contains a Descriptor Privilege Level that specifies what privilege level is required to access that segment.\nAccess Control Rule: CPL ≤ DPL (numerically) Examples: - CPL = 0, DPL = 2 → 0 ≤ 2 ✓ Access Allowed - CPL = 3, DPL = 0 → 3 ≤ 0 ✗ Access Denied - CPL = 1, DPL = 3 → 1 ≤ 3 ✓ Access Allowed Privilege Checking Process When code attempts to access a segment, the 80286 MMU performs automatic privilege checking:\nMemory Access Privilege Check: ┌─────────────────────────────────────────────────────────────┐ │ 1. Extract CPL from CS register │ │ 2. Load descriptor for target segment │ │ 3. Extract DPL from descriptor │ │ 4. Check: CPL ≤ DPL? │ │ - YES: Allow access │ │ - NO: Generate General Protection Fault (#GP) │ └─────────────────────────────────────────────────────────────┘ Privilege Transitions 1. System Calls: Ring 3 to Ring 0 User programs cannot directly call kernel functions. Instead, they use controlled entry points called system calls.\nSystem Call Process: ┌─────────────────────────────────────────────────────────────┐ │ User Program (Ring 3): │ │ INT 21h ; Software interrupt for DOS services │ │ │ │ Hardware automatically: │ │ 1. Save current state (CS:IP, FLAGS, SS:SP) │ │ 2. Look up interrupt handler in IDT │ │ 3. Check privilege level of handler │ │ 4. Switch to Ring 0 stack (from TSS) │ │ 5. Load Ring 0 code segment │ │ 6. Jump to interrupt handler │ │ │ │ Kernel Handler (Ring 0): │ │ ; Process the system call │ │ ; Perform privileged operations │ │ IRET ; Return to user program │ │ │ │ Hardware automatically: │ │ 1. Restore user state (CS:IP, FLAGS, SS:SP) │ │ 2. Switch back to Ring 3 stack │ │ 3. Continue user program execution │ └─────────────────────────────────────────────────────────────┘ 2. Call Gates: Controlled Ring Transitions Call gates provide a mechanism for controlled transitions between privilege levels without using interrupts.\nCall Gate Structure: ┌─────────────────────────────────────────────────────────────┐ │ • Target segment selector │ │ • Target offset within segment │ │ • Parameter count (for stack copying) │ │ • Access rights (privilege levels) │ └─────────────────────────────────────────────────────────────┘ Usage: CALL gate_selector ; Far call through call gate ; Hardware handles privilege transition 3. Interrupt and Trap Gates Interrupt gates and trap gates handle hardware interrupts and software exceptions while managing privilege transitions.\nInterrupt Handling: ┌─────────────────────────────────────────────────────────────┐ │ Hardware Interrupt (e.g., keyboard, timer): │ │ 1. Save current privilege level │ │ 2. Switch to Ring 0 (interrupt handlers run in Ring 0) │ │ 3. Execute interrupt service routine │ │ 4. Restore previous privilege level │ │ │ │ This allows Ring 3 programs to be interrupted safely │ │ without compromising system security │ └─────────────────────────────────────────────────────────────┘ How Does CPU/MMU Enforces the Privilege Check at Hardware Level? The CPU/MMU has no concept of “operating system” vs “application program.” It only understands:\nCurrent Privilege Level (CPL) Descriptor Privilege Levels (DPL) Access permissions based on these levels So CPU doesn’t know the difference between the Operating System’s code and a User Space program’s code. How does it know who should actually have higher level of privileges and who doesn’t?\nThe “First Mover Advantage” Principle 1. Bootstrap Sequence:\n1. CPU powers on in Real Mode (no protection) 2. BIOS/Bootloader runs (still no protection) 3. First OS code loads and runs (still no protection) 4. OS sets up GDT with itself as Ring 0 5. OS switches to Protected Mode 6. NOW protection is active - OS controls everything 2. OS Establishes Its Authority:\n// OS creates GDT during boot (while still unprotected) GDT[0] = NULL_DESCRIPTOR; GDT[1] = {base: 0, limit: 4GB, DPL: 0, type: CODE}; // OS code GDT[2] = {base: 0, limit: 4GB, DPL: 0, type: DATA}; // OS data GDT[3] = {base: 0, limit: 4GB, DPL: 3, type: CODE}; // User code GDT[4] = {base: 0, limit: 4GB, DPL: 3, type: DATA}; // User data // OS loads itself into Ring 0 CS = 0x08; // Ring 0 code segment // Now CPL = 0, and OS controls all privilege decisions But There’s a Catch - Memory Segmentation Isn’t Full Protection 80286 Segmentation Limitations:\nSame linear address space: All segments can point to the same memory No memory isolation: Ring 3 code can potentially read Ring 0 memory if descriptors allow it Descriptor-dependent: Protection Example Problem:\n// OS sets up segments (Ring 0 privilege required) GDT[1] = {base: 0x100000, limit: 64KB, DPL: 0}; // OS memory GDT[3] = {base: 0x100000, limit: 64KB, DPL: 3}; // User memory // Problem: Both point to SAME physical memory! // User can read OS memory through their own descriptor How 80286 Changed the CPU-OS Relationship Forever 8086 Era: OS as Optional Helper In the 8086 real mode world, the relationship between CPU and operating system was surprisingly casual:\nNo memory protection - any program could access any memory location No privilege levels - all code ran with identical hardware access Direct hardware control - programs could manipulate I/O ports, interrupts, and system resources directly OS was essentially a library - DOS functioned as a collection of utility functions that programs could call, but could easily bypass You could write a program that completely ignored DOS, accessed hardware directly, modified interrupt vectors, or even overwrote parts of DOS in memory. Running a program “with” or “without” an operating system made little architectural difference - the CPU imposed no restrictions.\n80286: The Partnership Revolution The 80286 introduced a radical concept: hardware features that required OS cooperation. Neither the CPU nor the OS could provide modern computing features alone - they had to work as partners.\nHardware Features Demanding OS Management: GDT/LDT setup - CPU provides descriptor table mechanism, but OS must create and manage the actual tables TSS management - CPU can switch tasks via hardware, but OS must set up Task State Segments for each process Privilege level enforcement - CPU enforces ring-based protection, but OS must define what gets what privileges Segment descriptors - CPU checks access rights, but OS must create proper access permissions and memory limits Protected mode switching - Complex initialization sequence requiring intimate OS-hardware coordination The New Partnership Model: Hardware provides MECHANISMS ↓ OS provides POLICIES ↓ CPU enforces what OS defines Why This Partnership Was Essential: 1. Memory Protection: CPU can only protect memory if OS properly sets up segment descriptors 2. Multitasking: TSS structure is meaningless without OS task scheduling to utilize it 3. Privilege Separation: Ring levels only work if OS correctly manages user/kernel boundaries 4. Resource Management: I/O permission bitmaps need OS policy to define task capabilities An address bus is a collection of wires (or electrical pathways) that carries memory addresses from the processor to memory and other components. Think of it as the “postal system” of the computer - when the CPU wants to read from or write to a specific location in memory, it sends that location’s address through the address bus. Each wire in the address bus represents one bit of the address. The CPU sets each wire to either high voltage (representing binary 1) or low voltage (representing binary 0) to form the complete binary address. ↩︎\n(Serial Ports) Communication ports for devices like modems, mice, or serial printers. Each COM port has a base I/O address (COM1 typically at 3F8h, COM2 at 2F8h, etc.). The BIOS Data Area stores these addresses so software knows where to find each serial port. ↩︎\n(Parallel Ports) “Line Printer” ports primarily used for parallel printers. LPT1 typically uses I/O address 378h. These were the standard way to connect printers before USB existed. The BIOS stores the base addresses of installed parallel ports. ↩︎\nWhether Shift, Ctrl, Alt, Caps Lock, Num Lock, or Scroll Lock are currently pressed or toggled. This is stored as bit flags in memory location 0040:0017h. ↩︎\nA circular buffer (usually 15-16 characters) that stores keystrokes when they’re typed faster than the program can process them. This prevents losing keystrokes during busy periods. ↩︎\nThis bitmap, usually set up by the operating system when a task is started, specifies individual ports to which the program should have access. The I/O bitmap is a bit array of port access permissions; if the program has permission to access a port, a “0” is stored at the corresponding bit index, and if the program does not have permission, a “1” is stored there. When a program issues an x86 I/O port instruction such as IN or OUT, the hardware will do an I/O privilege level (IOPL) check to see if the program has access to all I/O ports. If the Current Privilege Level (CPL) of the program is numerically greater than the I/O Privilege level (IOPL), the program does not have I/O port access to all ports. If the IOPL check fails, the CPU then consults the I/O bitmap to see if this specific port is allowed. It prevents malicious programs from accessing hardware directly by stopping user programs from interfering with system devices. ↩︎\n","wordCount":"12931","inLanguage":"en","datePublished":"2025-07-18T00:00:00Z","dateModified":"2025-07-18T00:00:00Z","author":{"@type":"Person","name":"Sanketh"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://sankethbk.github.io/blog/posts/cpu/2025-07-20-processor-modes/"},"publisher":{"@type":"Organization","name":"Sanketh's Blog","logo":{"@type":"ImageObject","url":"https://sankethbk.github.io/blog/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://sankethbk.github.io/blog/ accesskey=h title="Sanketh's Blog (Alt + H)">Sanketh's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Processor Modes in x86</h1><div class=post-meta><span title='2025-07-18 00:00:00 +0000 UTC'>July 18, 2025</span>&nbsp;·&nbsp;61 min&nbsp;·&nbsp;Sanketh&nbsp;|&nbsp;<a href=https://github.com/SankethBK/blog/edit/main/content/posts/cpu/2025-07-20-processor-modes.markdown rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#the-8086-processor aria-label="The 8086 Processor">The 8086 Processor</a><ul><li><a href=#a-brief-history aria-label="A Brief History">A Brief History</a><ul><li><a href=#why-20-bit-address-bus-in-the-8086 aria-label="Why 20-bit Address Bus in the 8086?">Why 20-bit Address Bus in the 8086?</a></li></ul></li><li><a href=#the-segmented-memory-model aria-label="The Segmented Memory Model">The Segmented Memory Model</a><ul><li><a href=#disadvantages-of-the-segmentation-model aria-label="Disadvantages of the Segmentation Model">Disadvantages of the Segmentation Model</a></li><li><a href=#the-real-mode aria-label="The Real Mode">The Real Mode</a><ul><li><a href=#contents-of-1mb-memory-layout-in-8086-real-mode aria-label="Contents of 1MB memory layout in 8086 real mode">Contents of 1MB memory layout in 8086 real mode</a><ul><li><a href=#key-memory-regions aria-label="Key Memory Regions">Key Memory Regions</a></li><li><a href=#why-this-layout aria-label="Why This Layout?">Why This Layout?</a></li></ul></li></ul></li></ul></li></ul></li><li><a href=#the-80286-and-protected-mode aria-label="The 80286 and protected mode">The 80286 and protected mode</a><ul><li><a href=#introduction-to-the-80286 aria-label="Introduction to the 80286">Introduction to the 80286</a></li><li><a href=#key-innovations-of-the-80286 aria-label="Key Innovations of the 80286">Key Innovations of the 80286</a><ul><li><a href=#16mb-address-space aria-label="16MB Address Space">16MB Address Space</a></li><li><a href=#hardware-memory-protection aria-label="Hardware Memory Protection">Hardware Memory Protection</a></li><li><a href=#virtual-memory-foundation aria-label="Virtual Memory Foundation">Virtual Memory Foundation</a></li></ul></li><li><a href=#addressing-24-bit-memory aria-label="Addressing 24-Bit Memory">Addressing 24-Bit Memory</a></li><li><a href=#the-virtual-memory aria-label="The Virtual Memory">The Virtual Memory</a><ul><li><a href=#simplified-programming-model-with-virtual-memory aria-label="Simplified Programming Model with Virtual Memory">Simplified Programming Model with Virtual Memory</a></li></ul></li><li><a href=#global-and-local-descriptor-tables-gdt-and-ldt aria-label="Global and Local Descriptor Tables (GDT and LDT)">Global and Local Descriptor Tables (GDT and LDT)</a><ul><li><a href=#what-are-descriptor-tables aria-label="What Are Descriptor Tables?">What Are Descriptor Tables?</a></li><li><a href=#the-basic-problem-they-solve aria-label="The Basic Problem They Solve">The Basic Problem They Solve</a></li><li><a href=#understanding-selectors aria-label="Understanding Selectors">Understanding Selectors</a></li><li><a href=#what-is-a-descriptor aria-label="What Is a Descriptor?">What Is a Descriptor?</a></li><li><a href=#flags-field-4-bits aria-label="Flags Field (4 bits)">Flags Field (4 bits)</a></li><li><a href=#global-descriptor-table-gdt aria-label="Global Descriptor Table (GDT)">Global Descriptor Table (GDT)</a><ul><li><a href=#gdt-structure-and-location aria-label="GDT Structure and Location">GDT Structure and Location</a></li><li><a href=#what-goes-in-the-gdt aria-label="What Goes in the GDT?">What Goes in the GDT?</a></li><li><a href=#example-gdt-layout aria-label="Example GDT Layout">Example GDT Layout</a></li></ul></li><li><a href=#local-descriptor-table-ldt aria-label="Local Descriptor Table (LDT)">Local Descriptor Table (LDT)</a><ul><li><a href=#key-differences-gdt-vs-ldt aria-label="Key Differences: GDT vs LDT">Key Differences: GDT vs LDT</a></li><li><a href=#how-ldts-work aria-label="How LDTs Work">How LDTs Work</a></li><li><a href=#ldt-entries aria-label="LDT Entries">LDT Entries</a></li></ul></li><li><a href=#what-are-gates aria-label="What Are Gates?">What Are Gates?</a><ul><li><a href=#types-of-gates-in-x86 aria-label="Types of Gates in x86:">Types of Gates in x86:</a></li></ul></li><li><a href=#gdtr-and-ldtr aria-label="GDTR and LDTR">GDTR and LDTR</a><ul><li><a href=#gdtr-global-descriptor-table-register aria-label="GDTR (Global Descriptor Table Register):">GDTR (Global Descriptor Table Register):</a></li><li><a href=#ldtr-local-descriptor-table-register aria-label="LDTR (Local Descriptor Table Register):">LDTR (Local Descriptor Table Register):</a></li><li><a href=#who-can-readwrite-into-gdtr-and-ldtr-registers aria-label="WHo can Read/Write into GDTR and LDTR registers?">WHo can Read/Write into GDTR and LDTR registers?</a></li><li><a href=#initial-setup-process aria-label="Initial Setup Process:">Initial Setup Process:</a></li><li><a href=#who-can-readwrite-gdt-and-ldt aria-label="Who Can Read/Write GDT and LDT?">Who Can Read/Write GDT and LDT?</a></li><li><a href=#post-80386-era aria-label="Post 80386 Era">Post 80386 Era</a></li></ul></li></ul></li><li><a href=#task-state-segment-tss aria-label="Task State Segment (TSS)">Task State Segment (TSS)</a><ul><li><a href=#tss-solution aria-label="TSS Solution:">TSS Solution:</a></li><li><a href=#tss-structure-and-layout aria-label="TSS Structure and Layout">TSS Structure and Layout</a></li><li><a href=#memory-layout-visualization aria-label="Memory Layout Visualization">Memory Layout Visualization</a></li><li><a href=#tss-descriptor-in-the-gdt aria-label="TSS Descriptor in the GDT">TSS Descriptor in the GDT</a></li><li><a href=#task-switching-process aria-label="Task Switching Process">Task Switching Process</a></li><li><a href=#privilege-level-stack-management aria-label="Privilege Level Stack Management">Privilege Level Stack Management</a><ul><li><a href=#why-multiple-stacks-are-needed aria-label="Why Multiple Stacks are Needed?">Why Multiple Stacks are Needed?</a></li><li><a href=#stack-pointer-sp-and-stack-segment-ss-explained aria-label="Stack Pointer (SP) and Stack Segment (SS) Explained">Stack Pointer (SP) and Stack Segment (SS) Explained</a></li><li><a href=#how-stack-switching-works aria-label="How Stack Switching Works?">How Stack Switching Works?</a></li><li><a href=#ring-1-and-ring-2-stacks aria-label="Ring 1 and Ring 2 Stacks">Ring 1 and Ring 2 Stacks</a></li><li><a href=#why-each-program-gets-its-own-kernel-stack-even-though-kernel-code-is-common-for-all aria-label="Why Each Program Gets its own Kernel Stack Even though Kernel Code is Common for all?">Why Each Program Gets its own Kernel Stack Even though Kernel Code is Common for all?</a></li><li><a href=#why-each-task-needs-its-own-kernel-stack aria-label="Why Each Task Needs Its Own Kernel Stack">Why Each Task Needs Its Own Kernel Stack</a></li><li><a href=#shared-kernel-segment-separate-stack-areas aria-label="Shared Kernel Segment, Separate Stack Areas">Shared Kernel Segment, Separate Stack Areas</a></li></ul></li><li><a href=#tss-stack-pointer-management aria-label="TSS Stack Pointer Management">TSS Stack Pointer Management</a><ul><li><a href=#real-world-example-system-call-with-task-switch aria-label="Real-World Example: System Call with Task Switch">Real-World Example: System Call with Task Switch</a></li><li><a href=#why-this-design-is-necessary aria-label="Why This Design Is Necessary">Why This Design Is Necessary</a></li><li><a href=#alternative-approaches-used-in-some-systems aria-label="Alternative Approaches (Used in Some Systems)">Alternative Approaches (Used in Some Systems)</a></li></ul></li><li><a href=#the-stack-collision-problem aria-label="The Stack Collision Problem">The Stack Collision Problem</a><ul><li><a href=#real-world-solutions aria-label="Real-World Solutions">Real-World Solutions</a></li><li><a href=#what-80286-systems-actually-did aria-label="What 80286 Systems Actually Did">What 80286 Systems Actually Did</a></li><li><a href=#example-os2-approach aria-label="Example: OS/2 Approach">Example: OS/2 Approach</a></li><li><a href=#how-modern-systems-handle-this aria-label="How Modern Systems Handle This">How Modern Systems Handle This</a></li></ul></li><li><a href=#previous-tss-link aria-label="Previous TSS Link">Previous TSS Link</a><ul><li><a href=#how-previous-task-link-works aria-label="How Previous Task Link Works">How Previous Task Link Works</a></li><li><a href=#hardware-behavior aria-label="Hardware Behavior">Hardware Behavior</a></li></ul></li><li><a href=#tss-benefits-and-limitations aria-label="TSS Benefits and Limitations">TSS Benefits and Limitations</a><ul><li><a href=#advantages-of-hardware-task-switching aria-label="Advantages of Hardware Task Switching">Advantages of Hardware Task Switching</a></li><li><a href=#limitations-and-problems aria-label="Limitations and Problems">Limitations and Problems</a></li><li><a href=#evolution-beyond-80286 aria-label="Evolution Beyond 80286">Evolution Beyond 80286</a></li><li><a href=#legacy-of-tss aria-label="Legacy of TSS">Legacy of TSS</a></li></ul></li></ul></li><li><a href=#the-memory-management-unit-mmu aria-label="The Memory Management Unit (MMU)">The Memory Management Unit (MMU)</a><ul><li><a href=#key-mmu-functions-introduced-by-80286 aria-label="Key MMU Functions Introduced by 80286">Key MMU Functions Introduced by 80286</a><ul><li><a href=#1-hardware-address-translation aria-label="1. Hardware Address Translation">1. Hardware Address Translation</a></li><li><a href=#2-memory-protection aria-label="2. Memory Protection">2. Memory Protection</a></li><li><a href=#3-bounds-checking aria-label="3. Bounds Checking">3. Bounds Checking</a></li></ul></li><li><a href=#80286-mmu-components aria-label="80286 MMU Components">80286 MMU Components</a><ul><li><a href=#1-segment-register-cache-hidden-descriptor-cache aria-label="1. Segment Register Cache (Hidden Descriptor Cache)">1. Segment Register Cache (Hidden Descriptor Cache)</a><ul><li><a href=#what-would-happen-without-segment-register-cache aria-label="What Would Happen Without Segment Register Cache">What Would Happen Without Segment Register Cache</a></li><li><a href=#how-each-segment-register-actually-works aria-label="How Each Segment Register Actually Works">How Each Segment Register Actually Works</a></li><li><a href=#cache-loading-process aria-label="Cache Loading Process">Cache Loading Process</a></li><li><a href=#fast-address-translation-with-cache aria-label="Fast Address Translation with Cache">Fast Address Translation with Cache</a></li><li><a href=#cache-invalidation-and-management aria-label="Cache Invalidation and Management">Cache Invalidation and Management</a></li></ul></li></ul></li><li><a href=#what-the-80286-mmu-provided aria-label="What the 80286 MMU Provided">What the 80286 MMU Provided</a></li><li><a href=#what-80286-mmu-lacked aria-label="What 80286 MMU Lacked">What 80286 MMU Lacked</a><ul><li><a href=#no-virtual-memory aria-label="No Virtual Memory">No Virtual Memory</a></li><li><a href=#no-page-level-protection aria-label="No Page-Level Protection">No Page-Level Protection</a></li><li><a href=#no-address-space-isolation aria-label="No Address Space Isolation">No Address Space Isolation</a></li></ul></li><li><a href=#historical-significance aria-label="Historical Significance">Historical Significance</a><ul><li><a href=#introduced-hardware-memory-protection aria-label="Introduced Hardware Memory Protection:">Introduced Hardware Memory Protection:</a></li><li><a href=#enabled-multitasking aria-label="Enabled Multitasking:">Enabled Multitasking:</a></li><li><a href=#set-architecture-foundation aria-label="Set Architecture Foundation:">Set Architecture Foundation:</a></li></ul></li></ul></li><li><a href=#ring-level-privileges-in-80286 aria-label="Ring Level Privileges in 80286">Ring Level Privileges in 80286</a><ul><li><a href=#ring-0-the-kernel-domain aria-label="Ring 0: The Kernel Domain">Ring 0: The Kernel Domain</a></li><li><a href=#ring-1-device-driver-territory aria-label="Ring 1: Device Driver Territory">Ring 1: Device Driver Territory</a></li><li><a href=#ring-2-system-services-layer aria-label="Ring 2: System Services Layer">Ring 2: System Services Layer</a></li><li><a href=#ring-3-user-application-space aria-label="Ring 3: User Application Space">Ring 3: User Application Space</a></li><li><a href=#privilege-enforcement-mechanisms aria-label="Privilege Enforcement Mechanisms">Privilege Enforcement Mechanisms</a><ul><li><a href=#current-privilege-level-cpl aria-label="Current Privilege Level (CPL)">Current Privilege Level (CPL)</a></li><li><a href=#descriptor-privilege-level-dpl aria-label="Descriptor Privilege Level (DPL)">Descriptor Privilege Level (DPL)</a></li><li><a href=#privilege-checking-process aria-label="Privilege Checking Process">Privilege Checking Process</a></li><li><a href=#privilege-transitions aria-label="Privilege Transitions">Privilege Transitions</a><ul><li><a href=#1-system-calls-ring-3-to-ring-0 aria-label="1. System Calls: Ring 3 to Ring 0">1. System Calls: Ring 3 to Ring 0</a></li><li><a href=#2-call-gates-controlled-ring-transitions aria-label="2. Call Gates: Controlled Ring Transitions">2. Call Gates: Controlled Ring Transitions</a></li><li><a href=#3-interrupt-and-trap-gates aria-label="3. Interrupt and Trap Gates">3. Interrupt and Trap Gates</a></li></ul></li><li><a href=#how-does-cpummu-enforces-the-privilege-check-at-hardware-level aria-label="How Does CPU/MMU Enforces the Privilege Check at Hardware Level?">How Does CPU/MMU Enforces the Privilege Check at Hardware Level?</a><ul><li><a href=#the-first-mover-advantage-principle aria-label="The &ldquo;First Mover Advantage&rdquo; Principle">The &ldquo;First Mover Advantage&rdquo; Principle</a></li><li><a href=#but-theres-a-catch---memory-segmentation-isnt-full-protection aria-label="But There&rsquo;s a Catch - Memory Segmentation Isn&rsquo;t Full Protection">But There&rsquo;s a Catch - Memory Segmentation Isn&rsquo;t Full Protection</a></li></ul></li></ul></li></ul></li><li><a href=#how-80286-changed-the-cpu-os-relationship-forever aria-label="How 80286 Changed the CPU-OS Relationship Forever">How 80286 Changed the CPU-OS Relationship Forever</a><ul><li><a href=#8086-era-os-as-optional-helper aria-label="8086 Era: OS as Optional Helper">8086 Era: OS as Optional Helper</a></li><li><a href=#80286-the-partnership-revolution aria-label="80286: The Partnership Revolution">80286: The Partnership Revolution</a><ul><li><a href=#hardware-features-demanding-os-management aria-label="Hardware Features Demanding OS Management:">Hardware Features Demanding OS Management:</a></li><li><a href=#the-new-partnership-model aria-label="The New Partnership Model:">The New Partnership Model:</a></li><li><a href=#why-this-partnership-was-essential aria-label="Why This Partnership Was Essential:">Why This Partnership Was Essential:</a></li></ul></li></ul></li></ul></li></ul></div></details></div><div class=post-content><h1 id=the-8086-processor>The 8086 Processor<a hidden class=anchor aria-hidden=true href=#the-8086-processor>#</a></h1><h2 id=a-brief-history>A Brief History<a hidden class=anchor aria-hidden=true href=#a-brief-history>#</a></h2><p>The Intel 8086, released in 1978, marked a pivotal moment in computing history as Intel&rsquo;s first 16-bit microprocessor. Designed by a team led by Stephen Morse, the 8086 was Intel&rsquo;s answer to the growing demand for more powerful processors that could handle larger programs and address more memory than the existing 8-bit chips of the era.</p><p>The processor introduced the x86 architecture that would become the foundation for decades of computing evolution. With its 16-bit registers and 20-bit address bus <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>, the 8086 could access up to 1 megabyte of memory—a massive improvement over the 64KB limitation of 8-bit processors. However, it retained backward compatibility concepts that would prove both beneficial and constraining for future generations.</p><h3 id=why-20-bit-address-bus-in-the-8086>Why 20-bit Address Bus in the 8086?<a hidden class=anchor aria-hidden=true href=#why-20-bit-address-bus-in-the-8086>#</a></h3><p>The 8086 used a 20-bit address bus, which was a deliberate design decision based on several factors:</p><ul><li><p><strong>Memory Capacity:</strong> With 20 address lines, the processor could address 2^20 = 1,048,576 locations, or exactly 1 megabyte of memory. In 1978, this was considered enormous - most computers had only 4KB to 64KB of memory.</p></li><li><p><strong>Economic Considerations:</strong> Adding more address lines would have increased the chip&rsquo;s pin count, making it more expensive to manufacture and requiring more expensive motherboards. Intel balanced capability with cost-effectiveness.</p></li></ul><h2 id=the-segmented-memory-model>The Segmented Memory Model<a hidden class=anchor aria-hidden=true href=#the-segmented-memory-model>#</a></h2><p>Intel&rsquo;s previous 8-bit processors contained 8-bit wide registers and 16-bit wide address bus, which can enable addressing of 2^16 = 64KB of memory. So thoeretically a program could use 64KB of memory.</p><p>Intel&rsquo;s main goal was to maintain programming familiarity while expanding addressable memory. They wanted programmers to continue thinking in terms of 16-bit addresses (which they were already comfortable with from 8-bit processors) while secretly accessing a larger memory space. The segmentation model essentially says: &ldquo;You can still write programs using 16-bit addresses, but we&rsquo;ll automatically map these into different 64KB &lsquo;segments&rsquo; of the larger 1MB space.&rdquo;</p><p>The physical address was divided into 2 parts: selector/segment and offset.</p><ul><li><strong>Selector (Segment):</strong> 16-bit value stored in one of CS, DS, ES, SS, etc.</li><li><strong>Offset:</strong> 16-bit value (e.g., in SI, DI, BP, SP, or an immediate/displacement).</li><li><strong>Physical Address Calculation:</strong> physical_address = (selector × 16) + offset</li></ul><p>The idea is to express a 20-bit address using 2 16-bit registers. A selector register (CS, DS, ES, SS) indicates the starting address of the segment and the offset register (SI, DI, BP, SP) indicates the boundary of the segment. Since the offset is 16-bits, the boundary can be at a maximum of 64KB thus maintaining backward compatibility.</p><p><img alt="Segmentation Model" loading=lazy src=/blog/images/segmentation-memory-model.png></p><p><strong>What the diagram shows</strong></p><ol><li><p>A <em>segment</em> is not a fixed block—it’s a <strong>sliding 64 KB window</strong> that can start on <strong>any 16-byte paragraph</strong>.<br><em>Segment value = paragraph number; multiplying by 16 shifts the window left or right in 16-byte steps.</em></p></li><li><p><strong>Segment N</strong> and <strong>Segment N+1</strong> start only 16 bytes apart, so their two 64 KB windows overlap almost completely.<br>Any physical byte inside that overlap can be reached with two (or many more) different <em>segment:offset</em> pairs.</p></li><li><p>Because the window can slide to <strong>65,536</strong> different paragraph positions (0000h–FFFFh), the segment register must be <strong>16 bits</strong> wide—not just 4 bits.</p></li><li><p>The <strong>offset</strong> (0–65535) always selects the byte inside the current 64 KB window.<br>Together, <em>segment</em> and <em>offset</em> build the 20-bit physical address:</p></li></ol><h3 id=disadvantages-of-the-segmentation-model>Disadvantages of the Segmentation Model<a hidden class=anchor aria-hidden=true href=#disadvantages-of-the-segmentation-model>#</a></h3><ol><li><p><strong>64 KB Segment Limit:</strong></p><ul><li>Each selector covers only 64 KB (the 16-bit offset range). Although it was theoretically possible to support a higher offset which means larger segment memory for a program.</li><li>Large programs or data structures must be split across multiple segments.</li><li>Switching segments (e.g., changing CS or DS) adds overhead and complexity.</li></ul></li><li><p><strong>Alias Addresses:</strong></p><ul><li>The same physical byte can be addressed by many segment:offset pairs.</li><li>Example: physical 04808₁₆ = 047C:0048 = 047D:0038 = 047E:0028 = 047B:0058</li><li>Makes comparing or normalizing pointers tricky.</li></ul></li><li><p><strong>Wrap Around after 20 bits:</strong></p><ul><li>All segments after 0xF000 reference memory positions above the 1 MB address space that don’t exist, which the 8086 chose to wrap around by ignoring the 21st bit of an address. After all, there is no 21st line in the address bus.</li></ul></li></ol><h3 id=the-real-mode>The Real Mode<a hidden class=anchor aria-hidden=true href=#the-real-mode>#</a></h3><p>Real mode is the operating mode that all x86 processors boot into, providing direct hardware access and backward compatibility with the original 8086 processor. Named &ldquo;real&rdquo; because it provides direct, unsupervised access to real physical memory addresses without any protection mechanisms or virtual memory translation.</p><p>When an x86 processor powers on, it starts in real mode regardless of whether it&rsquo;s a modern 64-bit CPU or the original 8086. This ensures that decades-old software can still run and that the boot process remains consistent across the entire x86 family.</p><h4 id=contents-of-1mb-memory-layout-in-8086-real-mode>Contents of 1MB memory layout in 8086 real mode<a hidden class=anchor aria-hidden=true href=#contents-of-1mb-memory-layout-in-8086-real-mode>#</a></h4><pre tabindex=0><code>
FFFFFh ┌─────────────────────────────────────────────────────────┐
       │ System ROM BIOS (64KB)                                  │
       │ • Boot code and POST routines                           │
       │ • Hardware initialization                               │
       │ • Interrupt handlers (INT 10h, 13h, 16h, etc.)          │
       │ • System services and utilities                         │
F0000h ├─────────────────────────────────────────────────────────┤
       │ Expansion ROM Area (192KB)                              │
       │ • Network card ROM                                      │
       │ • SCSI controller ROM                                   │
       │ • Other adapter ROM                                     │
       │ • Often partially unused                                │
C0000h ├─────────────────────────────────────────────────────────┤
       │ Video BIOS ROM (128KB)                                  │
       │ • VGA/EGA BIOS routines                                 │
       │ • Graphics mode setup                                   │
       │ • Character font data                                   │
       │ • Display adapter firmware                              │
A0000h ├─────────────────────────────────────────────────────────┤
       │ Video RAM (128KB)                                       │
       │ A0000h-AFFFFh: EGA/VGA graphics memory (64KB)           │
       │ B0000h-B7FFFh: Monochrome text memory (32KB)            │
       │ B8000h-BFFFFh: Color text memory (32KB)                 │
90000h ├─────────────────────────────────────────────────────────┤
       │ Extended Conventional Memory (576KB)                    │
       │ • Available for programs if installed                   │
       │ • Many early systems had less RAM                       │
       │ • Could be used for disk buffers, RAM disks             │
       │ • Upper portion often used by DOS itself                │
A0000h ├─────────────────────────────────────────────────────────┤ ← 640KB barrier
       │                                                         │
       │ Conventional Memory (640KB)                             │
       │ Main user program area                                  │
       │                                                         │
       │ ┌─────────────────────────────────────────────────────┐ │
       │ │ User Program Area                                   │ │ 
       │ │ • Application programs                              │ │
       │ │ • Program data and variables                        │ │
       │ │ • Dynamic memory allocation                         │ │
       │ │ • TSR (Terminate and Stay Resident) programs        │ │
       │ └─────────────────────────────────────────────────────┘ │
       │ ┌─────────────────────────────────────────────────────┐ │
       │ │ DOS Kernel and System Files                         │ │
       │ │ • COMMAND.COM                                       │ │
       │ │ • Device drivers                                    │ │
       │ │ • File allocation tables                            │ │
       │ │ • Directory buffers                                 │ │
       │ └─────────────────────────────────────────────────────┘ │
00500h ├─────────────────────────────────────────────────────────┤
       │ BIOS Data Area (256 bytes)                              │
       │ • Hardware configuration data                           │
       │ • Equipment list                                        │
       │ • Keyboard buffer                                       │
       │ • Video mode information                                │
       │ • Serial/parallel port addresses                        │
       │ • Timer tick count                                      │
       │ • Memory size information                               │
003FFh ├─────────────────────────────────────────────────────────┤
       │ Interrupt Vector Table (1024 bytes)                     │
       │ • 256 interrupt vectors × 4 bytes each                  │
       │ • Each vector: segment:offset (2 bytes:2 bytes)         │
       │ • INT 00h-FFh handler addresses                         │
       │ • Hardware and software interrupts                      │
       │ • Critical for system operation                         │
00000h └─────────────────────────────────────────────────────────┘
</code></pre><h5 id=key-memory-regions>Key Memory Regions<a hidden class=anchor aria-hidden=true href=#key-memory-regions>#</a></h5><ol><li><strong>Interrupt Vector Table (00000h-003FFh)</strong></li></ol><ul><li>Size: 1024 bytes (256 vectors × 4 bytes each)</li><li>Structure: Each entry contains segment:offset pointer (YYYY:XXXX format)</li><li>Purpose: The system&rsquo;s &ldquo;phone book&rdquo; for interrupt handlers</li><li>Function: When hardware or software triggers an interrupt (like pressing a key), the CPU looks up the handler address here</li><li>Critical vectors:<ul><li>INT 08h: System timer (18.2 times per second)</li><li>INT 09h: Keyboard interrupt</li><li>INT 10h: Video services</li><li>INT 13h: Disk services</li><li>INT 16h: Keyboard services</li><li>INT 21h: DOS system calls</li></ul></li><li>Why it&rsquo;s at address 0: The CPU automatically multiplies the interrupt number by 4 to find the handler address, so INT 09h handler is at 0×4×9 = 36 (0024h).</li></ul><ol start=2><li><strong>BIOS Data Area (00400h-004FFh) - 256 bytes</strong></li></ol><ul><li>Purpose: System configuration and status information</li><li>Hardware ports: COM1-4 <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> and LPT1-3 <sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup> base addresses</li><li>Video info: Current video mode, screen dimensions, cursor position</li><li>Keyboard: Shift/Ctrl/Alt key states <sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup>, keyboard buffer <sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup></li><li>System info: Installed memory size, equipment flags</li><li>Timers: System tick count since boot</li></ul><ol start=3><li><strong>Conventional Memory (00500h-9FFFFh) - ~640KB</strong></li></ol><ul><li>Purpose: Main workspace for operating system and applications</li><li><strong>DOS Kernel Area (lower portion)</strong><ul><li>COMMAND.COM: The DOS command interpreter</li><li>DOS kernel: File system, memory management, process control</li><li>Device drivers: Disk drivers, printer drivers, etc.</li><li>System buffers: File allocation table cache, directory buffers</li></ul></li><li><strong>User Program Area (upper portion)</strong><ul><li>Application programs: Your actual software</li><li>Program data: Variables, arrays, user data</li><li>Dynamic allocation: Heap memory for runtime allocation</li><li>TSR programs: Background utilities (like antivirus, print spoolers)</li></ul></li><li>Why 640KB limit: IBM reserved the upper 384KB for hardware, creating the famous &ldquo;640KB ought to be enough&rdquo; barrier.</li></ul><ol start=4><li><p><strong>Video RAM (A0000h-BFFFFh) - 128KB</strong></p><ul><li>Purpose: Direct access to display memory</li><li><strong>A0000h-AFFFFh: Graphics Memory (64KB)</strong><ul><li>EGA/VGA framebuffer: Each byte represents pixel data</li><li>Direct pixel control: Writing here immediately changes screen pixels</li><li>Mode-dependent: Layout changes based on resolution and color depth</li></ul></li></ul></li><li><p><strong>B0000h-B7FFFh: Monochrome Text (32KB)</strong></p><ul><li>Character display: For monochrome monitors</li><li>Text mode: 80×25 characters, 2 bytes per character (char + attribute)</li></ul></li><li><p><strong>B8000h-BFFFFh: Color Text (32KB)</strong></p><ul><li>Color character display: Standard color text mode</li><li>Format: Byte pairs (character, attribute)</li><li>Example: Writing &lsquo;A&rsquo; (65) + 0x07 (white on black) to B8000h displays &lsquo;A&rsquo; at top-left</li></ul></li><li><p><strong>Video BIOS ROM (C0000h-C7FFFh) - 32KB</strong></p><ul><li>Purpose: Graphics card firmware and services</li><li>Font data: Character sets for text modes</li><li>Hardware control: Register programming for graphics chips</li><li>BIOS extensions: Additional video services beyond basic BIOS</li><li>Memory-mapped: This is ROM on the graphics card, not system RAM.</li></ul></li><li><p><strong>Expansion ROM Area (C8000h-EFFFFh) - 160KB</strong></p><ul><li>Purpose: Additional adapter card firmware</li><li>Network cards: Boot ROM for network booting</li><li>SCSI controllers: Disk controller firmware</li><li>Sound cards: Audio processing firmware</li><li>Other adapters: Any card that needs ROM space</li><li>Often unused: Many systems had empty areas here.</li></ul></li><li><p><strong>System ROM BIOS (F0000h-FFFFFh) - 64KB</strong></p><ul><li>Purpose: Core system firmware</li><li>Power-On Self Test (POST): Hardware diagnostics at boot</li><li>Bootstrap loader: Loads operating system from disk</li><li>Hardware drivers: Low-level hardware access routines</li><li>System services: INT 10h (video), INT 13h (disk), INT 16h (keyboard)</li><li>Reset vector: CPU starts execution at FFFF:0000 on power-up</li></ul></li></ol><h5 id=why-this-layout>Why This Layout?<a hidden class=anchor aria-hidden=true href=#why-this-layout>#</a></h5><ul><li>Hardware Requirements: Different devices need different address ranges</li><li>ROM needs upper memory: BIOS must be at top (reset vector at FFFFFh)</li><li>Video needs fast access: Memory-mapped for performance</li><li>Programs need contiguous space: Large conventional memory block</li></ul><h1 id=the-80286-and-protected-mode>The 80286 and protected mode<a hidden class=anchor aria-hidden=true href=#the-80286-and-protected-mode>#</a></h1><h2 id=introduction-to-the-80286>Introduction to the 80286<a hidden class=anchor aria-hidden=true href=#introduction-to-the-80286>#</a></h2><p>The Intel 80286, released in 1982, represented a revolutionary leap in x86 architecture. While maintaining backward compatibility with the 8086, it introduced protected mode - a sophisticated operating environment that broke free from real mode&rsquo;s limitations and laid the foundation for modern computing.</p><p>The 80286 was Intel&rsquo;s answer to the growing demands for multitasking operating systems, memory protection, and the ability to address more than 1MB of memory. It powered the IBM PC/AT and became the processor that truly enabled the transition from simple DOS machines to powerful workstations.</p><h2 id=key-innovations-of-the-80286>Key Innovations of the 80286<a hidden class=anchor aria-hidden=true href=#key-innovations-of-the-80286>#</a></h2><h3 id=16mb-address-space>16MB Address Space<a hidden class=anchor aria-hidden=true href=#16mb-address-space>#</a></h3><ul><li><strong>24-bit address bus</strong> (compared to 8086&rsquo;s 20-bit)</li><li><strong>16MB maximum memory</strong> (2^24 = 16,777,216 bytes)</li><li><strong>Maintained real mode compatibility</strong> for existing</li></ul><h3 id=hardware-memory-protection>Hardware Memory Protection<a hidden class=anchor aria-hidden=true href=#hardware-memory-protection>#</a></h3><ul><li><strong>Privilege levels</strong> preventing user programs from corrupting system memory</li><li><strong>Segment-level protection</strong> with access rights and bounds checking</li><li><strong>Hardware-enforced security</strong> that software cannot bypass</li></ul><h3 id=virtual-memory-foundation>Virtual Memory Foundation<a hidden class=anchor aria-hidden=true href=#virtual-memory-foundation>#</a></h3><ul><li><strong>Segment descriptors</strong> containing detailed memory management information</li><li><strong>Global and Local Descriptor Tables</strong> for memory organization</li><li><strong>Task switching support</strong> enabling true multitasking</li></ul><h2 id=addressing-24-bit-memory>Addressing 24-Bit Memory<a hidden class=anchor aria-hidden=true href=#addressing-24-bit-memory>#</a></h2><p>The 80286 processor had 24 address bus compared to 20-Bit address bus of 8086. It had to implement the addressing in such a way that its backward compatible with 8086 processor&rsquo;s addressing. Instead of extending the logic used in 8086&rsquo;s real mode addressing, 80286 took an entirely different approach. The memory was still addressed with <code>selector (16-Bit): offset (16-Bit)</code> pairs. In real mode, a selector value was a paragraph number of physical memory. In protected mode, a selector value is an index into a descriptor table. In both modes, programs are divided into segments. In real mode, these segments are at fixed positions in physical memory and the selector value denotes the paragraph number of the beginning of the segment.</p><p>While we are storing the actual physical address of the segment in descriptor table, the descriptor table entry can store other information related to the segment as well. For eg: length of the segment which can be used to check if the memory accessed by the program is within the segment, read/write flags which can be used to enforce protection, etc.</p><p><img alt="Descriptor Table" loading=lazy src=/blog/images/descriptor-table.png></p><h2 id=the-virtual-memory>The Virtual Memory<a hidden class=anchor aria-hidden=true href=#the-virtual-memory>#</a></h2><p>The idea of virtual memory is provide an illusion to a program that it is the only program running and it has access to all the memory. The 80286 introduced the foundational concepts of virtual memory to the x86 architecture, though it implemented a more limited form compared to modern processors. Understanding the 80286&rsquo;s approach helps clarify why virtual memory became essential and how it evolved.</p><p>Virtual memory creates an abstraction layer between what programs think they&rsquo;re accessing (virtual addresses) and what actually exists in physical memory. The 80286 achieved this through segmentation-based virtual memory.</p><p><img alt="Virtual Memory" loading=lazy src=/blog/images/virtual-memory-80286.png></p><h3 id=simplified-programming-model-with-virtual-memory>Simplified Programming Model with Virtual Memory<a hidden class=anchor aria-hidden=true href=#simplified-programming-model-with-virtual-memory>#</a></h3><p>Before virtual memory, programmer had to directly manage physical addresses which is error prone and there&rsquo;s a possibility of overwriting other program&rsquo;s data. This also means the programmer has to know where the segments will be loaded in memory beforehand. Virtual Memory solves this issue as each segment will be under the illusion that it starts at memory address 0 and can access upto 64KB of memory.</p><h2 id=global-and-local-descriptor-tables-gdt-and-ldt>Global and Local Descriptor Tables (GDT and LDT)<a hidden class=anchor aria-hidden=true href=#global-and-local-descriptor-tables-gdt-and-ldt>#</a></h2><h3 id=what-are-descriptor-tables>What Are Descriptor Tables?<a hidden class=anchor aria-hidden=true href=#what-are-descriptor-tables>#</a></h3><p>Think of descriptor tables as address books for the computer&rsquo;s memory system. Just like you use a phone book to look up someone&rsquo;s address when you only know their name, the 80286 processor uses descriptor tables to look up memory information when it only knows a selector (a kind of memory &ldquo;name&rdquo;).</p><h3 id=the-basic-problem-they-solve>The Basic Problem They Solve<a hidden class=anchor aria-hidden=true href=#the-basic-problem-they-solve>#</a></h3><p>In real mode, programs had to deal with physical memory addresses directly:</p><pre tabindex=0><code>Real Mode Problem:
Program says: &#34;I want to access memory at 0x12345&#34;
CPU responds: &#34;OK, accessing physical memory at 0x12345&#34;

Issues:
- Programs must know exact physical addresses
- No protection between programs  
- Programs can corrupt each other&#39;s memory
- Hard to relocate programs in memory
</code></pre><p>Protected mode solves this with an indirection layer:</p><pre tabindex=0><code>Protected Mode Solution:
Program says: &#34;I want to access selector 0x0008, offset 0x1234&#34;
CPU responds: &#34;Let me look up selector 0x0008 in the descriptor table...&#34;
CPU finds: &#34;Selector 0x0008 points to base address 0x100000&#34;
CPU calculates: &#34;Physical address = 0x100000 + 0x1234 = 0x101234&#34;
CPU verifies: &#34;Access allowed? Yes. Accessing physical memory at 0x101234&#34;
</code></pre><h3 id=understanding-selectors>Understanding Selectors<a hidden class=anchor aria-hidden=true href=#understanding-selectors>#</a></h3><p>A selector is a 16-bit value that acts like a &ldquo;memory ID card.&rdquo; Instead of using physical addresses, programs use selectors to identify memory segments.</p><p><img alt="Selector Format" loading=lazy src=/blog/images/selector-format.png></p><ul><li><strong>Index (bits 15-3):</strong> Which entry in the descriptor table (0-8191)</li><li><strong>TI (bit 2):</strong> Table Indicator - 0 = GDT, 1 = LDT</li><li><strong>RPL (bits 1-0):</strong> Requested Privilege Level (0-3)</li></ul><h3 id=what-is-a-descriptor>What Is a Descriptor?<a hidden class=anchor aria-hidden=true href=#what-is-a-descriptor>#</a></h3><p>A descriptor is an 8-byte data structure that contains all the information the CPU needs to access a memory segment safely.</p><p><img alt="Descriptor Format" loading=lazy src=/blog/images/descriptor-format.png></p><p><strong>Base Address (24 bits total in 80286):</strong> (Base[23..16] + Base[15..0])</p><ul><li>Bits 15..0 from the lower section</li><li>Bits 23..16 from the upper section</li></ul><p><strong>Limit (20 bits total, but 80286 only uses 16 bits):</strong></p><ul><li>Limit 15..0 (16 bits) - from Lower 32 bits</li><li>Limit 19..16 (4 bits) - from Upper 32 bits (but not used in 80286)</li></ul><p>The descriptor format was designed to be forward-compatible. The 80386 later extended it to use:</p><ul><li>Full 32-bit base address (adding Base 31..24)</li><li>Full 20-bit limit (adding Limit 19..16 with granularity bit)</li></ul><p><strong>Final physical address calculation:</strong></p><pre tabindex=0><code>Physical Address = 24-bit Base (from descriptor) + 16-bit Offset (from instruction)
</code></pre><p><strong>Access Byte Format</strong></p><p><img alt="Access Byte" loading=lazy src=/blog/images/access-byte-format.png></p><ul><li><strong>P (Present) - Bit 7:</strong> Indicates whether the segment is currently loaded in memory. When P=1, the segment is valid and can be accessed. When P=0, any attempt to access this segment generates a segment-not-present exception, allowing the OS to load the segment from disk (virtual memory support).</li><li><strong>DPL (Descriptor Privilege Level) - Bits 6-5:</strong> Defines the privilege level required to access this segment (0-3, where 0 is most privileged). Code running at privilege level 3 (user mode) cannot access segments with DPL=0 (kernel mode). This enforces memory protection between kernel and user space.</li><li><strong>S (System) - Bit 4:</strong> Distinguishes between application segments and system segments. When S=1, this is an application segment (code/data used by programs). When S=0, this is a system segment (like Task State Segment or LDT descriptor) used by the processor for special operations.</li><li><strong>E (Executable) - Bit 3:</strong> Determines if this segment contains executable code or data. When E=1, this is a code segment that can be executed (instructions fetched from here). When E=0, this is a data segment used for storing variables and cannot be executed.</li><li><strong>D (Direction/Conforming) - Bit 2:</strong> For data segments: D=0 means segment grows upward (normal), D=1 means grows downward (stack). For code segments: D=0 means non-conforming (strict privilege checking), D=1 means conforming (can be called from lower privilege levels without changing CPL).</li><li><strong>R (Read/Write) - Bit 1:</strong> For data segments: R=1 allows write access, R=0 makes it read-only. For code segments: R=1 allows reading the code (useful for debuggers), R=0 makes it execute-only. Code segments are never writable regardless of this bit.</li><li><strong>A (Accessed) - Bit 0:</strong> Automatically set by the CPU whenever the segment is accessed (loaded into a segment register or used). Never cleared by hardware - only software can clear it. Used by operating systems to implement virtual memory algorithms by tracking which segments are actively being used.</li></ul><h3 id=flags-field-4-bits>Flags Field (4 bits)<a hidden class=anchor aria-hidden=true href=#flags-field-4-bits>#</a></h3><p><strong>Bit 3: G (Granularity)</strong></p><ul><li><p>G = 0: Limit is in bytes (fine granularity)</p><ul><li>Segment can be 1 byte to 1 MB in size</li><li>Limit value is used directly</li></ul></li><li><p>G = 1: Limit is in 4KB pages (page granularity)</p><ul><li>Segment can be 4KB to 4GB in size</li><li>CPU automatically shifts limit left by 12 bits (multiplies by 4096)</li></ul></li></ul><p><strong>Bit 2: D/B (Default/Big)</strong></p><ul><li><p>For Code Segments: Controls default operand/address size</p><ul><li>D = 0: 16-bit mode (8086/80286 compatible)</li><li>D = 1: 32-bit mode (80386+ native)</li></ul></li><li><p>For Data Segments: Controls stack pointer size</p><ul><li>B = 0: Stack uses SP (16-bit stack pointer)</li><li>B = 1: Stack uses ESP (32-bit stack pointer)</li></ul></li></ul><p><strong>Bit 1: L (Long Mode)</strong></p><ul><li>For 64-bit mode only (not relevant for 80286)</li><li>L = 0: Not a 64-bit code segment</li><li>L = 1: 64-bit code segment (x86-64 mode)</li><li>Rule: If L = 1, then D must = 0</li></ul><p><strong>Bit 0: AVL (Available)</strong></p><ul><li>Available for system software use</li><li>Not used by CPU hardware</li><li>OS can use for its own purposes</li><li>Examples: Process tracking, debugging flags, memory management hints</li></ul><h3 id=global-descriptor-table-gdt>Global Descriptor Table (GDT)<a hidden class=anchor aria-hidden=true href=#global-descriptor-table-gdt>#</a></h3><p>The Global Descriptor Table is a system-wide table containing descriptors that all tasks can potentially access. Think of it as the &ldquo;public directory&rdquo; of memory segments.</p><h4 id=gdt-structure-and-location>GDT Structure and Location<a hidden class=anchor aria-hidden=true href=#gdt-structure-and-location>#</a></h4><pre tabindex=0><code>Physical Memory Layout:
┌─────────────────────────────────────────────────────────────┐
│                    System RAM                               │
│                                                             │
│  ┌─────────────────────────────────────────────────────┐    │
│  │                 GDT                                 │    │
│  ├─────────────────────────────────────────────────────┤    │
│  │ Entry 0: NULL Descriptor (required)                 │    │
│  ├─────────────────────────────────────────────────────┤    │
│  │ Entry 1: Kernel Code Segment                        │    │
│  ├─────────────────────────────────────────────────────┤    │
│  │ Entry 2: Kernel Data Segment                        │    │
│  ├─────────────────────────────────────────────────────┤    │
│  │ Entry 3: User Code Segment                          │    │
│  ├─────────────────────────────────────────────────────┤    │
│  │ Entry 4: User Data Segment                          │    │
│  ├─────────────────────────────────────────────────────┤    │
│  │ Entry 5: Task A&#39;s LDT Descriptor                    │    │
│  ├─────────────────────────────────────────────────────┤    │
│  │ Entry 6: Task A&#39;s TSS Descriptor                    │    │
│  ├─────────────────────────────────────────────────────┤    │
│  │ Entry 7: Task B&#39;s LDT Descriptor                    │    │
│  ├─────────────────────────────────────────────────────┤    │
│  │ Entry 8: Task B&#39;s TSS Descriptor                    │    │
│  └─────────────────────────────────────────────────────┘    │
│                                                             │
└─────────────────────────────────────────────────────────────┘

GDTR Register (inside CPU):
┌─────────────────────────────────────────────────────────────┐
│ Base Address: Points to start of GDT in memory              │
│ Limit: Size of GDT - 1                                      │
└─────────────────────────────────────────────────────────────┘
</code></pre><h4 id=what-goes-in-the-gdt>What Goes in the GDT?<a hidden class=anchor aria-hidden=true href=#what-goes-in-the-gdt>#</a></h4><p><strong>System-wide resources that multiple tasks might need:</strong></p><p><strong>1. Operating System Segments</strong></p><ul><li>Kernel code segment (Ring 0)</li><li>Kernel data segment (Ring 0)</li><li>System service segments</li></ul><p><strong>2. Common User Segments</strong></p><ul><li>Standard user code segment (Ring 3)</li><li>Standard user data segment (Ring 3)</li></ul><p><strong>3. Task Management Descriptors</strong></p><ul><li>Task State Segments (TSS) for each task</li><li>Local Descriptor Table (LDT) descriptors for each task</li></ul><p><strong>4. Device Driver Segments</strong></p><ul><li>Driver code segments</li><li>Shared system libraries</li></ul><h4 id=example-gdt-layout>Example GDT Layout<a hidden class=anchor aria-hidden=true href=#example-gdt-layout>#</a></h4><pre tabindex=0><code>┌─────┬───────────────────┬──────────┬─────────┬─────────────────┐
│Index│ Description       │ Base     │ Limit   │ Access Rights   │
├─────┼───────────────────┼──────────┼─────────┼─────────────────┤
│  0  │ NULL (required)   │ 00000000 │ 00000   │ 00000000        │
├─────┼───────────────────┼──────────┼─────────┼─────────────────┤
│  1  │ Kernel Code       │ 00000000 │ FFFFF   │ 9A (Ring 0, X/R)│
├─────┼───────────────────┼──────────┼─────────┼─────────────────┤
│  2  │ Kernel Data       │ 00000000 │ FFFFF   │ 92 (Ring 0, R/W)│
├─────┼───────────────────┼──────────┼─────────┼─────────────────┤
│  3  │ User Code         │ 00000000 │ FFFFF   │ FA (Ring 3, X/R)│
├─────┼───────────────────┼──────────┼─────────┼─────────────────┤
│  4  │ User Data         │ 00000000 │ FFFFF   │ F2 (Ring 3, R/W)│
├─────┼───────────────────┼──────────┼─────────┼─────────────────┤
│  5  │ Text Editor LDT   │ 00200000 │ 01000   │ 82 (LDT, Ring 0)│
├─────┼───────────────────┼──────────┼─────────┼─────────────────┤
│  6  │ Text Editor TSS   │ 00201000 │ 00068   │ 89 (TSS, Ring 0)│
├─────┼───────────────────┼──────────┼─────────┼─────────────────┤
│  7  │ Web Browser LDT   │ 00300000 │ 01000   │ 82 (LDT, Ring 0)│
├─────┼───────────────────┼──────────┼─────────┼─────────────────┤
│  8  │ Web Browser TSS   │ 00301000 │ 00068   │ 89 (TSS, Ring 0)│
└─────┴───────────────────┴──────────┴─────────┴─────────────────┘
</code></pre><h3 id=local-descriptor-table-ldt>Local Descriptor Table (LDT)<a hidden class=anchor aria-hidden=true href=#local-descriptor-table-ldt>#</a></h3><p>A Local Descriptor Table is a task-specific table containing descriptors that are private to one particular task. Think of it as each task&rsquo;s &ldquo;private address book.&rdquo;</p><h4 id=key-differences-gdt-vs-ldt>Key Differences: GDT vs LDT<a hidden class=anchor aria-hidden=true href=#key-differences-gdt-vs-ldt>#</a></h4><pre tabindex=0><code>GDT (Global - Shared):           LDT (Local - Private):
┌─────────────────────┐         ┌─────────────────────┐
│ • One per system    │         │ • One per task      │
│ • Shared by all     │         │ • Private to task   │
│ • System resources  │         │ • Task resources    │
│ • Always available  │         │ • Only when task    │
│                     │         │   is running        │
└─────────────────────┘         └─────────────────────┘
</code></pre><h4 id=how-ldts-work>How LDTs Work<a hidden class=anchor aria-hidden=true href=#how-ldts-work>#</a></h4><p><strong>Step 1: LDT Descriptor in GDT</strong>
The GDT contains a descriptor that points to each task&rsquo;s LDT:</p><pre tabindex=0><code>GDT Entry 5 (Text Editor&#39;s LDT):
┌─────────────────────────────────────────────────────────────┐
│ Base: 0x200000  ← Physical address where LDT is stored      │
│ Limit: 0x1000   ← LDT can hold up to 512 descriptors        │
│ Type: LDT       ← This is an LDT descriptor                 │
│ DPL: 0          ← Ring 0 (system manages LDTs)              │
└─────────────────────────────────────────────────────────────┘
</code></pre><p><strong>Step 2: LDT Contains Task&rsquo;s Private Descriptors</strong></p><pre tabindex=0><code>At physical address 0x200000 (Text Editor&#39;s LDT):
┌─────────────────────────────────────────────────────────────┐
│ Entry 0: NULL                                               │
│ Entry 1: Text Editor Code Segment                           │
│ Entry 2: Text Editor Data Segment                           │
│ Entry 3: Text Editor Stack Segment                          │
│ Entry 4: Document Buffer Segment                            │
│ Entry 5: Font Library Segment                               │
└─────────────────────────────────────────────────────────────┘
</code></pre><h4 id=ldt-entries>LDT Entries<a hidden class=anchor aria-hidden=true href=#ldt-entries>#</a></h4><p>LDT entries follow the exact same 8-byte descriptor format as GDT entries. An LDT is a block of (linear) memory up to 64K in size, just like the GDT. The difference from the GDT is in the Descriptors that it can store, and the method used to access it.</p><p>Both use the same:</p><ul><li>64-bit (8-byte) descriptor structure</li><li>Same Base/Limit/Access byte/Flags layout</li><li>Same bit positions for all fields</li></ul><p>However, there are content restrictions for LDT:</p><ul><li>LDT cannot hold system segments (Task State Segments and Local Descriptor Tables)</li><li>LDT can only contain application segments (code/data) and some gates</li><li>GDT can contain everything (application segments, system segments, LDT descriptors, TSS descriptors)</li></ul><h3 id=what-are-gates>What Are Gates?<a hidden class=anchor aria-hidden=true href=#what-are-gates>#</a></h3><p>Gates are special descriptors that act as &ldquo;doorways&rdquo; for controlled transfers of execution. Unlike regular segment descriptors that point to memory regions, gates contain entry points (addresses) where execution should transfer to.</p><h4 id=types-of-gates-in-x86>Types of Gates in x86:<a hidden class=anchor aria-hidden=true href=#types-of-gates-in-x86>#</a></h4><p><strong>1. Call Gates</strong></p><ul><li><strong>Purpose:</strong> Allow controlled calls from lower privilege code to higher privilege code</li><li><strong>Function:</strong> Like a &ldquo;secure function pointer&rdquo; - lets user code (Ring 3) safely call kernel functions (Ring 0)</li><li><strong>Contains:</strong> Target code segment selector + offset where to jump</li><li><strong>Security:</strong> CPU automatically checks privilege levels and switches stacks if needed</li></ul><p><strong>2. Task Gates</strong></p><ul><li><strong>Purpose:</strong> Trigger hardware task switches</li><li><strong>Function:</strong> Points to a TSS descriptor to switch to a different task</li><li><strong>Contains:</strong> TSS selector that identifies which task to switch to</li><li><strong>Usage:</strong> Can be placed in IDT for task-switching interrupts</li></ul><p><strong>3. Interrupt Gates</strong></p><ul><li><strong>Purpose:</strong> Handle interrupts and exceptions</li><li><strong>Function:</strong> Similar to call gates but for interrupt handling</li><li><strong>Contains:</strong> Target code segment + interrupt handler address</li><li><strong>Behavior:</strong> Automatically disables interrupts when called</li></ul><p><strong>4. Trap Gates</strong></p><ul><li><strong>Purpose:</strong> Handle exceptions and software interrupts</li><li><strong>Function:</strong> Like interrupt gates but doesn&rsquo;t disable interrupts</li><li><strong>Contains:</strong> Target code segment + exception handler address</li><li><strong>Usage:</strong> For system calls and debugging exceptions</li></ul><p><strong>Why Gates Can Be in LDT:</strong></p><p>While LDT cannot contain system segments (TSS, LDT descriptors), it can contain gates because:</p><ul><li><strong>Call gates:</strong> Allow process-specific entry points to system services</li><li><strong>Task gates:</strong> Could theoretically allow process-specific task switching (though rarely used)</li></ul><p><strong>Example Use Case:</strong></p><pre tabindex=0><code>Process A&#39;s LDT might contain:
├── Code Segment (Ring 3)
├── Data Segment (Ring 3) 
├── Call Gate → Kernel function for file I/O
└── Call Gate → Kernel function for memory allocation
</code></pre><p>This way, each process can have its own set of &ldquo;approved&rdquo; kernel entry points through call gates in their private LDT, while the kernel maintains control over exactly which functions can be called and how.</p><p>In practice: Modern operating systems rarely use LDTs or gates, preferring software-based system call mechanisms and paging-based memory protection. But the hardware still supports these features for compatibility and specialized use cases.</p><h3 id=gdtr-and-ldtr>GDTR and LDTR<a hidden class=anchor aria-hidden=true href=#gdtr-and-ldtr>#</a></h3><p>The processor locates the GDT and the current LDT in memory by means of the GDTR and LDTR registers. These registers store the base addresses of the tables in the linear address space and store the segment limits.</p><h4 id=gdtr-global-descriptor-table-register>GDTR (Global Descriptor Table Register):<a hidden class=anchor aria-hidden=true href=#gdtr-global-descriptor-table-register>#</a></h4><pre tabindex=0><code>┌─────────────────────────────────────────────────────────────┐
│ GDTR - Simple pointer structure                             │
├─────────────────────────────────┬───────────────────────────┤
│ Base Address (32-bit)           │ Limit (16-bit)            │
│ Linear address of GDT in memory │ Size of GDT - 1           │
└─────────────────────────────────┴───────────────────────────┘
</code></pre><ul><li>Direct pointer to GDT location in memory</li><li>Loaded with <code>LGDT</code> instruction</li><li>Contains actual memory address and size</li></ul><h4 id=ldtr-local-descriptor-table-register>LDTR (Local Descriptor Table Register):<a hidden class=anchor aria-hidden=true href=#ldtr-local-descriptor-table-register>#</a></h4><pre tabindex=0><code>┌─────────────────────────────────────────────────────────────┐
│ LDTR - Segment register with selector + cached descriptor   │
├─────────────────────────────────────────────────────────────┤
│ Visible: LDT Selector (16-bit)                              │
├─────────────────────────────────────────────────────────────┤
│ Hidden: Cached LDT Descriptor (64-bit)                      │
│ Base + Limit + Access Rights from GDT entry                 │
└─────────────────────────────────────────────────────────────┘
</code></pre><ul><li>Indirect reference through GDT selector</li><li>The LDT is defined as a &rsquo;normal&rsquo; memory Segment inside the GDT - simply with a Base memory address and Limit</li><li>Loaded with LLDT instruction using a selector</li><li>CPU automatically fetches LDT descriptor from GDT and caches it</li></ul><p><strong>The Relationship:</strong></p><ul><li>GDTR points directly to GDT in memory</li><li>LDTR contains a selector that points to an entry within the GDT</li><li>That GDT entry describes where the LDT is located</li><li>CPU caches that LDT descriptor information from GDT in LDTR&rsquo;s hidden part</li></ul><h4 id=who-can-readwrite-into-gdtr-and-ldtr-registers>WHo can Read/Write into GDTR and LDTR registers?<a hidden class=anchor aria-hidden=true href=#who-can-readwrite-into-gdtr-and-ldtr-registers>#</a></h4><p><strong>GDTR (Global Descriptor Table Register):</strong></p><ul><li><strong>Set by:</strong> Operating system kernel (Ring 0 code only)</li><li><strong>Instructions:</strong> LGDT (Load GDT) and SGDT (Store GDT)</li><li><strong>Privilege:</strong> These instructions can only be executed in Ring 0 (kernel mode)</li><li><strong>When:</strong> During OS boot/initialization</li></ul><p><strong>LDTR (Local Descriptor Table Register):</strong></p><ul><li><strong>Set by:</strong> Operating system kernel (Ring 0 code only)</li><li><strong>Instructions:</strong> LLDT (Load LDT) and SLDT (Store LDT)</li><li><strong>Privilege:</strong> Ring 0 only</li><li><strong>When:</strong> During task/process creation or context switches</li></ul><h4 id=initial-setup-process>Initial Setup Process:<a hidden class=anchor aria-hidden=true href=#initial-setup-process>#</a></h4><p><strong>1. System Boot Sequence:</strong></p><pre tabindex=0><code>1. CPU starts in Real Mode (no GDTR/LDTR)
2. Bootloader loads OS kernel
3. Kernel creates initial GDT in memory
4. Kernel executes LGDT to set GDTR
5. Kernel switches to Protected Mode
6. Kernel can now create LDTs and set LDTR as needed
</code></pre><p><strong>2. GDT Creation (by OS Kernel):</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-C data-lang=C><span style=display:flex><span><span style=color:#75715e>// Kernel code (Ring 0) during boot
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>struct</span> gdt_entry gdt[<span style=color:#ae81ff>8</span>];  <span style=color:#75715e>// Array in kernel memory
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Set up null descriptor (entry 0)
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>gdt[<span style=color:#ae81ff>0</span>] <span style=color:#f92672>=</span> {<span style=color:#ae81ff>0</span>};
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Set up kernel code segment (entry 1) 
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>gdt[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>=</span> {base: <span style=color:#ae81ff>0</span>, limit: <span style=color:#ae81ff>0xFFFFF</span>, access: <span style=color:#ae81ff>0x9A</span>, flags: <span style=color:#ae81ff>0xC</span>};
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Set up kernel data segment (entry 2)
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>gdt[<span style=color:#ae81ff>2</span>] <span style=color:#f92672>=</span> {base: <span style=color:#ae81ff>0</span>, limit: <span style=color:#ae81ff>0xFFFFF</span>, access: <span style=color:#ae81ff>0x92</span>, flags: <span style=color:#ae81ff>0xC</span>};
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Set up user code segment (entry 3)
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>gdt[<span style=color:#ae81ff>3</span>] <span style=color:#f92672>=</span> {base: <span style=color:#ae81ff>0</span>, limit: <span style=color:#ae81ff>0xFFFFF</span>, access: <span style=color:#ae81ff>0xFA</span>, flags: <span style=color:#ae81ff>0xC</span>};
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// More entries...
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Load the GDT
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>struct</span> gdt_ptr {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>uint16_t</span> limit;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>uint32_t</span> base;
</span></span><span style=display:flex><span>} gdt_descriptor <span style=color:#f92672>=</span> {<span style=color:#66d9ef>sizeof</span>(gdt)<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, (<span style=color:#66d9ef>uint32_t</span>)gdt};
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>asm</span>(<span style=color:#e6db74>&#34;lgdt %0&#34;</span> <span style=color:#f92672>:</span> <span style=color:#f92672>:</span> <span style=color:#e6db74>&#34;m&#34;</span>(gdt_descriptor));
</span></span></code></pre></div><h4 id=who-can-readwrite-gdt-and-ldt>Who Can Read/Write GDT and LDT?<a hidden class=anchor aria-hidden=true href=#who-can-readwrite-gdt-and-ldt>#</a></h4><p><strong>Reading:</strong></p><p>GDT/LDT contents: Any code can read (they&rsquo;re just memory)
GDTR/LDTR values: SGDT/SLDT instructions (Ring 0 only)</p><p><strong>Writing:</strong></p><p>GDT/LDT contents: Only Ring 0 code should modify (by convention)
GDTR/LDTR registers: Only Ring 0 via LGDT/LLDT</p><p><strong>Memory Protection:</strong></p><p>GDT location: Kernel typically places GDT in kernel-only memory pages
LDT location: Can be in user-accessible memory (but user can&rsquo;t change LDTR)</p><h4 id=post-80386-era>Post 80386 Era<a hidden class=anchor aria-hidden=true href=#post-80386-era>#</a></h4><ul><li>SGDT/SLDT: Ring 3 accessible (any privilege level)</li><li>LGDT/LLDT: Still Ring 0 only</li></ul><p><strong>Why Intel Made This Change:</strong></p><p><strong>Practical Reasons:</strong></p><ul><li>Debugging tools: Debuggers and system utilities needed to examine system state</li><li>Virtual machines: VM software needed to read GDT/IDT information</li><li>System monitoring: Performance tools and diagnostics required access</li><li>Compatibility: Some software had legitimate needs to read (not write) this info</li></ul><p><strong>Security Analysis:</strong></p><ul><li>Reading GDTR/IDTR: Reveals memory layout but doesn&rsquo;t grant control</li><li>Still protected: Only reading allowed - writing still requires Ring 0</li><li>Limited exposure: Knowing GDT location doesn&rsquo;t directly compromise security</li></ul><p><strong>Modern Usage:</strong></p><p>This change enabled:</p><ul><li>Hypervisors: VMware, VirtualBox can inspect guest OS descriptor tables</li><li>Security tools: Rootkit detectors can examine system structures</li><li>Debuggers: WinDbg, GDB can show detailed system state</li><li>OS utilities: System information tools can display memory management details</li></ul><h2 id=task-state-segment-tss>Task State Segment (TSS)<a hidden class=anchor aria-hidden=true href=#task-state-segment-tss>#</a></h2><p>The Task State Segment (TSS) is a special data structure that contains the complete execution state of a task (program). Think of it as a &ldquo;snapshot&rdquo; that captures everything the CPU needs to know about a task - all its registers, memory settings, and execution context.</p><p>Before the 80286, task switching was a manual, error-prone process:</p><pre tabindex=0><code>Manual Task Switching (8086 era):
┌─────────────────────────────────────────────────────────────┐
│ 1. Programmer saves all registers manually                  │
│    MOV [task_a_ax], AX                                      │
│    MOV [task_a_bx], BX                                      │
│    MOV [task_a_cx], CX                                      │
│    ... (save 20+ registers and flags)                       │
│                                                             │
│ 2. Programmer loads new task&#39;s registers manually           │
│    MOV AX, [task_b_ax]                                      │
│    MOV BX, [task_b_bx]                                      │
│    ... (load 20+ registers and flags)                       │
│                                                             │
│ 3. Programmer manages memory segments manually              │
│    MOV DS, [task_b_ds]                                      │
│    MOV ES, [task_b_es]                                      │
│                                                             │
│ Problems:                                                   │
│ ❌ 50+ instructions per task switch                         │
│ ❌ Easy to forget registers                                 │
│ ❌ No atomic operation                                      │
│ ❌ No protection                                            │
│ ❌ Very slow                                                │
└─────────────────────────────────────────────────────────────┘
</code></pre><h3 id=tss-solution>TSS Solution:<a hidden class=anchor aria-hidden=true href=#tss-solution>#</a></h3><pre tabindex=0><code>Hardware Task Switching (80286):
┌─────────────────────────────────────────────────────────────┐
│ Single instruction: JMP task_selector                       │
│                                                             │
│ Hardware automatically:                                     │
│ ✅ Saves ALL current state to current TSS                   │
│ ✅ Loads ALL new state from target TSS                      │
│ ✅ Updates memory management (LDT switch)                   │
│ ✅ Atomic operation (cannot be interrupted)                 │
│ ✅ Hardware protection checks                               │
│ ✅ Extremely fast (few clock cycles)                        │
└─────────────────────────────────────────────────────────────┘
</code></pre><h3 id=tss-structure-and-layout>TSS Structure and Layout<a hidden class=anchor aria-hidden=true href=#tss-structure-and-layout>#</a></h3><p>The 80286 TSS is a 44-byte (104 bytes with I/O bitmap <sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup>) data structure containing every piece of information needed to resume a task:</p><pre tabindex=0><code>TSS Layout (80286):
┌─────────────────────────────────────────────────────────────┐
│ Offset │ Size │ Field Name        │ Description             │
├────────┼──────┼───────────────────┼─────────────────────────┤
│   00h  │  2   │ Previous TSS Link │ Selector of previous    │
│        │      │                   │ task (for nested calls) │
├────────┼──────┼───────────────────┼─────────────────────────┤
│   02h  │  2   │ SP0 (Stack Ring 0)│ Stack pointer for Ring 0│
├────────┼──────┼───────────────────┼─────────────────────────┤
│   04h  │  2   │ SS0 (Stack Ring 0)│ Stack segment for Ring 0│
├────────┼──────┼───────────────────┼─────────────────────────┤
│   06h  │  2   │ SP1 (Stack Ring 1)│ Stack pointer for Ring 1│
├────────┼──────┼───────────────────┼─────────────────────────┤
│   08h  │  2   │ SS1 (Stack Ring 1)│ Stack segment for Ring 1│
├────────┼──────┼───────────────────┼─────────────────────────┤
│   0Ah  │  2   │ SP2 (Stack Ring 2)│ Stack pointer for Ring 2│
├────────┼──────┼───────────────────┼─────────────────────────┤
│   0Ch  │  2   │ SS2 (Stack Ring 2)│ Stack segment for Ring 2│
├────────┼──────┼───────────────────┼─────────────────────────┤
│   0Eh  │  2   │ IP                │ Instruction Pointer     │
├────────┼──────┼───────────────────┼─────────────────────────┤
│   10h  │  2   │ FLAGS             │ Processor flags         │
├────────┼──────┼───────────────────┼─────────────────────────┤
│   12h  │  2   │ AX                │ General register AX     │
├────────┼──────┼───────────────────┼─────────────────────────┤
│   14h  │  2   │ CX                │ General register CX     │
├────────┼──────┼───────────────────┼─────────────────────────┤
│   16h  │  2   │ DX                │ General register DX     │
├────────┼──────┼───────────────────┼─────────────────────────┤
│   18h  │  2   │ BX                │ General register BX     │
├────────┼──────┼───────────────────┼─────────────────────────┤
│   1Ah  │  2   │ SP                │ Stack Pointer           │
├────────┼──────┼───────────────────┼─────────────────────────┤
│   1Ch  │  2   │ BP                │ Base Pointer            │
├────────┼──────┼───────────────────┼─────────────────────────┤
│   1Eh  │  2   │ SI                │ Source Index            │
├────────┼──────┼───────────────────┼─────────────────────────┤
│   20h  │  2   │ DI                │ Destination Index       │
├────────┼──────┼───────────────────┼─────────────────────────┤
│   22h  │  2   │ ES                │ Extra Segment           │
├────────┼──────┼───────────────────┼─────────────────────────┤
│   24h  │  2   │ CS                │ Code Segment            │
├────────┼──────┼───────────────────┼─────────────────────────┤
│   26h  │  2   │ SS                │ Stack Segment           │
├────────┼──────┼───────────────────┼─────────────────────────┤
│   28h  │  2   │ DS                │ Data Segment            │
├────────┼──────┼───────────────────┼─────────────────────────┤
│   2Ah  │  2   │ LDT Selector      │ Local Descriptor Table  │
└─────────────────────────────────────────────────────────────┘
</code></pre><h3 id=memory-layout-visualization>Memory Layout Visualization<a hidden class=anchor aria-hidden=true href=#memory-layout-visualization>#</a></h3><pre tabindex=0><code>TSS in Physical Memory:
┌─────────────────────────────────────────────────────────────┐
│                     Task A&#39;s TSS                            │
│                  (44 bytes minimum)                         │
├─────────────────────────────────────────────────────────────┤
│ Offset 00h: Previous Task = 0x0000                          │
│ Offset 02h: Ring 0 SP = 0x7C00                              │
│ Offset 04h: Ring 0 SS = 0x0008                              │
│ Offset 06h: Ring 1 SP = 0x0000                              │
│ Offset 08h: Ring 1 SS = 0x0000                              │
│ Offset 0Ah: Ring 2 SP = 0x0000                              │
│ Offset 0Ch: Ring 2 SS = 0x0000                              │
│ Offset 0Eh: IP = 0x1234        ← Where task will resume     │
│ Offset 10h: FLAGS = 0x0202                                  │
│ Offset 12h: AX = 0x1234                                     │
│ Offset 14h: CX = 0x5678                                     │
│ Offset 16h: DX = 0x9ABC                                     │
│ Offset 18h: BX = 0xDEF0                                     │
│ Offset 1Ah: SP = 0x7FF0                                     │
│ Offset 1Ch: BP = 0x7FE0                                     │
│ Offset 1Eh: SI = 0x1000                                     │
│ Offset 20h: DI = 0x2000                                     │
│ Offset 22h: ES = 0x0010                                     │
│ Offset 24h: CS = 0x0008                                     │
│ Offset 26h: SS = 0x0010                                     │
│ Offset 28h: DS = 0x0010                                     │
│ Offset 2Ah: LDT = 0x0028       ← Task&#39;s private memory      │
└─────────────────────────────────────────────────────────────┘
</code></pre><h3 id=tss-descriptor-in-the-gdt>TSS Descriptor in the GDT<a hidden class=anchor aria-hidden=true href=#tss-descriptor-in-the-gdt>#</a></h3><p>The TSS itself is just a data structure in memory. To use it, there must be a TSS descriptor in the GDT that points to it:
(SInce TSS Descriptor is just another entry in GDT, it follows the same pattern as GDT entries)</p><pre tabindex=0><code>GDT Entry for TSS:
┌─────────────────────────────────────────────────────────────┐
│                 TSS Descriptor (8 bytes)                   │
├─────────────────────────────────────────────────────────────┤
│ Base Address: 0x00010000  ← Physical address of TSS        │
│ Limit: 0x0067             ← TSS size (103 bytes)           │
│ Access Byte: 0x89         ← TSS type, Ring 0               │
│ Flags: 0x00               ← Standard flags                 │
└─────────────────────────────────────────────────────────────┘

Access Byte Breakdown (0x89):
┌─┬─────┬─┬─┬─────┬─┬─┬─┐
│1│ 00  │0│1│ 001 │0│0│1│
└─┴─────┴─┴─┴─────┴─┴─┴─┘
 │  │    │ │  │    │ │ │
 │  │    │ │  │    │ │ └─ Accessed bit
 │  │    │ │  │    │ └─── Reserved
 │  │    │ │  │    └───── Busy bit (0=available, 1=busy)
 │  │    │ │  └────────── TSS type (1001 = available TSS)
 │  │    │ └─────────────── System descriptor (0)
 │  │    └───────────────── Reserved
 │  └────────────────────── Privilege level (00 = Ring 0)
 └───────────────────────── Present (1 = valid)
</code></pre><p><strong>Key Differences by Descriptor Type</strong></p><p><strong>Bits 3-0 Interpretation</strong></p><ul><li><p>Application Descriptors (S=1):</p><ul><li>Bit 3: Executable (1=code, 0=data)</li><li>Bit 2: Direction/Conforming</li><li>Bit 1: Read/Write permission</li><li>Bit 0: Accessed by CPU</li></ul></li><li><p>System Descriptors (S=0):</p><ul><li>Bits 3-0: System type (TSS, LDT, gates, etc.)</li></ul></li></ul><pre tabindex=0><code>System Types:
0001 = Available 286 TSS
0010 = LDT
0011 = Busy 286 TSS  
0100 = 286 Call Gate
0101 = Task Gate
0110 = 286 Interrupt Gate
0111 = 286 Trap Gate
1001 = Available 386 TSS
1011 = Busy 386 TSS
(others reserved)
</code></pre><h3 id=task-switching-process>Task Switching Process<a hidden class=anchor aria-hidden=true href=#task-switching-process>#</a></h3><p>When the CPU executes a task switch instruction, here&rsquo;s exactly what happens:</p><pre tabindex=0><code>Task Switch: JMP 0x0030  ; Jump to task with TSS at GDT entry 6

Hardware Sequence:
┌─────────────────────────────────────────────────────────────┐
│ Step 1: Identify Target Task                                │
│ • Extract index from selector 0x0030 → Index 6              │
│ • Look up GDT entry 6 → TSS descriptor                      │
│ • Get TSS base address and verify it&#39;s a valid TSS          │
├─────────────────────────────────────────────────────────────┤
│ Step 2: Save Current Task State                             │
│ • Get current TSS address (from TR register)                │
│ • Save all CPU registers to current TSS:                    │
│   - Store AX at TSS+0x12h                                   │
│   - Store CX at TSS+0x14h                                   │
│   - Store DX at TSS+0x16h                                   │
│   - ... (save all registers and flags)                      │
│   - Store IP at TSS+0x0Eh                                   │
│   - Store segment registers                                 │
├─────────────────────────────────────────────────────────────┤
│ Step 3: Mark Tasks                                          │
│ • Set current TSS descriptor busy bit = 0 (available)       │
│ • Set target TSS descriptor busy bit = 1 (busy)             │
├─────────────────────────────────────────────────────────────┤
│ Step 4: Load New Task State                                 │
│ • Load all registers from target TSS:                       │
│   - Load AX from TSS+0x12h                                  │
│   - Load CX from TSS+0x14h                                  │
│   - ... (load all registers and flags)                      │
│   - Load IP from TSS+0x0Eh                                  │
│   - Load segment registers                                  │
├─────────────────────────────────────────────────────────────┤
│ Step 5: Update Memory Management                            │
│ • Load LDT selector from TSS+0x2Ah                          │
│ • Update LDTR register → new task&#39;s private memory view     │
│ • Flush segment register caches                             │
├─────────────────────────────────────────────────────────────┤
│ Step 6: Update Task Register                                │
│ • Store new TSS selector in TR register                     │
│ • Cache new TSS descriptor in hidden portion                │
├─────────────────────────────────────────────────────────────┤
│ Step 7: Continue Execution                                  │
│ • Begin executing at CS:IP from new TSS                     │
│ • Task switch complete!                                     │
└─────────────────────────────────────────────────────────────┘
</code></pre><p>Total time: ~17-34 clock cycles (extremely fast!)</p><h3 id=privilege-level-stack-management>Privilege Level Stack Management<a hidden class=anchor aria-hidden=true href=#privilege-level-stack-management>#</a></h3><p>Each privilege level (Ring 0-3) needs its own separate stack for each program for security and proper operation:</p><h4 id=why-multiple-stacks-are-needed>Why Multiple Stacks are Needed?<a hidden class=anchor aria-hidden=true href=#why-multiple-stacks-are-needed>#</a></h4><pre tabindex=0><code>Security Problem Without Separate Stacks:
┌─────────────────────────────────────────────────────────────┐
│ User Program (Ring 3) stack contains:                      │
│ ┌─────────────────────────────────────────────────────────┐ │
│ │ User data, local variables, function calls             │ │
│ │ Potentially malicious or corrupted data                │ │
│ └─────────────────────────────────────────────────────────┘ │
│                                                             │
│ System Call (Ring 3 → Ring 0):                            │
│ If kernel uses same stack:                                  │
│ ❌ Kernel data mixed with user data                        │
│ ❌ User could corrupt kernel stack                         │
│ ❌ Security vulnerability                                  │
│ ❌ Kernel crash could corrupt user stack                   │
└─────────────────────────────────────────────────────────────┘

Solution - Separate Stacks:
┌─────────────────────────────────────────────────────────────┐
│ Ring 0 Stack (Kernel):                                     │
│ ┌─────────────────────────────────────────────────────────┐ │
│ │ Kernel local variables, system call parameters         │ │
│ │ Protected from user access                              │ │
│ └─────────────────────────────────────────────────────────┘ │
│                                                             │
│ Ring 3 Stack (User):                                       │
│ ┌─────────────────────────────────────────────────────────┐ │
│ │ User program data, function calls                       │ │
│ │ Cannot affect kernel operations                         │ │
│ └─────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────┘
</code></pre><h4 id=stack-pointer-sp-and-stack-segment-ss-explained>Stack Pointer (SP) and Stack Segment (SS) Explained<a hidden class=anchor aria-hidden=true href=#stack-pointer-sp-and-stack-segment-ss-explained>#</a></h4><ul><li><strong>Stack Pointer (SP):</strong> The offset within the stack segment where the stack currently &ldquo;points&rdquo;</li><li><strong>Stack Segment (SS):</strong> The selector that identifies which memory segment contains the stack</li></ul><h4 id=how-stack-switching-works>How Stack Switching Works?<a hidden class=anchor aria-hidden=true href=#how-stack-switching-works>#</a></h4><pre tabindex=0><code>Privilege Level Change Example:

User Program (Ring 3) makes system call:
┌─────────────────────────────────────────────────────────────┐
│ Current State:                                              │
│ SS = 0x0010 (user data segment)                             │
│ SP = 0x7FF0 (user stack pointer)                            │
│ CPL = 3 (Ring 3)                                            │
└─────────────────────────────────────────────────────────────┘
                           │
                           ▼ INT 21h (system call)
┌─────────────────────────────────────────────────────────────┐
│ Hardware automatically:                                     │
│ 1. Detects privilege change: Ring 3 → Ring 0                │
│ 2. Gets Ring 0 stack from current TSS:                      │
│    SS0 = 0x0008, SP0 = 0x7C00                               │
│ 3. Switches to Ring 0 stack:                                │
│    SS = 0x0008, SP = 0x7C00                                 │
│ 4. Pushes Ring 3 context onto Ring 0 stack:                 │
│    - Push old SS (0x0010)                                   │
│    - Push old SP (0x7FF0)                                   │
│    - Push FLAGS                                             │
│    - Push CS                                                │
│    - Push IP                                                │
│ 5. Loads interrupt handler address                          │
└─────────────────────────────────────────────────────────────┘
                           │
                           ▼
┌────────────────────────────────────────────────────────────┐
│ Now Running in Ring 0:                                     │
│ SS = 0x0008 (kernel data segment)                          │
│ SP = 0x7BF6 (adjusted after pushes)                        │
│ CPL = 0 (Ring 0)                                           │
│                                                            │
│ Ring 0 stack now contains:                                 │
│ [SP+12]: Old SS (0x0010)                                   │
│ [SP+10]: Old SP (0x7FF0)                                   │
│ [SP+8]:  Old FLAGS                                         │
│ [SP+6]:  Old CS                                            │
│ [SP+4]:  Old IP                                            │
│ [SP+2]:  (space for kernel use)                            │
│ [SP+0]:  (current stack top)                               │
└────────────────────────────────────────────────────────────┘
</code></pre><h4 id=ring-1-and-ring-2-stacks>Ring 1 and Ring 2 Stacks<a hidden class=anchor aria-hidden=true href=#ring-1-and-ring-2-stacks>#</a></h4><pre tabindex=0><code>Ring Usage in Practice:
┌─────────────────────────────────────────────────────────────┐
│ Ring 0: Operating System Kernel                            │
│ • SS0/SP0: Most critical system operations                 │
│ • Memory management, process switching                     │
│ • Hardware interrupt handlers                              │
├─────────────────────────────────────────────────────────────┤
│ Ring 1: Device Drivers (Rarely Used)                       │
│ • SS1/SP1: Device driver code                             │
│ • Some operating systems use this for drivers              │
│ • Most modern systems use Ring 0 for drivers               │
├─────────────────────────────────────────────────────────────┤
│ Ring 2: System Services (Rarely Used)                      │
│ • SS2/SP2: System service layer                           │
│ • Most systems jump directly from Ring 3 to Ring 0        │
│ • Some experimental OS designs used this                   │
├─────────────────────────────────────────────────────────────┤
│ Ring 3: User Applications                                  │
│ • SS/SP: Normal application stack                          │
│ • Regular program execution                                │
│ • Cannot directly access lower rings                       │
└─────────────────────────────────────────────────────────────┘

Typical Stack Usage:
Most 80286 systems only used Ring 0 and Ring 3:
- SS0/SP0: Kernel stack  
- SS1/SP1: Usually 0 (unused)
- SS2/SP2: Usually 0 (unused)  
- SS/SP: User application stack
</code></pre><p>When user program makes system call:</p><ol><li>Hardware saves user context on kernel stack (SS0:SP0)</li><li>Kernel operations use kernel stack space</li><li>When returning, hardware restores user context</li><li>User program continues with user stack (SS:SP)</li></ol><h4 id=why-each-program-gets-its-own-kernel-stack-even-though-kernel-code-is-common-for-all>Why Each Program Gets its own Kernel Stack Even though Kernel Code is Common for all?<a hidden class=anchor aria-hidden=true href=#why-each-program-gets-its-own-kernel-stack-even-though-kernel-code-is-common-for-all>#</a></h4><p>If there was only one kernel stack for the entire OS, here&rsquo;s what would happen:</p><pre tabindex=0><code>Single Global Kernel Stack Problem:
┌─────────────────────────────────────────────────────────────┐
│ Task A makes system call:                                   │
│ ┌─────────────────────────────────────────────────────────┐ │
│ │ Global Kernel Stack:                                    │ │
│ │ [Task A&#39;s saved context]                                │ │
│ │ [Kernel local variables for Task A]                     │ │
│ │ [System call parameters]                                │ │
│ └─────────────────────────────────────────────────────────┘ │
│                                                             │
│ Timer interrupt occurs → Task Switch to Task B:             │
│ ❌ Task A&#39;s kernel context still on global stack!           │
│                                                             │
│ Task B makes system call:                                   │
│ ┌─────────────────────────────────────────────────────────┐ │
│ │ Global Kernel Stack (CORRUPTED):                        │ │
│ │ [Task A&#39;s saved context] ← Still there!                 │ |
│ │ [Task A&#39;s kernel variables] ← Still there!              │ |
│ │ [Task B&#39;s saved context] ← New data overwrites!         │ │
│ │ [Task B&#39;s kernel variables]                             │ │
│ └─────────────────────────────────────────────────────────┘ │
│                                                             │
│ When Task A resumes:                                        │
│ ❌ Its kernel context is corrupted                          │
│ ❌ System crash or data corruption                          │
└─────────────────────────────────────────────────────────────┘
</code></pre><h4 id=why-each-task-needs-its-own-kernel-stack>Why Each Task Needs Its Own Kernel Stack<a hidden class=anchor aria-hidden=true href=#why-each-task-needs-its-own-kernel-stack>#</a></h4><p>Each task gets its own kernel stack because:</p><ul><li>Task can be preempted while in kernel mode</li><li>Kernel context must be preserved per task</li><li>Multiple tasks can have pending system calls</li><li>Recursion and nested operations</li></ul><h4 id=shared-kernel-segment-separate-stack-areas>Shared Kernel Segment, Separate Stack Areas<a hidden class=anchor aria-hidden=true href=#shared-kernel-segment-separate-stack-areas>#</a></h4><p>The kernel memory segment is shared, but each task gets its own stack area within that segment:</p><pre tabindex=0><code>Kernel Memory Layout:
┌────────────────────────────────────────────────────────────┐
│              Kernel Data Segment (Selector 0x0008)         │
│                    Base Address: 0x100000                  │
├────────────────────────────────────────────────────────────┤
│ 0x100000: Kernel Code                                      │
│ 0x110000: Kernel Global Data                               │
│ 0x120000: Kernel Heap                                      │
│ 0x130000: ┌─────────────────────────────────────────────┐  │
│           │ Task A Kernel Stack                         │  │
│ 0x131000: │ ← Task A&#39;s SS0:SP0 = 0x0008:0x31000         │  │
│           └─────────────────────────────────────────────┘  │
│ 0x131000: ┌─────────────────────────────────────────────┐  │
│           │ Task B Kernel Stack                         │  │
│ 0x132000: │ ← Task B&#39;s SS0:SP0 = 0x0008:0x32000         │  │
│           └────────────────────────────────────────-────┘  │
│ 0x132000: ┌─────────────────────────────────────────────┐  │
│           │ Task C Kernel Stack                         │  │
│ 0x133000: │ ← Task C&#39;s SS0:SP0 = 0x0008:0x33000         │  │
│           └-────────────────────────────────────────────┘  │
│ 0x140000: Other Kernel Data                                │
└────────────────────────────────────────────────────────────┘

Key Point: Same SS0 (0x0008), Different SP0 values
</code></pre><h3 id=tss-stack-pointer-management>TSS Stack Pointer Management<a hidden class=anchor aria-hidden=true href=#tss-stack-pointer-management>#</a></h3><pre tabindex=0><code>Task Creation Process:
┌─────────────────────────────────────────────────────────────┐
│ When OS creates new task:                                   │
│                                                             │
│ 1. Allocate kernel stack space:                             │
│    kernel_stack_base = allocate_kernel_stack()              │
│    // Returns something like 0x31000                        │
│                                                             │
│ 2. Set up TSS:                                              │
│    task_tss.SS0 = KERNEL_DATA_SELECTOR  // 0x0008           │
│    task_tss.SP0 = kernel_stack_base     // 0x31000          │
│                                                             │
│ 3. When task makes system call:                             │
│    Hardware automatically switches to SS0:SP0               │
│    Now using this task&#39;s private kernel stack area          │
│                                                             │
│ 4. When task switch occurs:                                 │
│    Each task&#39;s kernel stack remains intact                  │
│    Next task uses its own SS0:SP0 values                    │
└─────────────────────────────────────────────────────────────┘
</code></pre><h4 id=real-world-example-system-call-with-task-switch>Real-World Example: System Call with Task Switch<a hidden class=anchor aria-hidden=true href=#real-world-example-system-call-with-task-switch>#</a></h4><pre tabindex=0><code>Scenario: Task A calls file read, gets blocked, Task B runs

Step 1: Task A makes system call
┌─────────────────────────────────────────────────────────────┐
│ Task A (Ring 3): INT 21h  ; Read file                       │
│                                                             │
│ Hardware switches to Task A&#39;s kernel stack:                 │
│ SS = 0x0008, SP = 0x31000 (Task A&#39;s kernel stack)           │
│                                                             │
│ Task A&#39;s Kernel Stack (0x31000):                            │
│ [Task A&#39;s user SS:SP]                                       │
│ [Task A&#39;s user FLAGS]                                       │
│ [Task A&#39;s user CS:IP]                                       │
│ [Kernel local variables for file operation]                 │
│ [File system state]                                         │
└─────────────────────────────────────────────────────────────┘

Step 2: File not ready, Task A blocks
┌─────────────────────────────────────────────────────────────┐
│ Kernel: File not available, block Task A                    │
│                                                             │
│ Kernel performs task switch to Task B:                      │
│ JMP task_b_selector                                         │
│                                                             │
│ Hardware saves current state to Task A&#39;s TSS:               │
│ - Current SS (0x0008) → Task A TSS                          │
│ - Current SP (0x30F80) → Task A TSS  ← Note: changed!       │
│ - All registers → Task A TSS                                │
│                                                             │
│ Hardware loads Task B&#39;s state:                              │
│ - SS = Task B&#39;s user SS                                     │
│ - SP = Task B&#39;s user SP                                     │
│ - SS0 = 0x0008, SP0 = 0x32000  ← Task B&#39;s kernel stack      │
└─────────────────────────────────────────────────────────────┘

Step 3: Task B runs and makes system call
┌─────────────────────────────────────────────────────────────┐
│ Task B (Ring 3): INT 10h  ; Video operation                 │
│                                                             │
│ Hardware switches to Task B&#39;s kernel stack:                 │
│ SS = 0x0008, SP = 0x32000 (Task B&#39;s kernel stack)           │
│                                                             │
│ Memory State:                                               │
│ Task A&#39;s Kernel Stack (0x31000): [Preserved file operation] │
│ Task B&#39;s Kernel Stack (0x32000): [New video operation]      │
│                                                             │
│ Both stacks coexist safely!                                 │
└─────────────────────────────────────────────────────────────┘

Step 4: Task A resumes later
┌─────────────────────────────────────────────────────────────┐
│ File becomes available, switch back to Task A:              │
│ JMP task_a_selector                                         │
│                                                             │
│ Hardware loads Task A&#39;s state from TSS:                     │
│ - SS = 0x0008, SP = 0x30F80  ← Back to Task A kernel stack  │
│                                                             │
│ Task A&#39;s kernel stack is exactly as it was left:            │
│ [Task A&#39;s user context]                                     │
│ [File operation state] ← Still there!                       │
│ [Kernel variables] ← All preserved!                         │
│                                                             │
│ Kernel completes file operation and returns to user         │
└─────────────────────────────────────────────────────────────┘
</code></pre><h4 id=why-this-design-is-necessary>Why This Design Is Necessary<a hidden class=anchor aria-hidden=true href=#why-this-design-is-necessary>#</a></h4><p><strong>Fundamental Requirements</strong></p><ul><li><strong>Reentrancy:</strong> Multiple tasks can be &ldquo;inside&rdquo; the kernel simultaneously</li><li><strong>Preemption:</strong> Tasks can be switched even while in kernel mode</li><li><strong>State Preservation:</strong> Each task&rsquo;s kernel context must survive task switches</li><li><strong>Isolation:</strong> One task&rsquo;s kernel operations can&rsquo;t interfere with another&rsquo;s</li></ul><h4 id=alternative-approaches-used-in-some-systems>Alternative Approaches (Used in Some Systems)<a hidden class=anchor aria-hidden=true href=#alternative-approaches-used-in-some-systems>#</a></h4><pre tabindex=0><code>Alternative 1: Non-preemptive Kernel
┌─────────────────────────────────────────────────────────────┐
│ • Only one task in kernel at a time                         │
│ • Disable task switching during system calls                │
│ • Simpler: can use single kernel stack                      │
│ • Problem: Poor responsiveness, no true multitasking        │
└─────────────────────────────────────────────────────────────┘

Alternative 2: Kernel Threads (Modern Approach)
┌─────────────────────────────────────────────────────────────┐
│ • Separate kernel thread handles each system call           │
│ • User task blocks, kernel thread continues                 │
│ • More complex but better scalability                       │
│ • Used in modern operating systems                          │
└─────────────────────────────────────────────────────────────┘
</code></pre><h3 id=the-stack-collision-problem>The Stack Collision Problem<a hidden class=anchor aria-hidden=true href=#the-stack-collision-problem>#</a></h3><p>How Stack Collision Occurs</p><pre tabindex=0><code>Stack Growth Problem:
┌─────────────────────────────────────────────────────────────┐
│ Normal State:                                               │
│ 0x130000: ┌────────────────────────────────────────── ───┐  │
│            │ Task A Kernel Stack                         │  │
│            │ [Some data]                                 │  │
│            │ [Some data]                                 │  │
│ 0x130800:  │ ← Current SP0 (stack grows down)            │  │
│            │ [Free space]                                │  │
│ 0x131000:  └─────────────────────────────────────────────┘  │
│ 0x131000: ┌──────────────────────────────────────────── ─┐  │
│            │ Task B Kernel Stack                         │  │
│ 0x131800:  │ ← Current SP0                               │  │
│            │ [Free space]                                │  │
│ 0x132000:  └─────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────┘

Stack Overflow Scenario:
┌─────────────────────────────────────────────────────────────┐
│ Task A makes deep system call with many nested functions:   │
│ 0x130000: ┌───────────────────────────────────────────── ┐  │
│            │ Task A Kernel Stack                         │  │
│            │ [Deep call stack]                           │  │
│            │ [Local variables]                           │  │
│            │ [More function calls]                       │  │
│            │ [Even more data]                            │  │
│ 0x130F00:  │ ← SP0 approaching limit                     │  │
│            │ [Critical: Almost full!]                    │  │
│ 0x131000:  └─────────────────────────────────────────────┘  │
│ 0x131000: ┌─────────────────────────────────────────── ──┐  │
│            │ Task B Kernel Stack ← CORRUPTED!            │  │
│            │ [Task A overflow data] ← Wrong task data!   │  │
│ 0x131800:  │ ← Task B&#39;s SP0                              │  │
│ 0x132000:  └─────────────────────────────────────────────┘  │
│                                                             │
│ Result: Task A corrupts Task B&#39;s kernel stack               │
│         System crash, data corruption, security breach      │
└─────────────────────────────────────────────────────────────┘
</code></pre><h4 id=real-world-solutions>Real-World Solutions<a hidden class=anchor aria-hidden=true href=#real-world-solutions>#</a></h4><p><strong>1. Stack Size Planning and Limits</strong></p><pre tabindex=0><code>Conservative Stack Allocation:
┌─────────────────────────────────────────────────────────────┐
│ Better Layout with Larger Gaps:                             │
├─────────────────────────────────────────────────────────────┤
│ 0x130000:  ┌─────────────────────────────────────────────┐  │
│            │ Task A Kernel Stack (8KB)                   │  │
│ 0x132000:  └─────────────────────────────────────────────┘  │
│ 0x132000:  ┌─────────────────────────────────────────────┐  │
│            │ Task B Kernel Stack (8KB)                   │  │
│ 0x134000:  └─────────────────────────────────────────────┘  │
│ 0x134000:  ┌──────────────────────────────────────────-──┐  │
│            │ Task C Kernel Stack (8KB)                   │  │
│ 0x136000:  └─────────────────────────────────────────────┘  │
│                                                             │
│ Advantages:                                                 │
│ ✅ Larger stacks reduce overflow risk                       │
│ ✅ Clear boundaries                                         │
│ ❌ Wastes memory if stacks are small                        │
└─────────────────────────────────────────────────────────────┘
</code></pre><p><strong>2. Guard Pages (Modern Approach)</strong></p><pre tabindex=0><code>Stack with Guard Pages:
┌─────────────────────────────────────────────────────────────┐
│ 0x130000:  ┌───────────────────────────────────────--────┐  │
│            │ Task A Kernel Stack (4KB)                   │  │
│ 0x131000:  └─────────────────────────────────────────────┘  │
│ 0x131000:  ┌────────────────────────────────────────--───┐  │
│            │ GUARD PAGE (unmapped/protected)             │  │
│ 0x132000:  └─────────────────────────────────────────────┘  │
│ 0x132000:  ┌───────────────────────────────────────-─────┐  │
│            │ Task B Kernel Stack (4KB)                   │  │
│ 0x133000:  └─────────────────────────────────────────────┘  │
│                                                             │
│ How it works:                                               │
│ • Guard page has no memory mapped                           │
│ • Stack overflow triggers page fault                        │
│ • Kernel can detect and handle gracefully                   │
│ • Kill offending task instead of corrupting memory          │
└─────────────────────────────────────────────────────────────┘
</code></pre><p><strong>3. Stack Bounds Checking</strong></p><pre tabindex=0><code>; Kernel stack overflow detection
check_stack_overflow:
    mov ax, sp                  ; Get current stack pointer
    cmp ax, stack_limit         ; Compare with minimum allowed
    jb stack_overflow_handler   ; Jump if below limit
    ret

stack_overflow_handler:
    ; Emergency handling:
    ; 1. Log the error
    ; 2. Kill the current task
    ; 3. Switch to a safe task
    ; 4. Prevent system crash
</code></pre><p><strong>4. Dynamic Stack Expansion (Advanced)</strong></p><pre tabindex=0><code>Expandable Stacks:
┌─────────────────────────────────────────────────────────────┐
│ Initial Allocation (Small):                                 │
│ 0x130000:  ┌─────────────────────────────────────────────┐  │
│            │ Task A Initial Stack (1KB)                  │  │
│ 0x130400:  └─────────────────────────────────────────────┘  │
│            │ Expansion Area (monitored)                  │  │
│ 0x131000:  ┌─────────────────────────────────────────────┐  │
│            │ Task B Initial Stack (1KB)                  │  │
│ 0x131400:  └─────────────────────────────────────────────┘  │
│                                                             │
│ On Near-Overflow:                                           │
│ • Kernel detects stack approaching limit                    │
│ • Allocates more space if available                         │
│ • Updates stack boundaries                                  │
│ • Continues operation                                       │
└─────────────────────────────────────────────────────────────┘
</code></pre><h4 id=what-80286-systems-actually-did>What 80286 Systems Actually Did<a hidden class=anchor aria-hidden=true href=#what-80286-systems-actually-did>#</a></h4><pre tabindex=0><code>Typical 80286 Approach:
┌────────────────────────────────────────────────────────────┐
│ Conservative Fixed Allocation:                             │
│                                                            │
│ 1. Large Fixed Stack Sizes:                                │
│    • Each task: 4KB-8KB kernel stack                       │
│    • Over-provision to avoid overflow                      │
│    • Waste memory but ensure safety                        │
│                                                            │
│ 2. Task Limits:                                            │
│    • Limit number of concurrent tasks                      │
│    • Reduce memory pressure                                │
│    • Simpler management                                    │
│                                                            │
│ 3. Programming Discipline:                                 │
│    • Avoid deep recursion in kernel                        │
│    • Minimize local variables                              │
│    • Use heap for large data structures                    │
│                                                            │
│ 4. System Monitoring:                                      │
│    • Debug builds check stack usage                        │
│    • Runtime stack depth monitoring                        │
│    • Early warning systems                                 │
└────────────────────────────────────────────────────────────┘
</code></pre><h4 id=example-os2-approach>Example: OS/2 Approach<a hidden class=anchor aria-hidden=true href=#example-os2-approach>#</a></h4><pre tabindex=0><code>OS/2 Stack Management:
┌─────────────────────────────────────────────────────────────┐
│ Thread Creation:                                            │
│ • Default kernel stack: 8KB per thread                      │
│ • Configurable stack sizes                                  │
│ • Stack committed on demand                                 │
│                                                             │
│ Stack Layout:                                               │
│ ┌─────────────────────────────────────────────────────────┐ │
│ │ Thread 1: 8KB kernel stack                              │ │
│ │ Thread 2: 8KB kernel stack                              │ │
│ │ Thread 3: 8KB kernel stack                              │ │
│ │ (Large gaps to prevent collision)                       │ │
│ └─────────────────────────────────────────────────────────┘ │
│                                                             │
│ Protection:                                                 │
│ • Memory manager tracks allocations                         │
│ • Stack overflow detected by memory manager                 │
│ • Graceful task termination instead of corruption           │
└─────────────────────────────────────────────────────────────┘
</code></pre><h4 id=how-modern-systems-handle-this>How Modern Systems Handle This<a hidden class=anchor aria-hidden=true href=#how-modern-systems-handle-this>#</a></h4><pre tabindex=0><code>Modern Approach (Linux/Windows):
┌─────────────────────────────────────────────────────────────┐
│ Virtual Memory + Guard Pages:                               │
│                                                             │
│ Each process/thread gets:                                   │
│ • Virtual address space                                     │
│ • Guard pages at stack boundaries                           │
│ • Page fault handling for overflow                          │
│ • Dynamic expansion up to limits                            │
│                                                             │
│ Benefits:                                                   │
│ ✅ No memory waste                                          │
│ ✅ Automatic protection                                     │
│ ✅ Scales to thousands of threads                           │
│ ✅ Hardware-assisted detection                              │
│                                                             │
│ 80286 Limitations:                                          │
│ ❌ No virtual memory/paging                                 │
│ ❌ Limited memory management                                │
│ ❌ Must use simpler approaches                              │
└─────────────────────────────────────────────────────────────┘
</code></pre><h3 id=previous-tss-link>Previous TSS Link<a hidden class=anchor aria-hidden=true href=#previous-tss-link>#</a></h3><p>The Previous TSS Link supports task calling chains - when one task calls another task (not just jumps to it).</p><pre tabindex=0><code>Task Calling vs Task Jumping:

Task Jump (JMP):
Task A ──JMP──→ Task B
         │
         └─ Task A stops, Task B runs
            No way to return to Task A

Task Call (CALL):  
Task A ──CALL──→ Task B ──IRET──→ Task A
         │                        │
         └─ Task A suspended ──────┘
            Task B can return to Task A
</code></pre><h4 id=how-previous-task-link-works>How Previous Task Link Works<a hidden class=anchor aria-hidden=true href=#how-previous-task-link-works>#</a></h4><pre tabindex=0><code>Example Task Calling Chain:

Step 1: Main Program calls Print Service
┌─────────────────────────────────────────────────────────────┐
│ Main Program TSS (Selector 0x0030)                         │
│ Previous Link: 0x0000 (no caller)                          │
│ CALL 0x0038  ; Call Print Service Task                     │
└─────────────────────────────────────────────────────────────┘
                           │
                           ▼
┌─────────────────────────────────────────────────────────────┐
│ Print Service TSS (Selector 0x0038)                        │
│ Previous Link: 0x0030 ← Points back to Main Program        │
│ CALL 0x0040  ; Call File I/O Task                         │
└─────────────────────────────────────────────────────────────┘
                           │
                           ▼
┌─────────────────────────────────────────────────────────────┐
│ File I/O TSS (Selector 0x0040)                             │
│ Previous Link: 0x0038 ← Points back to Print Service       │
│ IRET  ; Return to previous task                            │
└─────────────────────────────────────────────────────────────┘

When File I/O executes IRET:
1. CPU reads Previous Link (0x0038)
2. Switches back to Print Service TSS
3. Print Service continues where it left off

When Print Service executes IRET:
1. CPU reads Previous Link (0x0030)  
2. Switches back to Main Program TSS
3. Main Program continues after the CALL
</code></pre><h4 id=hardware-behavior>Hardware Behavior<a hidden class=anchor aria-hidden=true href=#hardware-behavior>#</a></h4><pre tabindex=0><code>CALL task_selector behavior:
1. Save current state to current TSS
2. Set target TSS Previous Link = current TSS selector
3. Switch to target task
4. Target task can later use IRET to return

JMP task_selector behavior:
1. Save current state to current TSS  
2. Target TSS Previous Link unchanged (usually 0)
3. Switch to target task
4. No automatic return mechanism
</code></pre><h3 id=tss-benefits-and-limitations>TSS Benefits and Limitations<a hidden class=anchor aria-hidden=true href=#tss-benefits-and-limitations>#</a></h3><h4 id=advantages-of-hardware-task-switching>Advantages of Hardware Task Switching<a hidden class=anchor aria-hidden=true href=#advantages-of-hardware-task-switching>#</a></h4><p><strong>1. Atomic Operation</strong></p><ul><li>Complete task switch in single instruction</li><li>Cannot be interrupted midway</li><li>Guaranteed consistent state</li></ul><p><strong>2. Performance</strong></p><ul><li>Extremely fast: ~17-34 clock cycles</li><li>No manual register save/restore needed</li><li>Hardware optimized</li></ul><p><strong>3. Reliability</strong></p><ul><li>Cannot forget to save registers</li><li>Hardware enforced privilege management</li><li>Automatic stack switching</li></ul><p><strong>4. Security</strong></p><ul><li>Memory isolation through LDT switching</li><li>Privilege level enforcement</li><li>Protected task linkage</li></ul><h4 id=limitations-and-problems>Limitations and Problems<a hidden class=anchor aria-hidden=true href=#limitations-and-problems>#</a></h4><p><strong>1. Memory Overhead</strong></p><pre tabindex=0><code>Each task requires:
- 44+ bytes for TSS
- 8 bytes for TSS descriptor in GDT
- Separate stacks for each privilege level
- Private LDT (optional but recommended)
</code></pre><p>For 100 tasks: ~5KB just for task management</p><p><strong>2. GDT Size Limitations</strong></p><pre tabindex=0><code>GDT maximum size: 65536 bytes
Each TSS descriptor: 8 bytes
Maximum tasks: ~8000 (practical limit much lower)
</code></pre><p><strong>3. Inflexibility</strong></p><pre tabindex=0><code>- Fixed TSS structure
- Cannot customize task switch behavior
- All-or-nothing: must save ALL registers
- Cannot optimize for specific use cases
</code></pre><p><strong>4. Scalability Issues</strong></p><pre tabindex=0><code>Modern systems with thousands of threads:
- Would need thousands of TSS structures
- GDT would become enormous
- Memory fragmentation problems
</code></pre><h4 id=evolution-beyond-80286>Evolution Beyond 80286<a hidden class=anchor aria-hidden=true href=#evolution-beyond-80286>#</a></h4><p><strong>Why Modern Systems Don&rsquo;t Use Hardware Task Switching</strong></p><pre tabindex=0><code>Modern Software Task Switching:
┌─────────────────────────────────────────────────────────────┐
│ Advantages:                                                 │
│ ✅ Flexible task structure                                  │
│ ✅ Can save only necessary registers                        │
│ ✅ Custom scheduling algorithms                             │
│ ✅ Supports unlimited tasks                                 │
│ ✅ More efficient memory usage                              │
│ ✅ Better cache performance                                 │
│                                                             │
│ Trade-offs:                                                 │
│ ❌ More complex kernel code                                 │
│ ❌ Slightly slower (but caches help)                        │
│ ❌ Must be carefully implemented                            │
└─────────────────────────────────────────────────────────────┘
</code></pre><h4 id=legacy-of-tss>Legacy of TSS<a hidden class=anchor aria-hidden=true href=#legacy-of-tss>#</a></h4><p>Even though modern x86 systems don&rsquo;t use hardware task switching for multitasking, the TSS remains important:</p><ul><li><strong>One TSS per CPU</strong> for privilege level stack management</li><li><strong>System call stack switching</strong> still uses TSS stack pointers</li><li><strong>Interrupt handling</strong> relies on TS</li></ul><h2 id=the-memory-management-unit-mmu>The Memory Management Unit (MMU)<a hidden class=anchor aria-hidden=true href=#the-memory-management-unit-mmu>#</a></h2><p>The 80286 was the first x86 processor to introduce an MMU (Memory Management Unit), but it was a simpler form than what we consider a &ldquo;full&rdquo; MMU today. The MMU in the 80286 is a hardware component integrated into the CPU chip itself. THe main purpose of MMU is to translate virtual addresses into physical addresses, along with checking bounds, enforcing privileges, etc.</p><h3 id=key-mmu-functions-introduced-by-80286>Key MMU Functions Introduced by 80286<a hidden class=anchor aria-hidden=true href=#key-mmu-functions-introduced-by-80286>#</a></h3><h4 id=1-hardware-address-translation>1. Hardware Address Translation<a hidden class=anchor aria-hidden=true href=#1-hardware-address-translation>#</a></h4><pre tabindex=0><code>; 8086 - Software calculation:
; Physical = (DS × 16) + SI

; 80286 - Hardware MMU translation:
MOV DS, 0x0008    ; Load selector (points to descriptor)
MOV AL, [SI]      ; MMU automatically:
                  ; 1. Looks up descriptor for selector 0x0008
                  ; 2. Checks permissions and bounds
                  ; 3. Translates to physical address
</code></pre><h4 id=2-memory-protection>2. Memory Protection<a hidden class=anchor aria-hidden=true href=#2-memory-protection>#</a></h4><pre tabindex=0><code>Descriptor Access Rights (enforced by MMU):
┌─┬─-─┬─┬─┬-─┬─-┬─┐
│P│DPL│S│E│DC│RW│A│ ← MMU checks these bits
└─┴─-─┴─┴─┴─-┴-─┴─┘
 │ │  │ │ │  │  │
 │ │  │ │ │  │  └─ Accessed (set by MMU)
 │ │  │ │ │  └──── Read/Write permission
 │ │  │ │ └─────── Direction/Conforming  
 │ │  │ └───────── Executable bit
 │ │  └─────────── Descriptor type
 │ └────────────── Privilege level (0-3)
 └──────────────── Present bit

MMU generates protection fault if access violates these rules
</code></pre><h4 id=3-bounds-checking>3. Bounds Checking<a hidden class=anchor aria-hidden=true href=#3-bounds-checking>#</a></h4><pre tabindex=0><code>Every memory access checked by MMU:
┌─────────────────────────────────────────┐
│ Descriptor Limit = 0x7FFF (32KB)        │
│ Offset = 0x1234                         │
│ MMU Check: 0x1234 ≤ 0x7FFF? ✓ Allow     │
│                                         │
│ Offset = 0x9000                         │  
│ MMU Check: 0x9000 ≤ 0x7FFF? ✗ Fault     │
└─────────────────────────────────────────┘
</code></pre><h3 id=80286-mmu-components>80286 MMU Components<a hidden class=anchor aria-hidden=true href=#80286-mmu-components>#</a></h3><h4 id=1-segment-register-cache-hidden-descriptor-cache>1. Segment Register Cache (Hidden Descriptor Cache)<a hidden class=anchor aria-hidden=true href=#1-segment-register-cache-hidden-descriptor-cache>#</a></h4><h5 id=what-would-happen-without-segment-register-cache>What Would Happen Without Segment Register Cache<a hidden class=anchor aria-hidden=true href=#what-would-happen-without-segment-register-cache>#</a></h5><pre tabindex=0><code>Every Memory Access Without Cache:
┌─────────────────────────────────────────────────────────────┐
│ Program executes: MOV AL, [DS:0x1234]                       │
│                                                             │
│ Without caching, MMU would need to:                         │
│ 1. Read DS selector: 0x0010                                 │
│ 2. Extract index: 2 (from bits 15-3)                        │
│ 3. Calculate GDT address: GDT_base + (2 × 8)                │
│ 4. Read 8 bytes from memory (descriptor)                    │ ← Memory access #1
│ 5. Extract base address from descriptor                     │
│ 6. Add offset: base + 0x1234                                │
│ 7. Finally access target memory                             │ ← Memory access #2
│                                                             │
│ Result: Every memory access requires TWO memory reads!      │
│ Performance: 50% of memory bandwidth wasted on translation  │
└─────────────────────────────────────────────────────────────┘
</code></pre><h5 id=how-each-segment-register-actually-works>How Each Segment Register Actually Works<a hidden class=anchor aria-hidden=true href=#how-each-segment-register-actually-works>#</a></h5><pre tabindex=0><code>Complete Segment Register Structure:
┌─────────────────────────────────────────────────────────────┐
│                    DS Register                              │
├─────────────────────────────────────────────────────────────┤
│ Visible Part (16 bits) - What programmer sees:              │
│ ┌─────────────────────────────────────────────────────────┐ │
│ │ Selector: 0x0010                                        │ │
│ └─────────────────────────────────────────────────────────┘ │
├─────────────────────────────────────────────────────────────┤
│ Hidden Cache (64 bits) - Hardware only:                     │
│ ┌─────────────────┬─────────────┬─────────────────────────┐ │
│ │ Base Address    │ Limit       │ Access Rights           │ │
│ │ 0x00200000      │ 0xFFFF      │ Ring 3, Read/Write      │ │
│ │ (Physical addr) │ (Segment sz)│ (Permissions)           │ │
│ └─────────────────┴─────────────┴─────────────────────────┘ │
├─────────────────────────────────────────────────────────────┤
│ Valid Bit: 1 (cache contains valid data)                    │
└─────────────────────────────────────────────────────────────┘
</code></pre><p>Instead of caching all GDT/LDT entries at MMU level, each segment register caches only one GDT/LDT entry - the one it currently points to:</p><pre tabindex=0><code>Individual Segment Register Caches:
┌─────────────────────────────────────────────────────────────┐
│ CS Register:                                                │
│ ┌─────────────────────────────────────────────────────────┐ │
│ │ Visible: 0x0008 (selector)                              │ │
│ │ Hidden:  [Base: 0x100000, Limit: 0xFFFF, Access: R/X]   │ │
│ └─────────────────────────────────────────────────────────┘ │
├─────────────────────────────────────────────────────────────┤
│ DS Register:                                                │
│ ┌─────────────────────────────────────────────────────────┐ │
│ │ Visible: 0x0010 (selector)                              │ │
│ │ Hidden:  [Base: 0x200000, Limit: 0xFFFF, Access: R/W]   │ │
│ └─────────────────────────────────────────────────────────┘ │
├─────────────────────────────────────────────────────────────┤
│ ES Register:                                                │
│ ┌─────────────────────────────────────────────────────────┐ │
│ │ Visible: 0x0018 (selector)                              │ │
│ │ Hidden:  [Base: 0x300000, Limit: 0x7FFF, Access: R/W]   │ │
│ └─────────────────────────────────────────────────────────┘ │
├─────────────────────────────────────────────────────────────┤
│ SS Register:                                                │
│ ┌─────────────────────────────────────────────────────────┐ │
│ │ Visible: 0x0020 (selector)                              │ │
│ │ Hidden:  [Base: 0x400000, Limit: 0x1FFF, Access: R/W]   │ │
│ └─────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────┘

Each register caches ONE descriptor from GDT/LDT
</code></pre><h5 id=cache-loading-process>Cache Loading Process<a hidden class=anchor aria-hidden=true href=#cache-loading-process>#</a></h5><pre tabindex=0><code>When Segment Register Is Loaded:
┌─────────────────────────────────────────────────────────────┐
│ Program executes: MOV DS, AX  (AX = 0x0010)                 │
│                                                             │
│ Hardware automatically:                                     │
│ 1. Store 0x0010 in DS visible part                          │
│ 2. Extract index: 2                                         │
│ 3. Calculate descriptor address: GDT_base + 16              │
│ 4. Read descriptor from memory (8 bytes)                    │
│ 5. Parse descriptor into components:                        │
│    - Base = 0x00200000                                      │
│    - Limit = 0xFFFF                                         │
│    - Access = Ring 3, Read/Write                            │
│ 6. Store in DS hidden cache                                 │
│ 7. Set valid bit = 1                                        │
│                                                             │
│ This happens ONCE when segment register is loaded           │
└─────────────────────────────────────────────────────────────┘
</code></pre><h5 id=fast-address-translation-with-cache>Fast Address Translation with Cache<a hidden class=anchor aria-hidden=true href=#fast-address-translation-with-cache>#</a></h5><pre tabindex=0><code>Fast Memory Access Using Cache:
┌─────────────────────────────────────────────────────────────┐
│ Program executes: MOV AL, [DS:0x1234]                       │
│                                                             │
│ MMU hardware:                                               │
│ 1. Check DS cache valid bit: 1 ✓                            │
│ 2. Get base from DS cache: 0x00200000                       │
│ 3. Get limit from DS cache: 0xFFFF                          │
│ 4. Check bounds: 0x1234 ≤ 0xFFFF ✓                          │
│ 5. Calculate address: 0x00200000 + 0x1234 = 0x00201234      │
│ 6. Access memory at 0x00201234                              │
│                                                             │
│ Total: ONE memory access (the actual data)                  │
│ No GDT lookup needed!                                       │
└─────────────────────────────────────────────────────────────┘
</code></pre><h5 id=cache-invalidation-and-management>Cache Invalidation and Management<a hidden class=anchor aria-hidden=true href=#cache-invalidation-and-management>#</a></h5><pre tabindex=0><code>Cache Invalidation Scenarios:
┌─────────────────────────────────────────────────────────────┐
│ 1. Segment Register Reload:                                 │
│    MOV DS, AX  ; New selector → invalidate DS cache         │
│                                                             │
│ 2. Task Switch:                                             │
│    JMP task_selector  ; All caches invalidated              │
│                                                             │
│ 3. GDT/LDT Reload:                                          │
│    LGDT [gdt_desc]    ; All caches invalidated              │
│    LLDT selector      ; All LDT-based caches invalidated    │
│                                                             │
│ 4. Descriptor Modification:                                 │
│    If OS modifies GDT/LDT in memory                         │
│    Must manually invalidate affected caches                 │
└─────────────────────────────────────────────────────────────┘
</code></pre><h3 id=what-the-80286-mmu-provided>What the 80286 MMU Provided<a hidden class=anchor aria-hidden=true href=#what-the-80286-mmu-provided>#</a></h3><p><strong>Segmentation-Based Memory Management</strong>
The 80286&rsquo;s MMU implemented:</p><ul><li><strong>Address translation</strong> via descriptor tables (GDT/LDT)</li><li><strong>Memory protection</strong> with privilege levels (rings 0-3)</li><li><strong>Bounds checking</strong> to prevent segment overruns</li><li><strong>Access control</strong> (read/write/execute permissions)</li></ul><h3 id=what-80286-mmu-lacked>What 80286 MMU Lacked<a hidden class=anchor aria-hidden=true href=#what-80286-mmu-lacked>#</a></h3><h4 id=no-virtual-memory>No Virtual Memory<a hidden class=anchor aria-hidden=true href=#no-virtual-memory>#</a></h4><ul><li>All segments had to exist in physical memory</li><li>No demand paging or swapping to disk</li><li>No virtual address spaces larger than physical memory</li></ul><h4 id=no-page-level-protection>No Page-Level Protection<a hidden class=anchor aria-hidden=true href=#no-page-level-protection>#</a></h4><ul><li>Segment-level only - coarse-grained protection</li><li>Cannot protect individual pages within segments</li><li>Limited memory layout flexibility</li></ul><h4 id=no-address-space-isolation>No Address Space Isolation<a hidden class=anchor aria-hidden=true href=#no-address-space-isolation>#</a></h4><ul><li>Shared physical address space among all tasks</li><li>Tasks could potentially access each other&rsquo;s memory if descriptors allowed it</li><li>No true virtual memory isolation</li></ul><h3 id=historical-significance>Historical Significance<a hidden class=anchor aria-hidden=true href=#historical-significance>#</a></h3><p>The 80286 MMU was revolutionary for its time because it:</p><h4 id=introduced-hardware-memory-protection>Introduced Hardware Memory Protection:<a hidden class=anchor aria-hidden=true href=#introduced-hardware-memory-protection>#</a></h4><ul><li>First x86 processor with privilege levels</li><li>Hardware-enforced protection (couldn&rsquo;t be bypassed by software)</li><li>Foundation for modern operating systems</li></ul><h4 id=enabled-multitasking>Enabled Multitasking:<a hidden class=anchor aria-hidden=true href=#enabled-multitasking>#</a></h4><ul><li>Task isolation through separate descriptor tables</li><li>Controlled access to system resources</li><li>Protection from application crashes</li></ul><h4 id=set-architecture-foundation>Set Architecture Foundation:<a hidden class=anchor aria-hidden=true href=#set-architecture-foundation>#</a></h4><ul><li>Descriptor table concept carried forward to 80386</li><li>Privilege level system still used today</li><li>Segmentation principles (though largely superseded by paging)</li></ul><p>While the 80286&rsquo;s MMU was simpler than modern MMUs, it represented the crucial first step from the 8086&rsquo;s &ldquo;wild west&rdquo; of direct memory access to the protected, managed memory systems we use today. The 80386 would later add paging to create the &ldquo;full&rdquo; MMU architecture that became the standard for modern computing.</p><h2 id=ring-level-privileges-in-80286>Ring Level Privileges in 80286<a hidden class=anchor aria-hidden=true href=#ring-level-privileges-in-80286>#</a></h2><p>One of the most revolutionary features introduced by the Intel 80286 was its ring-based privilege system - a hardware-enforced security mechanism that fundamentally changed how computer systems protect themselves from malicious or buggy software. Before the 80286, programs had unrestricted access to all system resources, meaning a single misbehaving application could crash the entire computer or corrupt critical system data.</p><p>The 80286&rsquo;s ring system solved this by creating four distinct privilege levels (Rings 0-3), arranged in a hierarchical structure where each ring has specific permissions and access rights. Think of it like security clearance levels in a government building - higher clearance (lower ring numbers) grants access to more sensitive areas, while lower clearance (higher ring numbers) restricts what you can access.</p><p>The 80286&rsquo;s ring system introduced hardware-enforced separation between different types of code, ensuring that:</p><ul><li><strong>User applications (Ring 3)</strong> could only access their own resources</li><li><strong>Operating system code (Ring 0</strong>) maintained exclusive control over critical hardware</li><li><strong>Device drivers (Ring 1)</strong> had controlled access to specific hardware components</li><li><strong>System services (Ring 2)</strong> provided a middle layer for specialized operations</li></ul><p><a title="Hertzsprung at English Wikipedia, CC BY-SA 3.0 <http://creativecommons.org/licenses/by-sa/3.0/>, via Wikimedia Commons" href=https://commons.wikimedia.org/wiki/File:Priv_rings.svg><img width=512 alt="Privilege rings for the x86 architecture, along with their common uses." src=https://upload.wikimedia.org/wikipedia/commons/thumb/2/2f/Priv_rings.svg/512px-Priv_rings.svg.png?20250128024610></a></p><p>Modern CPU&rsquo;s removed ring 1 and ring 2 as they are not used by any applications because of complex privilege transitions.</p><h3 id=ring-0-the-kernel-domain>Ring 0: The Kernel Domain<a hidden class=anchor aria-hidden=true href=#ring-0-the-kernel-domain>#</a></h3><p>Ring 0 represents the most trusted code in the system - the operating system kernel itself.
Capabilities:</p><ul><li><strong>Direct hardware access:</strong> Can manipulate any I/O port, memory location, or CPU register</li><li><strong>Memory management:</strong> Controls virtual memory, page tables, and segment descriptors</li><li><strong>Interrupt handling:</strong> Manages hardware interrupts and system exceptions</li><li><strong>Task switching:</strong> Can switch between different processes and threads</li><li><strong>Protection control:</strong> Can modify GDT, LDT, and other protection structures</li></ul><p>What runs in Ring 0:</p><pre tabindex=0><code>Typical Ring 0 Components:
┌─────────────────────────────────────────────────────────────┐
│ • Kernel core (scheduler, memory manager)                   │
│ • Device drivers (disk, network, graphics)                  │
│ • Interrupt service routines                                │
│ • System call handlers                                      │
│ • Hardware abstraction layer                                │
└─────────────────────────────────────────────────────────────┘
</code></pre><p><strong>Example Ring 0 Operations:</strong></p><pre tabindex=0><code>; Ring 0 can directly manipulate hardware
OUT 0x3F8, AL      ; Write to serial port
CLI                ; Disable interrupts
STI                ; Enable interrupts
LGDT [gdt_desc]    ; Load new GDT
</code></pre><h3 id=ring-1-device-driver-territory>Ring 1: Device Driver Territory<a hidden class=anchor aria-hidden=true href=#ring-1-device-driver-territory>#</a></h3><p>Ring 1 was designed for device drivers and hardware abstraction layers that need some hardware access but shouldn&rsquo;t have full kernel privileges.</p><p><strong>Intended capabilities:</strong></p><ul><li><strong>Limited hardware access:</strong> Can access specific I/O ports assigned to devices</li><li><strong>Kernel service calls:</strong> Can call Ring 0 services for memory allocation</li><li><strong>Device management:</strong> Direct control over assigned hardware devices</li><li><strong>Protected from user code:</strong> User programs cannot directly call Ring 1 code</li></ul><p><strong>Why it&rsquo;s rarely used:</strong></p><pre tabindex=0><code>Problems with Ring 1:
┌─────────────────────────────────────────────────────────────┐
│ • Complex permission management                             │
│ • Performance overhead of privilege transitions             │
│ • Difficult debugging across privilege boundaries           │
│ • Limited benefits over Ring 0 drivers                      │
│ • Most hardware needs either full access or none            │
└─────────────────────────────────────────────────────────────┘
</code></pre><p><strong>Historical usage:</strong></p><ul><li><strong>Early OS/2:</strong> Attempted to use Ring 1 for some device drivers</li><li><strong>Research systems:</strong> Academic projects exploring multi-level protection</li><li><strong>Embedded systems</strong>: Some real-time systems with strict separation requirements</li></ul><h3 id=ring-2-system-services-layer>Ring 2: System Services Layer<a hidden class=anchor aria-hidden=true href=#ring-2-system-services-layer>#</a></h3><p>Ring 2 was envisioned as a middle layer for system services that needed more privilege than user applications but less than the kernel.</p><p><strong>Intended purposes:</strong></p><ul><li><strong>File system services:</strong> Higher-level file operations</li><li><strong>Network protocol stacks:</strong> TCP/IP implementation</li><li><strong>Graphics subsystems:</strong> Advanced display management</li><li><strong>Database engines:</strong> System-level data management</li></ul><p><strong>Why it failed in practice:</strong></p><pre tabindex=0><code>Ring 2 Challenges:
┌─────────────────────────────────────────────────────────────┐
│ • Unclear boundaries between Ring 1 and Ring 2              │
│ • Most services either needed full kernel access or none    │
│ • Complex inter-ring communication protocols                │
│ • Performance penalties for frequent ring transitions       │
│ • Debugging and troubleshooting complexity                  │
└─────────────────────────────────────────────────────────────┘
</code></pre><h3 id=ring-3-user-application-space>Ring 3: User Application Space<a hidden class=anchor aria-hidden=true href=#ring-3-user-application-space>#</a></h3><p>Ring 3 is where all user applications run - from simple utilities to complex programs like word processors and games.</p><p><strong>Restrictions:</strong></p><ul><li><strong>No direct hardware access:</strong> Cannot use IN/OUT instructions</li><li><strong>No privileged instructions:</strong> Cannot modify system registers</li><li><strong>Limited memory access:</strong> Can only access memory explicitly allocated to the process</li><li><strong>No interrupt control:</strong> Cannot disable interrupts or modify interrupt vectors</li><li><strong>No system structure modification:</strong> Cannot change GDT, LDT, or page tables</li></ul><p><strong>What Ring 3 can do:</strong></p><pre tabindex=0><code>Ring 3 Capabilities:
┌─────────────────────────────────────────────────────────────┐
│ • Access own allocated memory                               │
│ • Perform computational operations                          │
│ • Call system services via controlled interfaces            │
│ • Communicate with other Ring 3 processes (if permitted)    │
│ • Use standard library functions                            │
└─────────────────────────────────────────────────────────────┘
</code></pre><h3 id=privilege-enforcement-mechanisms>Privilege Enforcement Mechanisms<a hidden class=anchor aria-hidden=true href=#privilege-enforcement-mechanisms>#</a></h3><h4 id=current-privilege-level-cpl>Current Privilege Level (CPL)<a hidden class=anchor aria-hidden=true href=#current-privilege-level-cpl>#</a></h4><p>The Current Privilege Level determines what the processor can do at any given moment. It&rsquo;s stored in the lowest 2 bits of the CS (Code Segment) register.</p><pre tabindex=0><code>CS Register Structure:
┌─────────────────────────────────────────────────────────---────┐
│ 15  14  13  12  11  10   9   8   7   6   5   4   3   2   1   0 │
├─────────────────────────────────────────────────────┬───┬───-──┤
│              Segment Index                          │TI │ CPL  │
└─────────────────────────────────────────────────────┴───┴──-───┘
                                                           │
                                                           └─ Current Privilege Level (0-3)
Level (0-3)
</code></pre><p><strong>CPL Examples:</strong></p><ul><li><strong>CPL = 0:</strong> Currently executing Ring 0 (kernel) code</li><li><strong>CPL = 3:</strong> Currently executing Ring 3 (user) code</li></ul><h4 id=descriptor-privilege-level-dpl>Descriptor Privilege Level (DPL)<a hidden class=anchor aria-hidden=true href=#descriptor-privilege-level-dpl>#</a></h4><p>Every segment descriptor (GDT entries) contains a Descriptor Privilege Level that specifies what privilege level is required to access that segment.</p><pre tabindex=0><code>Access Control Rule:
CPL ≤ DPL  (numerically)

Examples:
- CPL = 0, DPL = 2  →  0 ≤ 2  ✓ Access Allowed
- CPL = 3, DPL = 0  →  3 ≤ 0  ✗ Access Denied
- CPL = 1, DPL = 3  →  1 ≤ 3  ✓ Access Allowed
</code></pre><h4 id=privilege-checking-process>Privilege Checking Process<a hidden class=anchor aria-hidden=true href=#privilege-checking-process>#</a></h4><p>When code attempts to access a segment, the 80286 MMU performs automatic privilege checking:</p><pre tabindex=0><code>Memory Access Privilege Check:
┌─────────────────────────────────────────────────────────────┐
│ 1. Extract CPL from CS register                             │
│ 2. Load descriptor for target segment                       │
│ 3. Extract DPL from descriptor                              │
│ 4. Check: CPL ≤ DPL?                                        │
│    - YES: Allow access                                      │
│    - NO:  Generate General Protection Fault (#GP)           │
└─────────────────────────────────────────────────────────────┘
</code></pre><h4 id=privilege-transitions>Privilege Transitions<a hidden class=anchor aria-hidden=true href=#privilege-transitions>#</a></h4><h5 id=1-system-calls-ring-3-to-ring-0>1. System Calls: Ring 3 to Ring 0<a hidden class=anchor aria-hidden=true href=#1-system-calls-ring-3-to-ring-0>#</a></h5><p>User programs cannot directly call kernel functions. Instead, they use controlled entry points called system calls.</p><pre tabindex=0><code>System Call Process:
┌─────────────────────────────────────────────────────────────┐
│ User Program (Ring 3):                                      │
│ INT 21h          ; Software interrupt for DOS services      │
│                                                             │
│ Hardware automatically:                                     │
│ 1. Save current state (CS:IP, FLAGS, SS:SP)                 │
│ 2. Look up interrupt handler in IDT                         │
│ 3. Check privilege level of handler                         │
│ 4. Switch to Ring 0 stack (from TSS)                        │
│ 5. Load Ring 0 code segment                                 │
│ 6. Jump to interrupt handler                                │
│                                                             │
│ Kernel Handler (Ring 0):                                    │
│ ; Process the system call                                   │
│ ; Perform privileged operations                             │
│ IRET             ; Return to user program                   │
│                                                             │
│ Hardware automatically:                                     │
│ 1. Restore user state (CS:IP, FLAGS, SS:SP)                 │
│ 2. Switch back to Ring 3 stack                              │
│ 3. Continue user program execution                          │
└─────────────────────────────────────────────────────────────┘
</code></pre><h5 id=2-call-gates-controlled-ring-transitions>2. Call Gates: Controlled Ring Transitions<a hidden class=anchor aria-hidden=true href=#2-call-gates-controlled-ring-transitions>#</a></h5><p>Call gates provide a mechanism for controlled transitions between privilege levels without using interrupts.</p><pre tabindex=0><code>
Call Gate Structure:
┌─────────────────────────────────────────────────────────────┐
│ • Target segment selector                                   │
│ • Target offset within segment                              │
│ • Parameter count (for stack copying)                       │
│ • Access rights (privilege levels)                          │
└─────────────────────────────────────────────────────────────┘

Usage:
CALL gate_selector    ; Far call through call gate
                      ; Hardware handles privilege transition
</code></pre><h5 id=3-interrupt-and-trap-gates>3. Interrupt and Trap Gates<a hidden class=anchor aria-hidden=true href=#3-interrupt-and-trap-gates>#</a></h5><p>Interrupt gates and trap gates handle hardware interrupts and software exceptions while managing privilege transitions.</p><pre tabindex=0><code>Interrupt Handling:
┌─────────────────────────────────────────────────────────────┐
│ Hardware Interrupt (e.g., keyboard, timer):                 │
│ 1. Save current privilege level                             │
│ 2. Switch to Ring 0 (interrupt handlers run in Ring 0)      │
│ 3. Execute interrupt service routine                        │
│ 4. Restore previous privilege level                         │
│                                                             │
│ This allows Ring 3 programs to be interrupted safely        │
│ without compromising system security                        │
└─────────────────────────────────────────────────────────────┘
</code></pre><h4 id=how-does-cpummu-enforces-the-privilege-check-at-hardware-level>How Does CPU/MMU Enforces the Privilege Check at Hardware Level?<a hidden class=anchor aria-hidden=true href=#how-does-cpummu-enforces-the-privilege-check-at-hardware-level>#</a></h4><p>The CPU/MMU has no concept of &ldquo;operating system&rdquo; vs &ldquo;application program.&rdquo; It only understands:</p><ul><li>Current Privilege Level (CPL)</li><li>Descriptor Privilege Levels (DPL)</li><li>Access permissions based on these levels</li></ul><p>So CPU doesn&rsquo;t know the difference between the Operating System&rsquo;s code and a User Space program&rsquo;s code. How does it know who should actually have higher level of privileges and who doesn&rsquo;t?</p><h5 id=the-first-mover-advantage-principle>The &ldquo;First Mover Advantage&rdquo; Principle<a hidden class=anchor aria-hidden=true href=#the-first-mover-advantage-principle>#</a></h5><p><strong>1. Bootstrap Sequence:</strong></p><pre tabindex=0><code>1. CPU powers on in Real Mode (no protection)
2. BIOS/Bootloader runs (still no protection)
3. First OS code loads and runs (still no protection)
4. OS sets up GDT with itself as Ring 0
5. OS switches to Protected Mode
6. NOW protection is active - OS controls everything
</code></pre><p><strong>2. OS Establishes Its Authority:</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-C data-lang=C><span style=display:flex><span><span style=color:#75715e>// OS creates GDT during boot (while still unprotected)
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>GDT[<span style=color:#ae81ff>0</span>] <span style=color:#f92672>=</span> NULL_DESCRIPTOR;
</span></span><span style=display:flex><span>GDT[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>=</span> {base: <span style=color:#ae81ff>0</span>, limit: <span style=color:#ae81ff>4</span>GB, DPL: <span style=color:#ae81ff>0</span>, type: CODE};  <span style=color:#75715e>// OS code
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>GDT[<span style=color:#ae81ff>2</span>] <span style=color:#f92672>=</span> {base: <span style=color:#ae81ff>0</span>, limit: <span style=color:#ae81ff>4</span>GB, DPL: <span style=color:#ae81ff>0</span>, type: DATA};  <span style=color:#75715e>// OS data  
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>GDT[<span style=color:#ae81ff>3</span>] <span style=color:#f92672>=</span> {base: <span style=color:#ae81ff>0</span>, limit: <span style=color:#ae81ff>4</span>GB, DPL: <span style=color:#ae81ff>3</span>, type: CODE};  <span style=color:#75715e>// User code
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>GDT[<span style=color:#ae81ff>4</span>] <span style=color:#f92672>=</span> {base: <span style=color:#ae81ff>0</span>, limit: <span style=color:#ae81ff>4</span>GB, DPL: <span style=color:#ae81ff>3</span>, type: DATA};  <span style=color:#75715e>// User data
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span><span style=color:#75715e>// OS loads itself into Ring 0
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>CS <span style=color:#f92672>=</span> <span style=color:#ae81ff>0x08</span>;  <span style=color:#75715e>// Ring 0 code segment
</span></span></span><span style=display:flex><span><span style=color:#75715e>// Now CPL = 0, and OS controls all privilege decisions
</span></span></span></code></pre></div><h5 id=but-theres-a-catch---memory-segmentation-isnt-full-protection>But There&rsquo;s a Catch - Memory Segmentation Isn&rsquo;t Full Protection<a hidden class=anchor aria-hidden=true href=#but-theres-a-catch---memory-segmentation-isnt-full-protection>#</a></h5><p><strong>80286 Segmentation Limitations:</strong></p><ul><li><strong>Same linear address space:</strong> All segments can point to the same memory</li><li><strong>No memory isolation:</strong> Ring 3 code can potentially read Ring 0 memory if descriptors allow it</li><li><strong>Descriptor-dependent:</strong> Protection</li></ul><p>Example Problem:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-C data-lang=C><span style=display:flex><span><span style=color:#75715e>// OS sets up segments (Ring 0 privilege required)
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>GDT[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>=</span> {base: <span style=color:#ae81ff>0x100000</span>, limit: <span style=color:#ae81ff>64</span>KB, DPL: <span style=color:#ae81ff>0</span>};  <span style=color:#75715e>// OS memory
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>GDT[<span style=color:#ae81ff>3</span>] <span style=color:#f92672>=</span> {base: <span style=color:#ae81ff>0x100000</span>, limit: <span style=color:#ae81ff>64</span>KB, DPL: <span style=color:#ae81ff>3</span>};  <span style=color:#75715e>// User memory
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Problem: Both point to SAME physical memory!
</span></span></span><span style=display:flex><span><span style=color:#75715e>// User can read OS memory through their own descriptor
</span></span></span></code></pre></div><h2 id=how-80286-changed-the-cpu-os-relationship-forever>How 80286 Changed the CPU-OS Relationship Forever<a hidden class=anchor aria-hidden=true href=#how-80286-changed-the-cpu-os-relationship-forever>#</a></h2><h3 id=8086-era-os-as-optional-helper>8086 Era: OS as Optional Helper<a hidden class=anchor aria-hidden=true href=#8086-era-os-as-optional-helper>#</a></h3><p>In the 8086 real mode world, the relationship between CPU and operating system was surprisingly casual:</p><ul><li><strong>No memory protection</strong> - any program could access any memory location</li><li><strong>No privilege levels</strong> - all code ran with identical hardware access</li><li><strong>Direct hardware control</strong> - programs could manipulate I/O ports, interrupts, and system resources directly</li><li><strong>OS was essentially a library</strong> - DOS functioned as a collection of utility functions that programs could call, but could easily bypass</li></ul><p>You could write a program that completely ignored DOS, accessed hardware directly, modified interrupt vectors, or even overwrote parts of DOS in memory. Running a program &ldquo;with&rdquo; or &ldquo;without&rdquo; an operating system made little architectural difference - the CPU imposed no restrictions.</p><h3 id=80286-the-partnership-revolution>80286: The Partnership Revolution<a hidden class=anchor aria-hidden=true href=#80286-the-partnership-revolution>#</a></h3><p>The 80286 introduced a radical concept: hardware features that required OS cooperation. Neither the CPU nor the OS could provide modern computing features alone - they had to work as partners.</p><h4 id=hardware-features-demanding-os-management>Hardware Features Demanding OS Management:<a hidden class=anchor aria-hidden=true href=#hardware-features-demanding-os-management>#</a></h4><ul><li><strong>GDT/LDT setup</strong> - CPU provides descriptor table mechanism, but OS must create and manage the actual tables</li><li><strong>TSS management</strong> - CPU can switch tasks via hardware, but OS must set up Task State Segments for each process</li><li><strong>Privilege level enforcement</strong> - CPU enforces ring-based protection, but OS must define what gets what privileges</li><li><strong>Segment descriptors</strong> - CPU checks access rights, but OS must create proper access permissions and memory limits</li><li><strong>Protected mode switching</strong> - Complex initialization sequence requiring intimate OS-hardware coordination</li></ul><h4 id=the-new-partnership-model>The New Partnership Model:<a hidden class=anchor aria-hidden=true href=#the-new-partnership-model>#</a></h4><pre tabindex=0><code>Hardware provides MECHANISMS
    ↓
OS provides POLICIES  
    ↓
CPU enforces what OS defines
</code></pre><h4 id=why-this-partnership-was-essential>Why This Partnership Was Essential:<a hidden class=anchor aria-hidden=true href=#why-this-partnership-was-essential>#</a></h4><ul><li><strong>1. Memory Protection:</strong> CPU can only protect memory if OS properly sets up segment descriptors</li><li><strong>2. Multitasking:</strong> TSS structure is meaningless without OS task scheduling to utilize it</li><li><strong>3. Privilege Separation:</strong> Ring levels only work if OS correctly manages user/kernel boundaries</li><li><strong>4. Resource Management:</strong> I/O permission bitmaps need OS policy to define task capabilities</li></ul><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>An address bus is a collection of wires (or electrical pathways) that carries memory addresses from the processor to memory and other components. Think of it as the &ldquo;postal system&rdquo; of the computer - when the CPU wants to read from or write to a specific location in memory, it sends that location&rsquo;s address through the address bus. Each wire in the address bus represents one bit of the address. The CPU sets each wire to either high voltage (representing binary 1) or low voltage (representing binary 0) to form the complete binary address.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>(Serial Ports) Communication ports for devices like modems, mice, or serial printers. Each COM port has a base I/O address (COM1 typically at 3F8h, COM2 at 2F8h, etc.). The BIOS Data Area stores these addresses so software knows where to find each serial port.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>(Parallel Ports) &ldquo;Line Printer&rdquo; ports primarily used for parallel printers. LPT1 typically uses I/O address 378h. These were the standard way to connect printers before USB existed. The BIOS stores the base addresses of installed parallel ports.&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p>Whether Shift, Ctrl, Alt, Caps Lock, Num Lock, or Scroll Lock are currently pressed or toggled. This is stored as bit flags in memory location 0040:0017h.&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5><p>A circular buffer (usually 15-16 characters) that stores keystrokes when they&rsquo;re typed faster than the program can process them. This prevents losing keystrokes during busy periods.&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6><p>This bitmap, usually set up by the operating system when a task is started, specifies individual ports to which the program should have access. The I/O bitmap is a bit array of port access permissions; if the program has permission to access a port, a &ldquo;0&rdquo; is stored at the corresponding bit index, and if the program does not have permission, a &ldquo;1&rdquo; is stored there. When a program issues an x86 I/O port instruction such as IN or OUT, the hardware will do an I/O privilege level (IOPL) check to see if the program has access to all I/O ports. If the Current Privilege Level (CPL) of the program is numerically greater than the I/O Privilege level (IOPL), the program does not have I/O port access to all ports. If the IOPL check fails, the CPU then consults the I/O bitmap to see if this specific port is allowed. It prevents malicious programs from accessing hardware directly by stopping user programs from interfering with system devices.&#160;<a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://sankethbk.github.io/blog/tags/cpu/>Cpu</a></li><li><a href=https://sankethbk.github.io/blog/tags/x86/>X86</a></li></ul></footer></article><section id=references><h2>References</h2><ul><li><a href="https://www.youtube.com/watch?v=jkGZDb3100Q" target=_blank rel="noopener noreferrer">Virtual Memory in the x86</a></li><li><a href="https://www.youtube.com/watch?v=H4SDPLiUnv4" target=_blank rel="noopener noreferrer">How a Single Bit Inside Your Processor Shields Your Operating System's Integrity</a></li><li><a href=https://blogsystem5.substack.com/p/from-0-to-1-mb-in-dos target=_blank rel="noopener noreferrer">From 0 to 1 MB in DOS</a></li><li><a href=https://ragestorm.net/downloads/286intel.txt target=_blank rel="noopener noreferrer">Intel 80286 Manual</a></li><li><a href=https://pdos.csail.mit.edu/6.828/2017/readings/i386/s07_01.htm target=_blank rel="noopener noreferrer">Task State Segment</a></li><li><a href=https://pdos.csail.mit.edu/6.828/2017/readings/i386/toc.htm target=_blank rel="noopener noreferrer">Intel 80386 Manual</a></li><li><a href=https://wiki.osdev.org/Global_Descriptor_Table target=_blank rel="noopener noreferrer">Global Descriptor Table</a></li><li><a href=https://wiki.osdev.org/Task_State_Segment target=_blank rel="noopener noreferrer">Task State Segment</a></li></ul></section></main><footer class=footer><span>&copy; 2025 <a href=https://sankethbk.github.io/blog/>Sanketh's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>