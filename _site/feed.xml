<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/blog/" rel="alternate" type="text/html" /><updated>2024-06-30T19:31:19+05:30</updated><id>http://localhost:4000/blog/feed.xml</id><title type="html">Sanketh’s Blog</title><subtitle>Welcome to my blog! I have started this blog to document my journey of learning low-level areas of computer science.</subtitle><author><name>Sanketh B K</name></author><entry><title type="html">The Fetch Execute Decode Cycle</title><link href="http://localhost:4000/blog/the-fetch-execute-decode-cycle" rel="alternate" type="text/html" title="The Fetch Execute Decode Cycle" /><published>2024-06-30T00:00:00+05:30</published><updated>2024-06-30T00:00:00+05:30</updated><id>http://localhost:4000/blog/the-fetch-execute-decode-cycle</id><content type="html" xml:base="http://localhost:4000/blog/the-fetch-execute-decode-cycle"><![CDATA[]]></content><author><name>Sanketh B K</name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Measuring CPU Performance</title><link href="http://localhost:4000/blog/cpu/measuring-cpu-performance" rel="alternate" type="text/html" title="Measuring CPU Performance" /><published>2024-06-21T01:14:25+05:30</published><updated>2024-06-21T01:14:25+05:30</updated><id>http://localhost:4000/blog/cpu/measuring-cpu-performance</id><content type="html" xml:base="http://localhost:4000/blog/cpu/measuring-cpu-performance"><![CDATA[<p>CPU Manufacturers publish several metrics related to CPU like clock speed, number of cores, cache sizes, ISA, performance per Watt, number of transistors and more. Measuring CPU performance is complex, and it cannot be summarized by a single metric. In this post, I’ll explore each of these metrics and discuss some standard benchmarking software and their limitations.</p>

<h2 id="what-is-clock-speed-how-does-it-affects-cpu-performance">What is Clock Speed, How does it Affects CPU Performance?</h2>

<p>All Synchronous digital electronic circuits require an externally generated time reference. This is usually a square wave signal provided to the circuit called as clock. A <strong>clock cycle</strong> is the fundamental unit of time measurement for a CPU. A clock cycle is a single electrical pulse in a CPU, during which the CPU can execute a fundamental operation such as accessing memory, writing data, or fetching a new set of instructions. A clock cycle is measured as the amount of time between two pulses of an oscillator. The clock speed of a CPU is measured in Hertz (Hz), which signifies the number of clock cycles it can complete in one second. Common units are Megahertz (MHz) and Gigahertz (GHz).</p>

<h3 id="major-functionalities-of-cpu-clocks">Major functionalities of CPU clocks</h3>

<ul>
  <li>The clock signal ensures that all parts of the circuit change their state in a coordinated manner, ensuring reliable and predictable operation.</li>
  <li>In sequential logic circuits, where the output depends not just on the current inputs but also on the history of inputs, a clock is necessary to sequence the operations correctly.</li>
  <li>The clock signal allows precise control over the timing of data transfers between different parts of the circuit. The clock ensures that the data is stable and settled before being transferred to the next stage of the circuit.</li>
</ul>

<h3 id="does-higher-clock-speed-means-higher-cpu-performance">Does Higher Clock Speed Means Higher CPU Performance?</h3>

<p>Let’s say we have 2 CPU’s with A and B with clock speed 3.4 GHz and 3.6 GHz respectively. While CPU B can generate more clock pulses compared to A, it does not necessarily mean that it has better performance than A. There are several other factors which come into play while determining the overall performance. If an instruction took “x” number of cycles in CPU A and if it takes same number of cycles in CPU B, then CPU B is indeed faster as it means that the instruction is taking less time to complete on CPU B. But in real life it’s difficult to decrease the time of instruction execution. Some things like register access are very fast but things like memory access, ALU operations, floating point operations are complex in nature and cannot be optimized by merely increasing clock speed. Thus, comparing the clock speeds of two CPUs is only relevant if the CPUs belong to the same family, like Intel i5 and i7, or Mac M1 and M4.</p>

<h3 id="why-cpu-clock-speed-has-barely-changed-in-past-two-decades">Why CPU Clock speed has barely changed in past two decades?</h3>

<p>The clock speed of consumer-grade CPUs has barely changed in the past two decades. For example, the Intel Pentium 4, which came out in the early 2000s, achieved a clock speed of 3.8 GHz, while the recent Apple M3 released in 2023 runs at 4.05 GHz. Despite the similar clock speeds, the Apple M3 is far more powerful than the Intel Pentium 4.</p>

<p>The primary reason manufacturers haven’t increased clock speed is that higher frequency CPUs consume more power and generate more heat. This can lead to thermal throttling, where the CPU reduces its frequency to prevent overheating, negating the benefits of the higher frequency. As a result, manufacturers have shifted focus to other parameters to enhance performance:</p>

<ol>
  <li>
    <p><strong>Cycles per Instruction (CPI):</strong> Cycles per Instruction refers to the average number of cycles taken by a particular instruction to complete. Ideal value of CPI is 1, as each instruction needs at least one clock cycle to complete. But in real world scenario, even the simplest instruction will take multiple cycles to complete, depending on the architecture. Techniques such as pipelining and out-of-order execution are used to optimize CPI and improve overall performance.</p>
  </li>
  <li>
    <p><strong>Number of Cores and Threads:</strong> A multi-core CPU can perform several tasks in parallel, with each core functioning as an independent processing unit. Technologies like simultaneous multithreading (SMT), or Intel’s Hyper-Threading, allow a CPU core to support multiple hardware threads, each with its own Program Counter (PC) and registers allowing independent execution. Hyper-threading works by sharing functional units of a core among multiple hardware threads. Hardware threads are different from threads provided by OS which are known as software threads. In case of software threads, concurrency is achieved by context switching between multiple threads. In SMT, hardware threads may appear as independent cores to the operating system and applications, even though they share some physical resources.</p>
  </li>
  <li>
    <p><strong>Instruction Set Architecture (ISA):</strong> ISA is a set of instructions that a processor can understand and execute. ISA are classified into two types: Reduced Instruction Set Computer (RISC) and Complex Instruction Set Computer (CISC). RISC architectures use a small, highly optimized set of instructions that are all of uniform length and are executed in a single clock cycle. This simplicity and efficiency make RISC architectures easier to pipeline and more power-efficient. Some examples RISC ISA’s are MIPS, ARM. CISC architectures have a large and complex set of instructions, some of which can execute multi-step operations in a single instruction. This allows for more functionality per instruction but often results in more complex hardware and potentially slower performance for individual instructions, example: x86.</p>
  </li>
  <li>
    <p><strong>Dynamic Frequency Scaling:</strong> Dynamic frequency scaling allows the CPU to adjust its clock speed based on the current workload and thermal conditions. By lowering the clock speed when full performance is not needed, the CPU can save power and reduce heat generation, which helps in maintaining performance efficiency and longevity. In some modern day processors like Intel I7, it’s possible to increase the clock frequency beyond the base clock frequency. This will help in executing CPU intensive workloads efficiently provided there is enough thermal as well as power capacity. This is also known as overclocking.</p>
  </li>
</ol>

<h2 id="the-cpu-performance-equation">The CPU Performance Equation</h2>

<p>The CPU performance can be calculated using the equation</p>

\[T = N_{\text{instr}} \cdot \text{CPI} \cdot t_{\text{cycle}}\]

<p>where:</p>
<ul>
  <li>N<sub>instr</sub> = Number of instructions executed</li>
  <li>CPI = Cycles per Instruction</li>
  <li>t<sub>cycle</sub> = Duration of a clock cycle</li>
  <li>T = CPU time consumed by the program</li>
</ul>

<p>Cycles per Instruction (CPI) is a critical metric in evaluating CPU performance. Different types of instructions take different numbers of cycles to complete, and even the same type of instruction can take varying numbers of cycles depending on factors like pipeline stalls or cache hits/misses. Because of this variability, CPI is often represented as an average value for each type of instruction. This average CPI helps in estimating the overall performance of a CPU when executing a mix of different instructions.</p>

<p>From the above equation we can see that CPU time consumed by a program can be decreased by decreasing one of the three paramaters N<sub>instr</sub>, CPI or t<sub>cycle</sub>. However, these three parameters are not completely independent of each other. For example, if we try to reduce N<sub>instr</sub> by optimizing the Assembly code to produce fewer instructions, we may have to increase the complexity of instructions which would in turn increase CPI for those instructions.</p>

<h2 id="historical-laws-related-to-cpu-performance">Historical Laws Related to CPU Performance</h2>

<h3 id="amdahls-law">Amdahl’s Law</h3>

<p>Amdahl’s law provides a formula to calculate maximum theoretical speedup that can be obtained by parallelizing the CPU workload on multiple processing units.</p>

\[S = \frac{1}{(1 - P) + \frac{P}{N}}\]

<p>where:</p>
<ul>
  <li>S is the theoretical speedup of the execution of the whole task;</li>
  <li>P is the proportion of the program that can be parallelized;</li>
  <li>N is the number of processors.</li>
</ul>

<p><a title="Daniels220 at English Wikipedia, CC BY-SA 3.0 &lt;https://creativecommons.org/licenses/by-sa/3.0&gt;, via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:AmdahlsLaw.svg"><img width="512" alt="AmdahlsLaw" src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/AmdahlsLaw.svg/512px-AmdahlsLaw.svg.png?20170324202600" /></a></p>

<p>Using Amdahl’s Law, we can calculate that if 50% of the total workload is parallelizable, then the maximum speedup achieved will be 2 no matter how many processors we use. This demonstrates the limitation of parallel processing, highlighting that the non-parallelizable portion of the task significantly impacts the overall speedup.</p>

<h3 id="gustafsons-law">Gustafson’s Law</h3>

<p>While Amdahl’s Law focuses on the limitations of parallelism for a fixed workload, Gustafson’s Law presents a less pessimistic view by considering the scalability of parallelism by allowing the problem size to grow with the number of processors. Gustafson’s Law is expressed as:</p>

\[S = 1 + (N - 1)P\]

<p>where:</p>
<ul>
  <li>S is the speedup,</li>
  <li>N is the number of processors,</li>
  <li>P is the proportion of the parallel part of the workload.</li>
</ul>

<p><a title="Peahihawaii, CC BY-SA 3.0 &lt;https://creativecommons.org/licenses/by-sa/3.0&gt;, via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:Gustafson.png"><img width="512" alt="Gustafson" src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d7/Gustafson.png/512px-Gustafson.png?20110108143519" /></a></p>

<p>Gustafson’s Law suggests that as we increase the number of processors, the overall problem size can increase proportionally, thus making better use of the additional computational power. This perspective is more optimistic because it implies that large-scale problems can achieve significant performance gains through parallel processing, provided there is sufficient parallelizable work.</p>

<p>In essence, Amdahl’s Law highlights the diminishing returns of parallelism due to the serial portion of a task, while Gustafson’s Law emphasizes the potential for increased problem sizes to fully utilize the power of multiple processors. Together, these laws offer valuable insights into the challenges and opportunities of parallel computing.</p>

<h2 id="cpu-benchmarking-softwares">CPU Benchmarking Softwares</h2>

<p>There are no universal benchmarks for measuring CPU performance. Over the past five decades, manufacturers and researchers have used various benchmarks to describe CPU performance. CPU benchmarks can be broadly classified into two types:</p>

<p><strong>1. Synthetic Benchmarks:</strong> Synthetic benchmarks emulate CPU-intensive workloads such as file compression, cryptography, floating-point operations, and 3D rendering. While they are not exact predictors of performance, synthetic benchmarks are useful for testing individual components and comparing specific aspects of CPU performance.</p>

<p><strong>2. Application Benchmarks:</strong> Application benchmarks run real-world programs that perform CPU-intensive workloads on the system. These benchmarks are less biased and provide a more accurate representation of CPU metrics, offering a clearer picture of how a CPU will perform in practical scenarios.</p>]]></content><author><name>Sanketh</name></author><category term="cpu" /><summary type="html"><![CDATA[CPU Manufacturers publish several metrics related to CPU like clock speed, number of cores, cache sizes, ISA, performance per Watt, number of transistors and more. Measuring CPU performance is complex, and it cannot be summarized by a single metric. In this post, I’ll explore each of these metrics and discuss some standard benchmarking software and their limitations.]]></summary></entry><entry><title type="html">Key Differences between 32-bit and 64-bit CPU architectures</title><link href="http://localhost:4000/blog/cpu/processor-bit-size" rel="alternate" type="text/html" title="Key Differences between 32-bit and 64-bit CPU architectures" /><published>2024-06-02T12:35:25+05:30</published><updated>2024-06-02T12:35:25+05:30</updated><id>http://localhost:4000/blog/cpu/processor-bit-size</id><content type="html" xml:base="http://localhost:4000/blog/cpu/processor-bit-size"><![CDATA[<p>The terms 32 bit and 64 bit specifically relate to the size of the data and address registers within the CPU, which determines the maximum amount of memory that can be directly accessed and the range of values that can be processed.</p>

<ol>
  <li>Registers and Data Width:
    <ul>
      <li>Since all calculations take place in registers, when performing operations such as addition or subtraction, variables are loaded from memory into registers if they are not already there.</li>
      <li>A 32-bit CPU has 32-bit wide registers, meaning it can process 32 bits of data in a single instruction.</li>
    </ul>
  </li>
  <li>Memory Addressing:
    <ul>
      <li>32-bit CPU can address up to 2<sup>32</sup> unique memory locations translates to a maximum of 4 GB of addressable memory (RAM). 64-bit CPU can address up to 2<sup>64</sup> unique memory locations allowing for a theoretical maximum of 16 exabytes of addressable memory.</li>
      <li>This limitation comes from the fact that a 32-CPU can only load integers that are 32 bits long, thus limiting the maximum addressable memory space.</li>
    </ul>
  </li>
  <li>Data Transfer Speeds:
    <ul>
      <li>The memory bus width in 64-bit CPU is often 64 bits or more, meaning the physical path between the CPU and RAM can handle 64 bits of data in parallel. This helps in efficiently loading data into the cache but does not restrict the CPU to always reading 64 bits.</li>
      <li>Despite the ability to handle 64 bits of data in parallel, the CPU is not restricted to always reading 64 bits at a time. It can access smaller data sizes (e.g., 8-bit, 16-bit, 32-bit) as needed, depending on the specific instruction and data type.</li>
    </ul>
  </li>
  <li>Performance:
    <ul>
      <li>64-bit CPU’s perform better than 32-bit CPU’s. This performance difference comes up from various factors like size of registers, addressable memory space, larger bus width</li>
      <li>Some RISC architectures support SIMD (Single Instruction, Multiple Data) instructions that allow for parallel processing of multiple smaller data types within larger registers. For example, ARM’s NEON technology can operate on multiple 32-bit integers within 64-bit registers, which enable the parallel processing of smaller data types within larger registers.</li>
    </ul>
  </li>
  <li>Application Compatibility:
    <ul>
      <li>64-bit operating systems typically include backward compatibility to run 32-bit software seamlessly.</li>
      <li>These compatibility layers allow 32-bit applications to execute on 64-bit systems without any major issues. However, 32-bit applications may not fully utilize the advantages of 64-bit systems, such as increased memory addressing capabilities.</li>
    </ul>
  </li>
</ol>]]></content><author><name>Sanketh</name></author><category term="cpu" /><summary type="html"><![CDATA[The terms 32 bit and 64 bit specifically relate to the size of the data and address registers within the CPU, which determines the maximum amount of memory that can be directly accessed and the range of values that can be processed.]]></summary></entry><entry><title type="html">Components of CPU</title><link href="http://localhost:4000/blog/cpu/components-of-cpu" rel="alternate" type="text/html" title="Components of CPU" /><published>2024-05-31T01:05:25+05:30</published><updated>2024-05-31T01:05:25+05:30</updated><id>http://localhost:4000/blog/cpu/components-of-cpu</id><content type="html" xml:base="http://localhost:4000/blog/cpu/components-of-cpu"><![CDATA[<p>Before learning Assembly, I think it would be useful to learn a bit about different components of CPU in general. If we think of CPU as a black box its main function is to fetch instructions from RAM which are in the form of <a href="https://en.wikipedia.org/wiki/Machine_code">machine code</a> and execute them.</p>

<h2 id="components-of-cpu">Components of CPU</h2>

<ol>
  <li>Arithmetic Logic Unit (ALU)</li>
  <li>Memory Management Unit (MMU)</li>
  <li>Control Unit (CU)</li>
  <li>Registers</li>
  <li>Clock</li>
  <li>Cache</li>
  <li>Buses</li>
</ol>

<h3 id="1-arithmetic-logic-unit-alu">1. Arithmetic Logic Unit (ALU)</h3>

<p>ALU is an electronic circuit made of NAND gates responsible for performing arithmetic and logical operations on integer binary numbers. It takes two operands as inputs and an opcode to indicate the type of operation to be performed. Operations supported by ALU are Add, Subtract, Negation, Two’s complement, AND, OR, XOR, bit shift, etc.</p>

<h3 id="2-memory-management-unit-mmu">2. Memory Management Unit (MMU)</h3>

<p>The primary function of the MMU is to translate virtual addresses generated by the CPU into physical addresses used by the underlying hardware memory. It acts as a bridge between CPU and RAM, managing how the CPU accesses data stored in memory and provides an illusion of infinite memory space for programs. MMU utilizes different stragies such as the branch and bound registers, segmentation, page tables, TLB’s, etc to facilitate address translation.</p>

<h3 id="3-control-unit-cu">3. Control Unit (CU)</h3>

<p>CU’s primary function is to direct the operations of the CPU by interpreting instructions and generating control signals to execute them.</p>

<ol>
  <li>Instruction Fetching:
    <ul>
      <li>The CU fetches instructions from the memory unit (RAM) based on the Program Counter (PC) value.</li>
      <li>It reads the instruction from memory and stores it temporarily in the Instruction Register (IR) for decoding.</li>
    </ul>
  </li>
  <li>Instruction Decoding:
    <ul>
      <li>The CU interprets the fetched instruction from the IR.</li>
      <li>It breaks down the instruction into its constituent parts (opcode, operands) and sends control signals to other CPU components.</li>
    </ul>
  </li>
  <li>Operand Fetching:
    <ul>
      <li>If the instruction requires operands from memory or registers, the CU initiates the necessary data transfers.</li>
      <li>It interacts with the memory address register (MAR) and memory data register (MDR) to fetch data from memory.</li>
    </ul>
  </li>
  <li>Execution Control:
    <ul>
      <li>The CU generates control signals to coordinate the execution of the instruction.</li>
      <li>It activates specific functional units within the CPU, such as the ALU, to perform arithmetic, logic, or data manipulation operations.</li>
    </ul>
  </li>
  <li>Exception Handling:
    <ul>
      <li>The CU detects and handles exceptions, interrupts, or other abnormal conditions that occur during program execution.</li>
      <li>It may suspend the current instruction stream, save the current CPU state, and transfer control to an appropriate exception handler routine.</li>
    </ul>
  </li>
  <li>Synchronization and Control:
    <ul>
      <li>The CU synchronizes the activities of different CPU components and ensures that instructions are executed in the correct sequence.</li>
      <li>It generates timing signals, clock pulses, and control signals to coordinate the operation of the CPU and maintain system integrity.</li>
    </ul>
  </li>
</ol>

<h4 id="purpose-of-ir-mar-and-mdr-registers">Purpose of IR, MAR and MDR registers</h4>

<p><strong>Instruction Register (IR):</strong></p>

<ul>
  <li>After fetching an instruction from memory, the CPU places it into the IR for decoding and execution.</li>
  <li>The CU (Control Unit) interacts with the IR to decode the instruction and generate control signals for its execution.</li>
</ul>

<p><strong>Memory Address Register (MAR):</strong></p>

<ul>
  <li>When the CPU needs to read or write data or instructions from/to memory, it places the memory address into the MAR to specify the location in memory.</li>
  <li>The CU interacts with the MAR when initiating memory read or write operations. It provides the memory address to the MAR, which is used to access the desired location in memory.</li>
</ul>

<p><strong>Memory Data Register (MDR):</strong></p>

<ul>
  <li>When the CPU reads data from memory, it is stored temporarily in the MDR before being processed further. Similarly, when the CPU writes data to memory, it places the data into the MDR before it is transferred to the memory module.</li>
  <li>The CU interacts with the MDR during memory read or write operations. After fetching data from memory (or before writing data to memory), the data is transferred between the MDR and the CPU’s internal registers for processing.</li>
</ul>

<h3 id="4-registers">4. Registers</h3>

<p>Registers are small, fast storage locations within the CPU that hold data and instructions temporarily during processing.</p>

<h4 id="types-of-registers">Types of Registers</h4>

<ol>
  <li>General-Purpose Registers (GPRs):
    <ul>
      <li>Used to store temporary data and intermediate results during computation.</li>
      <li>In x86 architecture, common GPRs include EAX, EBX, ECX, and EDX.</li>
    </ul>
  </li>
  <li>Special-Purpose Registers
    <ul>
      <li>Program Counter (PC): Holds the address of the next instruction to be executed.</li>
      <li>Instruction Register (IR): Holds the current instruction being decoded and executed.</li>
      <li>Memory Address Register (MAR): Holds the memory address of data that needs to be accessed.</li>
      <li>Memory Data Register (MDR): Holds the data fetched from or to be written to memory.</li>
      <li>Instruction Register (IR): Holds the current instruction to be executed.</li>
    </ul>
  </li>
  <li>Index and Base Registers
    <ul>
      <li>Used for addressing modes, particularly in complex addressing calculations like indexed and based addressing.</li>
    </ul>
  </li>
  <li>Stack Pointer (SP) and Base Pointer (BP)
    <ul>
      <li>Used for stack operations. The SP points to the top of the stack, and the BP is often used to reference the base of the stack frame.</li>
    </ul>
  </li>
</ol>

<h3 id="5-clock">5. Clock</h3>

<p>CPU clocks generates regular electrical pulses known as clock cycleswhich synchronize the operations of the CPU and other components in the computer system. Synchronization ensures that tasks are performed in the correct order and at the right times, enabling the smooth and efficient execution of instructions.</p>

<ul>
  <li>The clock synchronizes the activities of various components within the CPU, such as the Control Unit (CU), Arithmetic Logic Unit (ALU), registers, and memory interfaces.</li>
  <li>Each stage of the instruction cycle (fetch, decode, execute, and write-back) is typically completed in one or more clock cycles, depending on the complexity of the instruction and the CPU architecture.</li>
</ul>

<h3 id="6-cache">6. Cache</h3>

<p>Cache in a CPU is a small, high-speed memory located inside the CPU or very close to it. Its main purpose is to temporarily store copies of frequently accessed data from the main memory (RAM), reducing the time it takes for the CPU to access this data.</p>

<p>The cache is significantly faster than the main memory (RAM). It’s built with a special type of memory called Static Random-Access Memory (SRAM), which offers much faster access times compared to the Dynamic Random-Access Memory (DRAM) used in RAM.</p>

<h4 id="types-of-cpu-cache">Types of CPU Cache</h4>

<ol>
  <li>L1 Cache (Level 1)
    <ul>
      <li>Typically located directly on the CPU chip.</li>
      <li>Smallest in size, ranging from a few kilobytes to tens of kilobytes.</li>
    </ul>
  </li>
  <li>L2 Cache (Level 2)
    <ul>
      <li>Larger than L1, ranging from tens of kilobytes to a few megabytes, often shared between multiple CPU cores.</li>
    </ul>
  </li>
  <li>L3 Cache (Level 3)
    <ul>
      <li>Largest and slowest cache, shared by all CPU cores in a multi-core processor.</li>
    </ul>
  </li>
</ol>

<h3 id="7-buses">7. Buses</h3>

<p>In a CPU and computer system, buses are communication pathways that transfer data between different components. These buses are critical for ensuring that data, control signals, and power are efficiently moved within the CPU and between the CPU and other parts of the computer.</p>

<h4 id="types-of-buses">Types of Buses</h4>

<ol>
  <li>Data Bus
    <ul>
      <li>Transfers data between the CPU, memory, and other peripherals.</li>
      <li>The width of the data bus (e.g., 8-bit, 16-bit, 32-bit, 64-bit) determines how much data can be transferred simultaneously. For example, a 32-bit data bus can transfer 32 bits of data at a time.</li>
      <li>Typically bidirectional, allowing data to be read from and written to memory or peripherals.</li>
    </ul>
  </li>
  <li>Address Bus
    <ul>
      <li>Carries addresses from the CPU to memory and other peripherals, indicating where data should be read from or written to.</li>
      <li>The width of the address bus determines the maximum addressable memory. For example, a 32-bit address bus can address 2<sup>32</sup> unique locations.</li>
      <li>Unidirectional, as addresses are only sent from the CPU to other components.</li>
    </ul>
  </li>
  <li>Control Bus
    <ul>
      <li>Carries control signals from the CPU to other components to coordinate and manage their operations.</li>
      <li>Control signals indicate whether data is to be read or written, when to start or stop an operation, and other control functions like interrupt requests.</li>
      <li>Typically bidirectional, as control signals can flow to and from the CPU.</li>
    </ul>
  </li>
</ol>

<h4 id="examples-of-buses-in-cpu-systems">Examples of Buses in CPU Systems</h4>

<ol>
  <li>Front-Side Bus (FSB)
    <ul>
      <li>Connects the CPU to the main memory (RAM) and the chipset.</li>
      <li>Historically, the FSB was the main pathway for data communication between the CPU and memory. Modern systems often use more complex architectures like Direct Media Interface (DMI) or HyperTransport.</li>
    </ul>
  </li>
  <li>Back-Side Bus (BSB)
    <ul>
      <li>Connects the CPU to the L2 or L3 cache.</li>
      <li>The BSB allows for high-speed communication between the CPU and its cache, improving performance.</li>
    </ul>
  </li>
  <li>System Bus
    <ul>
      <li>Combines the data, address, and control buses into a single bus that connects the CPU to memory and peripherals.</li>
      <li>This bus is used for general communication across the system, ensuring all components can interact as needed.</li>
    </ul>
  </li>
  <li>Peripheral Component Interconnect (PCI) Bus
    <ul>
      <li>Connects peripheral devices to the CPU.</li>
      <li>The PCI bus allows the CPU to communicate with hardware devices like network cards, sound cards, and graphics cards.</li>
    </ul>
  </li>
</ol>]]></content><author><name>Sanketh</name></author><category term="cpu" /><summary type="html"><![CDATA[Before learning Assembly, I think it would be useful to learn a bit about different components of CPU in general. If we think of CPU as a black box its main function is to fetch instructions from RAM which are in the form of machine code and execute them.]]></summary></entry><entry><title type="html">My Resources for Learning Operating Systems and Computer Architecture</title><link href="http://localhost:4000/blog/operating-systems/learning-resources/my-study-resources" rel="alternate" type="text/html" title="My Resources for Learning Operating Systems and Computer Architecture" /><published>2024-04-06T20:33:25+05:30</published><updated>2024-04-06T20:33:25+05:30</updated><id>http://localhost:4000/blog/operating-systems/learning-resources/my-study-resources</id><content type="html" xml:base="http://localhost:4000/blog/operating-systems/learning-resources/my-study-resources"><![CDATA[<p>I have previously studied operating systems as a part of my university curriculum, i’ve realized it’s time to revisit the fundamentals and go beyond. I have decided to start with some popular books. I will add more resources as i go along.</p>

<h4 id="text-books">Text Books</h4>

<ol>
  <li><a href="https://pages.cs.wisc.edu/~remzi/OSTEP/">Operating Systems Three Easy Pieces</a></li>
  <li>Linux System Programming: Talking Directly to the Kernel and C Library by Robert Love</li>
  <li><a href="https://acs.pub.ro/~cpop/SMPA/Computer%20Architecture%20A%20Quantitative%20Approach%20(5th%20edition).pdf">Computer Architecture A Quantitative Approach by Hennessy and Patterson</a></li>
</ol>

<p>There are some great resources mentioned in this <a href="https://www.reddit.com/r/compsci/comments/7sdcaq/best_way_to_learn_os_concepts_properly_so_that_i/">reddit thread</a>, i’ll be exploring them as i progress</p>

<h4 id="playlists">Playlists</h4>

<ol>
  <li><a href="https://www.youtube.com/playlist?list=PLeWkeA7esB-MuCn8XQWAarM7zvimE0yme">Computer Architecture Playlists by Prof. Dr. Ben H. Juurlink</a></li>
</ol>]]></content><author><name>Sanketh</name></author><category term="operating-systems" /><category term="learning-resources" /><summary type="html"><![CDATA[I have previously studied operating systems as a part of my university curriculum, i’ve realized it’s time to revisit the fundamentals and go beyond. I have decided to start with some popular books. I will add more resources as i go along.]]></summary></entry></feed>